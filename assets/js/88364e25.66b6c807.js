"use strict";(self.webpackChunkcs_notes=self.webpackChunkcs_notes||[]).push([[3555],{52678:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>r,default:()=>d,frontMatter:()=>a,metadata:()=>o,toc:()=>l});var i=t(85893),s=t(11151);const a={slug:"/compilers/scanning",id:"scanning",title:"Scanning",description:"Scanning"},r=void 0,o={id:"compilers/scanning/scanning",title:"Scanning",description:"Scanning",source:"@site/docs/compilers/03-scanning/scanning.md",sourceDirName:"compilers/03-scanning",slug:"/compilers/scanning",permalink:"/cs-notes/compilers/scanning",draft:!1,unlisted:!1,editUrl:"https://github.com/glennhenry/cs-notes/tree/main/docs/compilers/03-scanning/scanning.md",tags:[],version:"current",lastUpdatedBy:"glennhenry",lastUpdatedAt:1714643778e3,frontMatter:{slug:"/compilers/scanning",id:"scanning",title:"Scanning",description:"Scanning"},sidebar:"sidebar",previous:{title:"Syntax",permalink:"/cs-notes/compilers/syntax"},next:{title:"Parsing",permalink:"/cs-notes/compilers/parsing"}},c={},l=[];function h(e){const n={a:"a",admonition:"admonition",br:"br",code:"code",img:"img",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,s.a)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Main Source :"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.strong,{children:"Chapter 2, Programming Language Pragmatics - Michael L. Scott"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.strong,{children:"Chapter 3, Introduction to Compilers and Language Design - Douglas Thain"})}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.a,{href:"/programming-language-theory/syntax",children:"This note on programming language theory"})," discuss how syntax is specified. After writing source code in certain syntax, the next process is ",(0,i.jsx)(n.a,{href:"/compilers/parsing",children:"parsing"}),". It is the process of analyzing if the structure of a sequence of symbols follows the rules of a formal grammar correctly."]}),"\n",(0,i.jsxs)(n.p,{children:["Before parsing, a step called ",(0,i.jsx)(n.strong,{children:"scanning"})," occurs. This involves dividing the sequence of characters (e.g., source code) into meaningful units called ",(0,i.jsx)(n.strong,{children:"tokens"}),". Each token is then identified according to its category (e.g., keyword, identifier, literals), and parsing occurs afterwards."]}),"\n",(0,i.jsx)(n.admonition,{type:"info",children:(0,i.jsxs)(n.p,{children:["Scanning is the first step in ",(0,i.jsx)(n.a,{href:"/compilers/compilers-fundamentals#compilation-process",children:"compilation process"}),", while ",(0,i.jsx)(n.a,{href:"/compilers/parsing",children:"parsing"})," is the second step."]})}),"\n",(0,i.jsx)(n.p,{children:"The purpose of scanning is to reduce the input complexity by removing meaningless comments for the parser and eliminating whitespace (e.g., spaces, tabs, carriage returns, newlines), while only preserving the important tokens for the parser."}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.img,{alt:"Scanning algorithm for Pascal",src:t(31224).Z+"",width:"453",height:"470"}),(0,i.jsx)(n.br,{}),"\n","Source : Book page 48"]}),"\n",(0,i.jsx)(n.p,{children:"Above is the outline of scanner algorithm in Pascal programming language. Although it is from a specific language, the similar approach can be used for others. In general, the algorithm should ignore any white spaces. If it encounters unique symbols, it checks the symbol table if it is meaningful for the language. If some keywords are not from the language, it could be user-defined identifier, the compiler will also keep track of this."}),"\n",(0,i.jsxs)(n.p,{children:["The deterministic behavior of scanner can be described with a ",(0,i.jsx)(n.a,{href:"/theory-of-computation-and-automata/finite-automata",children:"finite automaton"})," like ",(0,i.jsx)(n.a,{href:"/theory-of-computation-and-automata/finite-automata#dfa",children:"DFA"}),". Deterministic means the system will always know what to do when it encounters any input. The automaton starts with an initial state, then it transitions to other state depending on the symbol encountered. If it reaches a final state, it means it has recognized some token."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.img,{alt:"Finite automaton of Pascal scanner",src:t(26777).Z+"",width:"482",height:"528"}),(0,i.jsx)(n.br,{}),"\n","Source : Book page 49"]}),"\n",(0,i.jsx)(n.p,{children:"A typical behavior of scanner is :"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"If it is unnecessary characters like comments and white lines, ignore them."}),"\n",(0,i.jsxs)(n.li,{children:["If it is single character token, such as operator like ",(0,i.jsx)(n.code,{children:"="}),", ",(0,i.jsx)(n.code,{children:"+"}),", ",(0,i.jsx)(n.code,{children:"-"}),"; literals, punctuations, save it as token."]}),"\n",(0,i.jsxs)(n.li,{children:["With multiple character token, it should check the character right after it. For example, ",(0,i.jsx)(n.code,{children:">"})," and ",(0,i.jsx)(n.code,{children:">="})," may be interpreted differently. The scanner must check if there is ",(0,i.jsx)(n.code,{children:"="})," right after it sees ",(0,i.jsx)(n.code,{children:">"}),", and interpret the token depending on the context."]}),"\n",(0,i.jsxs)(n.li,{children:["If it is digit, keep saving it until the sequence ends. If it encounters token like ",(0,i.jsx)(n.code,{children:"."}),", it may indicate the start of a floating-point number literal instead of just integer."]}),"\n",(0,i.jsx)(n.li,{children:"If it is a letter, keep saving it until the sequence ends. If the string is a known keyword, then save it as a keyword token, else as an identifier token."}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.a,{href:"#regular-expression",children:"Regular expression"})," is used to define the lexical rules or patterns that a scanner should recognize. This is why earlier we mentioned that regular expressions are helpful in defining tokens, as they are used to specify the patterns that scanner recognizes."]}),"\n",(0,i.jsxs)(n.p,{children:["Since a scanner reflects a finite automaton, creating a scanner specified with a regular expression involves converting the regular expression into an equivalent finite automaton. The regular expression is converted into an ",(0,i.jsx)(n.a,{href:"/theory-of-computation-and-automata/finite-automata#nfa",children:"NFA"})," first, then converted into a DFA. Optionally, we may ",(0,i.jsx)(n.a,{href:"/theory-of-computation-and-automata/finite-automata#minimization",children:"minimize the DFA"})," to reduce the number of states."]}),"\n",(0,i.jsx)(n.admonition,{type:"tip",children:(0,i.jsxs)(n.p,{children:["See ",(0,i.jsx)(n.a,{href:"/theory-of-computation-and-automata/regular-languages-part-2#regular-expression-to-finite-automata",children:"regular expression to finite automata"})," for an abstract example."]})}),"\n",(0,i.jsxs)(n.p,{children:["One way to make a scanner is through ",(0,i.jsx)(n.strong,{children:"scanner generator"})," (e.g., with a program called Lex). We specify our own regular expression, then the program take it and generate the scanner code in specific language. A scanner generator will generate the logic to tokenize the input source code based on the defined lexical rules. The generator may generate switch statement and nested loop to simulate an automaton behavior."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.img,{alt:"Usage of Flex",src:t(11106).Z+"",width:"1491",height:"468"}),(0,i.jsx)(n.br,{}),"\n","Source : Book 1 page 29-30"]}),"\n",(0,i.jsxs)(n.p,{children:["This is an example of using Flex to generate scanner. Flex takes a specification in ",(0,i.jsx)(n.code,{children:".flex"})," file to generate ",(0,i.jsx)(n.code,{children:"yylex()"})," function, which acts as the scanner. We will need to create our own ",(0,i.jsx)(n.code,{children:"main"})," function which actually call the ",(0,i.jsx)(n.code,{children:"yylex"}),", and it will save encountered tokens in ",(0,i.jsx)(n.code,{children:"yytext"})," file. The ",(0,i.jsx)(n.code,{children:"token.h"})," header file specify available token that we can use in the scanner. During the build process, the scanner exist in distinct ",(0,i.jsx)(n.code,{children:".c"})," file and will be linked to create final executable."]}),"\n",(0,i.jsxs)(n.p,{children:["Obviously, potential error will occur during scanning, this is called ",(0,i.jsx)(n.strong,{children:"lexical error"}),". It can arise from invalid characters, unrecognized character sequences, or violations of the language's lexical rules. The scanner may stop the scanning and report the error to user or ignoring the invalid token and continuing the scanning process."]}),"\n",(0,i.jsx)(n.p,{children:"Although using generator sounds easy and reduce efforts, making it manually is actually trivial. Furthermore, generator often doesn't provide helpful error message based on the actual context. Handwritten scanner allows for better control, customization, optimization, etc."})]})}function d(e={}){const{wrapper:n}={...(0,s.a)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(h,{...e})}):h(e)}},26777:(e,n,t)=>{t.d(n,{Z:()=>i});const i=t.p+"assets/images/finite-automaton-76a32f1aeabc4a4d5bb550fb2e449604.png"},11106:(e,n,t)=>{t.d(n,{Z:()=>i});const i=t.p+"assets/images/scanner-in-flex-f3a33ee0460284ec063ce95727787717.png"},31224:(e,n,t)=>{t.d(n,{Z:()=>i});const i=t.p+"assets/images/scanning-2039c23a992ac7aee697c2377331995b.png"},11151:(e,n,t)=>{t.d(n,{Z:()=>o,a:()=>r});var i=t(67294);const s={},a=i.createContext(s);function r(e){const n=i.useContext(a);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),i.createElement(a.Provider,{value:n},e.children)}}}]);