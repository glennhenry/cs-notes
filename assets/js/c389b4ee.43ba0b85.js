"use strict";(self.webpackChunkcs_notes=self.webpackChunkcs_notes||[]).push([[2240],{24967:(e,i,s)=>{s.r(i),s.d(i,{assets:()=>d,contentTitle:()=>o,default:()=>h,frontMatter:()=>a,metadata:()=>r,toc:()=>c});var n=s(85893),t=s(11151);const a={slug:"/digital-media-processing/ogg-vorbis",id:"ogg-vorbis",title:"OGG Vorbis",description:"OGG Vorbis"},o=void 0,r={id:"digital-media-processing/ogg-vorbis/ogg-vorbis",title:"OGG Vorbis",description:"OGG Vorbis",source:"@site/docs/digital-media-processing/24-ogg-vorbis/ogg-vorbis.md",sourceDirName:"digital-media-processing/24-ogg-vorbis",slug:"/digital-media-processing/ogg-vorbis",permalink:"/cs-notes/digital-media-processing/ogg-vorbis",draft:!1,unlisted:!1,editUrl:"https://github.com/glennhenry/cs-notes/tree/main/docs/digital-media-processing/24-ogg-vorbis/ogg-vorbis.md",tags:[],version:"current",lastUpdatedBy:"glennhenry",lastUpdatedAt:1707822071,formattedLastUpdatedAt:"Feb 13, 2024",frontMatter:{slug:"/digital-media-processing/ogg-vorbis",id:"ogg-vorbis",title:"OGG Vorbis",description:"OGG Vorbis"},sidebar:"sidebar",previous:{title:"WAV",permalink:"/cs-notes/digital-media-processing/wav"},next:{title:"MP3",permalink:"/cs-notes/digital-media-processing/mp3"}},d={},c=[{value:"OGG",id:"ogg",level:3},{value:"OGG Structure",id:"ogg-structure",level:3},{value:"OGG Vorbis",id:"ogg-vorbis",level:3},{value:"Encoding Process",id:"encoding-process",level:4},{value:"Decoding Process",id:"decoding-process",level:4}];function l(e){const i={a:"a",br:"br",h3:"h3",h4:"h4",img:"img",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,t.a)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(i.p,{children:(0,n.jsx)(i.strong,{children:"Main Source :"})}),"\n",(0,n.jsxs)(i.ul,{children:["\n",(0,n.jsx)(i.li,{children:(0,n.jsx)(i.strong,{children:(0,n.jsx)(i.a,{href:"https://en.wikipedia.org/wiki/Ogg",children:"Wikipedia Ogg"})})}),"\n",(0,n.jsx)(i.li,{children:(0,n.jsx)(i.strong,{children:(0,n.jsx)(i.a,{href:"https://en.wikipedia.org/wiki/Vorbis",children:"Wikipedia Vorbis"})})}),"\n"]}),"\n",(0,n.jsx)(i.h3,{id:"ogg",children:"OGG"}),"\n",(0,n.jsxs)(i.p,{children:[(0,n.jsx)(i.strong,{children:"OGG"})," is multimedia container format including audio, video, text, and metadata. As a container, OGG can hold multiple type of data, this is achieved by ",(0,n.jsx)(i.a,{href:"/digital-signal-processing/multiplexing",children:"multiplexing"}),". By supporting multiple type of data, OGG also supports multiple codecs for each data. Codecs is a software, device or program that is responsible for encoding and decoding a data stream or signal."]}),"\n",(0,n.jsx)(i.p,{children:"For example, an OGG file can contain audio, video, text, and metadata. The audio codec used is Vorbis, video codec is Theora, and the metadata provides additional information about the content such as title of the media, artist/author information, album/movie information, genres, and more."}),"\n",(0,n.jsx)(i.p,{children:(0,n.jsx)(i.img,{alt:"OGG container",src:s(34170).Z+"",width:"381",height:"575"})}),"\n",(0,n.jsx)(i.h3,{id:"ogg-structure",children:"OGG Structure"}),"\n",(0,n.jsx)(i.p,{children:"OGG file consists of a sequence of pages. Each page begins with a 27-byte header, followed by a variable-length payload. Each page size is generally between 4 to 64 kilobytes."}),"\n",(0,n.jsxs)(i.ol,{children:["\n",(0,n.jsxs)(i.li,{children:["\n",(0,n.jsxs)(i.p,{children:[(0,n.jsx)(i.strong,{children:"OGG Header"})," : The OGG file begins with an OGG header, which provides essential information about the file and its streams. The header includes details such as the OGG format version, the number of streams within the file, and the serial numbers assigned to each stream."]}),"\n"]}),"\n",(0,n.jsxs)(i.li,{children:["\n",(0,n.jsxs)(i.p,{children:[(0,n.jsx)(i.strong,{children:"Page Header"})," : Each page starts with a page header that contains metadata about the page itself. The header includes information such as the granule position, which represents the position of the data within the stream, and the page sequence number."]}),"\n"]}),"\n",(0,n.jsxs)(i.li,{children:["\n",(0,n.jsxs)(i.p,{children:[(0,n.jsx)(i.strong,{children:"Packet Data"})," : Following the page header, the page contains one or more packets of data. Each packet represents a chunk of encoded audio, video, text, or other multimedia data. The packets may belong to different streams within the file."]}),"\n"]}),"\n",(0,n.jsxs)(i.li,{children:["\n",(0,n.jsxs)(i.p,{children:[(0,n.jsx)(i.strong,{children:"Page Segments"})," : The page segments section follows the packet data and specifies the sizes of the individual packets within the page. It allows for variable-sized packets within a fixed-sized page."]}),"\n"]}),"\n",(0,n.jsxs)(i.li,{children:["\n",(0,n.jsxs)(i.p,{children:[(0,n.jsx)(i.strong,{children:"Page CRC Checksum"})," : Each page concludes with a cyclic redundancy checksum (CRC) value, which is used for error detection. In simple term, a data is calculated using mathematical function called ",(0,n.jsx)(i.a,{href:"/computer-security/hash-function",children:"hash function"})," to produce a value. The checksum is when we check if the produced value is the same as the value of the data that should be."]}),"\n"]}),"\n",(0,n.jsxs)(i.li,{children:["\n",(0,n.jsxs)(i.p,{children:[(0,n.jsx)(i.strong,{children:"Metadata"})," : Metadata can include details such as track titles, artist/author information, album/movie information, genres, and more. The metadata is typically stored in dedicated packets within the stream."]}),"\n"]}),"\n"]}),"\n",(0,n.jsxs)(i.p,{children:[(0,n.jsx)(i.img,{alt:"The structure of OGG page header",src:s(99200).Z+"",width:"564",height:"283"}),(0,n.jsx)(i.br,{}),"\n","Source : ",(0,n.jsx)(i.a,{href:"https://en.wikipedia.org/wiki/Ogg",children:"https://en.wikipedia.org/wiki/Ogg"}),(0,n.jsx)(i.br,{}),"\n","* Image of OGG page header"]}),"\n",(0,n.jsx)(i.h3,{id:"ogg-vorbis",children:"OGG Vorbis"}),"\n",(0,n.jsxs)(i.p,{children:[(0,n.jsx)(i.strong,{children:"Vorbis"}),' is the specific codecs for audio data in OGG file, it uses a lossy compression. The process of vorbis codecs begins with the audio data is divided into small sections called "blocks" or "windows." Each block typically contains a few milliseconds of audio.']}),"\n",(0,n.jsx)(i.h4,{id:"encoding-process",children:"Encoding Process"}),"\n",(0,n.jsxs)(i.ol,{children:["\n",(0,n.jsxs)(i.li,{children:["\n",(0,n.jsxs)(i.p,{children:[(0,n.jsx)(i.strong,{children:"Psychoacoustic Modeling"})," : The Vorbis codec applies a psychoacoustic model to analyze the audio within each block. This model takes into account the characteristics of human hearing and discard the less important audio."]}),"\n"]}),"\n",(0,n.jsxs)(i.li,{children:["\n",(0,n.jsxs)(i.p,{children:[(0,n.jsx)(i.strong,{children:"Transform"})," : The audio data within each block is transformed from the time domain to the frequency domain using the Modified ",(0,n.jsx)(i.a,{href:"/digital-signal-processing/discrete-cosine-transform",children:"Discrete Cosine Transform"})," (MDCT). The modified DCT is used for processing overlapping blocks of audio or video data. This transformation will map the audio to frequency domain."]}),"\n"]}),"\n",(0,n.jsxs)(i.li,{children:["\n",(0,n.jsxs)(i.p,{children:[(0,n.jsx)(i.strong,{children:(0,n.jsx)(i.a,{href:"/digital-signal-processing/quantization",children:"Quantization"})})," : The transformed audio data is quantized, meaning the amplitudes of the frequency components are approximated and represented with fewer bits."]}),"\n"]}),"\n",(0,n.jsxs)(i.li,{children:["\n",(0,n.jsxs)(i.p,{children:[(0,n.jsx)(i.strong,{children:"Encoding"})," : The quantized audio data is further processed and encoded using variable bitrate encoding. The codec allocates more bits to preserve important audio details and fewer bits for less important parts, based on the psychoacoustic analysis."]}),"\n"]}),"\n",(0,n.jsxs)(i.li,{children:["\n",(0,n.jsxs)(i.p,{children:[(0,n.jsx)(i.strong,{children:"Bitstream Generation"})," : The encoded audio data, along with metadata such as track information and tags, is packaged into a bitstream or sequence of bit to the OGG container format."]}),"\n"]}),"\n"]}),"\n",(0,n.jsx)(i.h4,{id:"decoding-process",children:"Decoding Process"}),"\n",(0,n.jsxs)(i.ol,{children:["\n",(0,n.jsxs)(i.li,{children:["\n",(0,n.jsxs)(i.p,{children:[(0,n.jsx)(i.strong,{children:"Bitstream Parsing"})," : The Vorbis decoder reads and parses the encoded bitstream, extracting the compressed audio data and associated metadata."]}),"\n"]}),"\n",(0,n.jsxs)(i.li,{children:["\n",(0,n.jsxs)(i.p,{children:[(0,n.jsx)(i.strong,{children:"Decoding"})," : The quantized and compressed audio data is decoded, reversing the encoding process. The inverse operations of quantization, inverse variable bitrate decoding, and inverse MDCT are applied to reconstruct the frequency representation of the audio."]}),"\n"]}),"\n",(0,n.jsxs)(i.li,{children:["\n",(0,n.jsxs)(i.p,{children:[(0,n.jsx)(i.strong,{children:"Time-domain Reconstruction"})," : The frequency data is transformed back into the time domain through additional processing."]}),"\n"]}),"\n",(0,n.jsxs)(i.li,{children:["\n",(0,n.jsxs)(i.p,{children:[(0,n.jsx)(i.strong,{children:"Audio Playback"})," : The decoded audio is played back through speakers or headphones, allowing the listener to hear the reconstructed audio."]}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:i}={...(0,t.a)(),...e.components};return i?(0,n.jsx)(i,{...e,children:(0,n.jsx)(l,{...e})}):l(e)}},34170:(e,i,s)=>{s.d(i,{Z:()=>n});const n=s.p+"assets/images/ogg-container-4e22244a15eb17907126f4ef8a0eaf84.png"},99200:(e,i,s)=>{s.d(i,{Z:()=>n});const n=s.p+"assets/images/ogg-structure-ffe5cc74f854db321d5d10728850af2e.png"},11151:(e,i,s)=>{s.d(i,{Z:()=>r,a:()=>o});var n=s(67294);const t={},a=n.createContext(t);function o(e){const i=n.useContext(a);return n.useMemo((function(){return"function"==typeof e?e(i):{...i,...e}}),[i,e])}function r(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:o(e.components),n.createElement(a.Provider,{value:i},e.children)}}}]);