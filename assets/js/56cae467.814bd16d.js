"use strict";(self.webpackChunkcs_notes=self.webpackChunkcs_notes||[]).push([[7794],{3905:(e,a,t)=>{t.d(a,{Zo:()=>p,kt:()=>g});var n=t(67294);function s(e,a,t){return a in e?Object.defineProperty(e,a,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[a]=t,e}function r(e,a){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);a&&(n=n.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),t.push.apply(t,n)}return t}function i(e){for(var a=1;a<arguments.length;a++){var t=null!=arguments[a]?arguments[a]:{};a%2?r(Object(t),!0).forEach((function(a){s(e,a,t[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):r(Object(t)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(t,a))}))}return e}function o(e,a){if(null==e)return{};var t,n,s=function(e,a){if(null==e)return{};var t,n,s={},r=Object.keys(e);for(n=0;n<r.length;n++)t=r[n],a.indexOf(t)>=0||(s[t]=e[t]);return s}(e,a);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(n=0;n<r.length;n++)t=r[n],a.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(s[t]=e[t])}return s}var m=n.createContext({}),l=function(e){var a=n.useContext(m),t=a;return e&&(t="function"==typeof e?e(a):i(i({},a),e)),t},p=function(e){var a=l(e.components);return n.createElement(m.Provider,{value:a},e.children)},c="mdxType",h={inlineCode:"code",wrapper:function(e){var a=e.children;return n.createElement(n.Fragment,{},a)}},d=n.forwardRef((function(e,a){var t=e.components,s=e.mdxType,r=e.originalType,m=e.parentName,p=o(e,["components","mdxType","originalType","parentName"]),c=l(t),d=s,g=c["".concat(m,".").concat(d)]||c[d]||h[d]||r;return t?n.createElement(g,i(i({ref:a},p),{},{components:t})):n.createElement(g,i({ref:a},p))}));function g(e,a){var t=arguments,s=a&&a.mdxType;if("string"==typeof e||s){var r=t.length,i=new Array(r);i[0]=d;var o={};for(var m in a)hasOwnProperty.call(a,m)&&(o[m]=a[m]);o.originalType=e,o[c]="string"==typeof e?e:s,i[1]=o;for(var l=2;l<r;l++)i[l]=t[l];return n.createElement.apply(null,i)}return n.createElement.apply(null,t)}d.displayName="MDXCreateElement"},6157:(e,a,t)=>{t.r(a),t.d(a,{assets:()=>m,contentTitle:()=>i,default:()=>h,frontMatter:()=>r,metadata:()=>o,toc:()=>l});var n=t(87462),s=(t(67294),t(3905));const r={slug:"/deep-learning/gan",id:"gan",title:"GAN",description:"GAN"},i=void 0,o={unversionedId:"deep-learning/gan/gan",id:"deep-learning/gan/gan",title:"GAN",description:"GAN",source:"@site/docs/deep-learning/12-gan/gan.md",sourceDirName:"deep-learning/12-gan",slug:"/deep-learning/gan",permalink:"/cs-notes/deep-learning/gan",draft:!1,editUrl:"https://github.com/glennhenry/cs-notes/tree/main/docs/deep-learning/12-gan/gan.md",tags:[],version:"current",lastUpdatedBy:"glennhenry",lastUpdatedAt:1696333375,formattedLastUpdatedAt:"Oct 3, 2023",frontMatter:{slug:"/deep-learning/gan",id:"gan",title:"GAN",description:"GAN"},sidebar:"sidebar",previous:{title:"Variational Autoencoder",permalink:"/cs-notes/deep-learning/variational-autoencoder"},next:{title:"Transformers Intro",permalink:"/cs-notes/deep-learning/transformers/transformers-intro"}},m={},l=[{value:"Adversarial Training",id:"adversarial-training",level:4},{value:"Generator",id:"generator",level:3},{value:"Discriminator",id:"discriminator",level:3},{value:"Training Process",id:"training-process",level:4},{value:"Loss Function",id:"loss-function",level:3},{value:"Minimax",id:"minimax",level:4},{value:"Wasserstein",id:"wasserstein",level:3},{value:"Variations of GAN",id:"variations-of-gan",level:3},{value:"Conditional GAN (cGAN)",id:"conditional-gan-cgan",level:4},{value:"Variational Autoencoder GAN (VAE-GAN)",id:"variational-autoencoder-gan-vae-gan",level:4},{value:"CycleGAN",id:"cyclegan",level:4}],p={toc:l},c="wrapper";function h(e){let{components:a,...r}=e;return(0,s.kt)(c,(0,n.Z)({},p,r,{components:a,mdxType:"MDXLayout"}),(0,s.kt)("p",null,(0,s.kt)("strong",{parentName:"p"},"Main Source :")),(0,s.kt)("ul",null,(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("strong",{parentName:"li"},(0,s.kt)("a",{parentName:"strong",href:"https://developers.google.com/machine-learning/gan"},"Google ML GAN Course"))),(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("strong",{parentName:"li"},(0,s.kt)("a",{parentName:"strong",href:"https://youtu.be/QJOEmwvnmTM?si=NiUmbLBTvcLh7wVb"},"WGANs: A stable alternative to traditional GANs || Wasserstein GAN - Developers Hutt")))),(0,s.kt)("p",null,(0,s.kt)("strong",{parentName:"p"},"Generative Adversarial Network (GAN)")," is a machine learning framework specifically used to generate data. GANs are a generative model, similar as ",(0,s.kt)("a",{parentName:"p",href:"/deep-learning/variational-autoencoder"},"variational autoencoder (VAE)"),", meaning they generate new samples that are similar to the training data. We feed some data to the model, the model will capture the pattern and common structure of the data to generate new instance of data."),(0,s.kt)("p",null,"GAN can be used to generate new images, audio, video, or generating next word in a sentence."),(0,s.kt)("p",null,"GAN consist of two components: the ",(0,s.kt)("strong",{parentName:"p"},"generator")," and the ",(0,s.kt)("strong",{parentName:"p"},"discriminator"),". The generator is responsible for generating new data samples, while the discriminator acts as a binary classifier, distinguishing between different types of data. GANs is an unsupervised learning because they do not rely on labeled data with correct outputs or labels."),(0,s.kt)("p",null,"The idea behind GANs is that the generator produces new data, and the discriminator which is able to differentiate between different types of data, in this case the discriminator differentiate between real or fake data, act as a critic that provides feedback to the generator to improve its data generation capabilities."),(0,s.kt)("h4",{id:"adversarial-training"},"Adversarial Training"),(0,s.kt)("p",null,"Both generator and discriminator are trained in adversarial way, the generator's objective is to produce new samples that can fool the discriminator, while the discriminator's objective is to accurately distinguish between real and fake samples."),(0,s.kt)("p",null,"The discriminator takes input from the data generated by the generator and the data from training samples. The data are combined together, every data from generator is labeled as fake and every data from the training samples is labeled as real."),(0,s.kt)("p",null,"The loss will be calculated from the classification result, the loss represent how good is the data generated by the generator and how correct is the classification of the discriminator."),(0,s.kt)("p",null,"GAN is considered as a ",(0,s.kt)("strong",{parentName:"p"},"minimax game")," or a ",(0,s.kt)("strong",{parentName:"p"},"zero-sum game"),", which is a mathematical game concept that represents a competitive interaction between two players. The goal of one player is to minimize their maximum possible loss (minimizer), while the goal of the other player is to maximize their minimum possible gain (maximizer)."),(0,s.kt)("p",null,"In this case, the generator aims to minimize the discriminator's ability to differentiate between real and fake samples, while the discriminator aims to maximize its ability to correctly classify real and fake samples."),(0,s.kt)("p",null,(0,s.kt)("img",{alt:"GAN mechanism between generator and discriminator",src:t(12644).Z,width:"771",height:"339"}),(0,s.kt)("br",{parentName:"p"}),"\n","Source : ",(0,s.kt)("a",{parentName:"p",href:"https://sthalles.github.io/intro-to-gans/"},"https://sthalles.github.io/intro-to-gans/")),(0,s.kt)("h3",{id:"generator"},"Generator"),(0,s.kt)("p",null,"The generator first takes a random input usually sampled from a normal or uniform distribution. The random input is often referred as ",(0,s.kt)("strong",{parentName:"p"},"latent vector")," or ",(0,s.kt)("strong",{parentName:"p"},"noise vector"),", which is a term for features that captures the charateristics of data. However, since it's just a random input they don't have necesarry meaning, they simply serve as a random seed for the starting point."),(0,s.kt)("p",null,(0,s.kt)("img",{alt:"Random noises as input",src:t(57477).Z,width:"233",height:"175"}),(0,s.kt)("br",{parentName:"p"}),"\n","Source : ",(0,s.kt)("a",{parentName:"p",href:"https://www.researchgate.net/figure/The-semi-supervised-GAN-architecture-Random-noise-is-used-by-the-Generator-to-generate_fig4_335359919"},"https://www.researchgate.net/figure/The-semi-supervised-GAN-architecture-Random-noise-is-used-by-the-Generator-to-generate_fig4_335359919")," (with modification)"),(0,s.kt)("p",null,"The random input will then be transformed into a higher-dimensional representation. They are passed into some neural network architecture such as ",(0,s.kt)("a",{parentName:"p",href:"/deep-learning/cnn"},"convolutional neural network")," for image related tasks that also include ",(0,s.kt)("a",{parentName:"p",href:"/deep-learning/deep-learning-foundation"},"activation function")," to enable the network to capture complex patterns."),(0,s.kt)("p",null,"The final layer of generator produces the generated data, which could be images, text, or any other type of data depending on the application. The generated sample are then fed into discriminator to be classified."),(0,s.kt)("p",null,(0,s.kt)("img",{alt:"Generator",src:t(24401).Z,width:"615",height:"252"}),(0,s.kt)("br",{parentName:"p"}),"\n","Source : ",(0,s.kt)("a",{parentName:"p",href:"https://towardsdatascience.com/dcgans-deep-convolutional-generative-adversarial-networks-c7f392c2c8f8"},"https://towardsdatascience.com/dcgans-deep-convolutional-generative-adversarial-networks-c7f392c2c8f8")),(0,s.kt)("h3",{id:"discriminator"},"Discriminator"),(0,s.kt)("p",null,"The discriminator can be any network architecture capable of classifying, if it's an image related task, ",(0,s.kt)("a",{parentName:"p",href:"/deep-learning/cnn"},"convolutional neural network")," can be used. The input data will be combined from the training samples and the generated samples. They will be labeled as fake or real and the discriminator will assign probability or how likely is the data to be real or fake."),(0,s.kt)("h4",{id:"training-process"},"Training Process"),(0,s.kt)("p",null,"In GAN, the training process of both generator and discriminator are closely related. When the discriminator fails, meaning it fail to accurately distinguish between real and generated samples, this will also provide weak or incorrect feedback to the generator, which hold back the learning process. The generator may receive misleading signals that its generated samples are realistic, even if they are not, making it might not learn to improve and generate a better samples."),(0,s.kt)("p",null,"This is often called as ",(0,s.kt)("strong",{parentName:"p"},"convergence failure"),"."),(0,s.kt)("p",null,"Both generator and discriminator are trained in alternating turns. This is to stabilize the learning process and to establish a feedback loop by improving iteratively from each other feedback."),(0,s.kt)("h3",{id:"loss-function"},"Loss Function"),(0,s.kt)("p",null,"The loss function used for GAN will be two, one for generator and another for discriminator. We used two loss function to be able to measure both of their performance. As explained before, the generator tries to minimize its loss by generating more realistic data, while the discriminator tries to minimize its loss by becoming better at classifying the data."),(0,s.kt)("h4",{id:"minimax"},"Minimax"),(0,s.kt)("p",null,"The minimax loss is the loss function used in the original paper that introduced GAN. The formula is :"),(0,s.kt)("p",null,(0,s.kt)("img",{alt:"Minimax loss function formula",src:t(88542).Z,width:"839",height:"405"}),(0,s.kt)("br",{parentName:"p"}),"\n","Source : ",(0,s.kt)("a",{parentName:"p",href:"https://developers.google.com/machine-learning/gan/loss"},"https://developers.google.com/machine-learning/gan/loss")),(0,s.kt)("p",null,"The D and G is commonly used to refer the discriminator and generator, respectively. It is related to the ",(0,s.kt)("a",{parentName:"p",href:"/deep-learning/deep-learning-foundation#cross-entropy"},"cross entropy loss function formula"),". The expected value measure of what we can expect to observe on average when dealing with uncertainty, in this case the uncertainty of the real data ",(0,s.kt)("span",{parentName:"p",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("msub",{parentName:"mrow"},(0,s.kt)("mi",{parentName:"msub"},"E"),(0,s.kt)("mi",{parentName:"msub"},"x"))),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"E_x")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.8333em",verticalAlign:"-0.15em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.05764em"}},"E"),(0,s.kt)("span",{parentName:"span",className:"msupsub"},(0,s.kt)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.1514em"}},(0,s.kt)("span",{parentName:"span",style:{top:"-2.55em",marginLeft:"-0.0576em",marginRight:"0.05em"}},(0,s.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,s.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight"},"x")))),(0,s.kt)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.15em"}},(0,s.kt)("span",{parentName:"span"}))))))))))," and the fake instance ",(0,s.kt)("span",{parentName:"p",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("msub",{parentName:"mrow"},(0,s.kt)("mi",{parentName:"msub"},"E"),(0,s.kt)("mi",{parentName:"msub"},"z"))),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"E_z")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.8333em",verticalAlign:"-0.15em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.05764em"}},"E"),(0,s.kt)("span",{parentName:"span",className:"msupsub"},(0,s.kt)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.1514em"}},(0,s.kt)("span",{parentName:"span",style:{top:"-2.55em",marginLeft:"-0.0576em",marginRight:"0.05em"}},(0,s.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,s.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight",style:{marginRight:"0.04398em"}},"z")))),(0,s.kt)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.15em"}},(0,s.kt)("span",{parentName:"span"})))))))))),"."),(0,s.kt)("p",null,"The first term ",(0,s.kt)("span",{parentName:"p",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("msub",{parentName:"mrow"},(0,s.kt)("mi",{parentName:"msub"},"E"),(0,s.kt)("mi",{parentName:"msub"},"x")),(0,s.kt)("mo",{parentName:"mrow",stretchy:"false"},"["),(0,s.kt)("mi",{parentName:"mrow"},"log"),(0,s.kt)("mo",{parentName:"mrow"},"\u2061"),(0,s.kt)("mo",{parentName:"mrow",stretchy:"false"},"("),(0,s.kt)("mi",{parentName:"mrow"},"D"),(0,s.kt)("mo",{parentName:"mrow",stretchy:"false"},"("),(0,s.kt)("mi",{parentName:"mrow"},"x"),(0,s.kt)("mo",{parentName:"mrow",stretchy:"false"},")"),(0,s.kt)("mo",{parentName:"mrow",stretchy:"false"},")"),(0,s.kt)("mo",{parentName:"mrow",stretchy:"false"},"]")),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"E_x[\\log(D(x))]")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.05764em"}},"E"),(0,s.kt)("span",{parentName:"span",className:"msupsub"},(0,s.kt)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.1514em"}},(0,s.kt)("span",{parentName:"span",style:{top:"-2.55em",marginLeft:"-0.0576em",marginRight:"0.05em"}},(0,s.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,s.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight"},"x")))),(0,s.kt)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.15em"}},(0,s.kt)("span",{parentName:"span"})))))),(0,s.kt)("span",{parentName:"span",className:"mopen"},"["),(0,s.kt)("span",{parentName:"span",className:"mop"},"lo",(0,s.kt)("span",{parentName:"span",style:{marginRight:"0.01389em"}},"g")),(0,s.kt)("span",{parentName:"span",className:"mopen"},"("),(0,s.kt)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.02778em"}},"D"),(0,s.kt)("span",{parentName:"span",className:"mopen"},"("),(0,s.kt)("span",{parentName:"span",className:"mord mathnormal"},"x"),(0,s.kt)("span",{parentName:"span",className:"mclose"},"))]")))))," represents the expected log-likelihood (the logarithm of a probability) of the ",(0,s.kt)("strong",{parentName:"p"},"discriminator correctly classifying real data as real"),'. The generator aims to minimize this term to generate data that can "fool" the discriminator.'),(0,s.kt)("p",null,"The second term ",(0,s.kt)("span",{parentName:"p",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("msub",{parentName:"mrow"},(0,s.kt)("mi",{parentName:"msub"},"E"),(0,s.kt)("mi",{parentName:"msub"},"z")),(0,s.kt)("mo",{parentName:"mrow",stretchy:"false"},"["),(0,s.kt)("mi",{parentName:"mrow"},"log"),(0,s.kt)("mo",{parentName:"mrow"},"\u2061"),(0,s.kt)("mo",{parentName:"mrow",stretchy:"false"},"("),(0,s.kt)("mn",{parentName:"mrow"},"1"),(0,s.kt)("mo",{parentName:"mrow"},"\u2212"),(0,s.kt)("mi",{parentName:"mrow"},"D"),(0,s.kt)("mo",{parentName:"mrow",stretchy:"false"},"("),(0,s.kt)("mi",{parentName:"mrow"},"G"),(0,s.kt)("mo",{parentName:"mrow",stretchy:"false"},"("),(0,s.kt)("mi",{parentName:"mrow"},"z"),(0,s.kt)("mo",{parentName:"mrow",stretchy:"false"},")"),(0,s.kt)("mo",{parentName:"mrow",stretchy:"false"},")"),(0,s.kt)("mo",{parentName:"mrow",stretchy:"false"},")"),(0,s.kt)("mo",{parentName:"mrow",stretchy:"false"},"]")),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"E_z[\\log(1 - D(G(z)))]")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.05764em"}},"E"),(0,s.kt)("span",{parentName:"span",className:"msupsub"},(0,s.kt)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.1514em"}},(0,s.kt)("span",{parentName:"span",style:{top:"-2.55em",marginLeft:"-0.0576em",marginRight:"0.05em"}},(0,s.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,s.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight",style:{marginRight:"0.04398em"}},"z")))),(0,s.kt)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.15em"}},(0,s.kt)("span",{parentName:"span"})))))),(0,s.kt)("span",{parentName:"span",className:"mopen"},"["),(0,s.kt)("span",{parentName:"span",className:"mop"},"lo",(0,s.kt)("span",{parentName:"span",style:{marginRight:"0.01389em"}},"g")),(0,s.kt)("span",{parentName:"span",className:"mopen"},"("),(0,s.kt)("span",{parentName:"span",className:"mord"},"1"),(0,s.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2222em"}}),(0,s.kt)("span",{parentName:"span",className:"mbin"},"\u2212"),(0,s.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2222em"}})),(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,s.kt)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.02778em"}},"D"),(0,s.kt)("span",{parentName:"span",className:"mopen"},"("),(0,s.kt)("span",{parentName:"span",className:"mord mathnormal"},"G"),(0,s.kt)("span",{parentName:"span",className:"mopen"},"("),(0,s.kt)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.04398em"}},"z"),(0,s.kt)("span",{parentName:"span",className:"mclose"},")))]")))))," represents the expected log-likelihood of the ",(0,s.kt)("strong",{parentName:"p"},"discriminator correctly classifying generated data as generated"),". The discriminator aims to maximize this term by correctly distinguishing between real and generated data."),(0,s.kt)("p",null,"The minimization or maximization of specific term is done by taking the partial derivative with respect to the specific parameters. The loss will be optimized and backpropagation process will be done to adjust all the parameters involved. The generator is connected to the discriminator to receive its gradient for optimization step."),(0,s.kt)("h3",{id:"wasserstein"},"Wasserstein"),(0,s.kt)("p",null,"The Wasserstein loss is the alternative loss function for minimax, it modified the concept of standard GAN, becoming ",(0,s.kt)("strong",{parentName:"p"},"Wasserstein Generative Adversarial Networks (WGANs)"),". This was introduced to address GAN problem including the lack of meaningful loss metric."),(0,s.kt)("p",null,"The minimax loss does not provide a direct and meaningful measure of the quality of generated samples, it only provides a real or fake indicator. The objective function does not correlate well with the visual quality or desired characteristics of the generated samples, making it difficult to assess the progress of training."),(0,s.kt)("p",null,"In WGAN, the discriminator is no longer trained to classify samples as real or fake. Also, it is no longer called a discriminator, instead it is called a ",(0,s.kt)("strong",{parentName:"p"},"critic"),"."),(0,s.kt)("p",null,"The real data from training sample and the fake data from generator is represented in a probability distribution. The discriminator or the critic still have its own network, however, the output of the network is a measure of how far is the input it received from the real data probability distribution. It is calculated using the ",(0,s.kt)("strong",{parentName:"p"},"earth mover distance")," or the ",(0,s.kt)("strong",{parentName:"p"},"wasserstein distance"),"."),(0,s.kt)("p",null,"After that, the result of critic will be used in the wasserstein loss function, which is the below formula :"),(0,s.kt)("p",null,(0,s.kt)("img",{alt:"Wasserstein loss",src:t(58872).Z,width:"858",height:"433"}),(0,s.kt)("br",{parentName:"p"}),"\n","Source : ",(0,s.kt)("a",{parentName:"p",href:"https://developers.google.com/machine-learning/gan/loss"},"https://developers.google.com/machine-learning/gan/loss")),(0,s.kt)("p",null,"The critic is trained to maximize the critic loss which is the difference between the output on real and fake instance. This mean we are training the critic to be able to accurately estimate the distance between input distribution and the real distribution. And the generator is trained to maximize the critic output for fake instance (or minimizing the negative output of critic), where the higher means the more close it is to real data."),(0,s.kt)("p",null,"In summary, the benefit of having the critic produce real-valued outputs instead of binary real or fake labels is that it allows the critic to provide a measure of the degree of realism in the generated samples."),(0,s.kt)("p",null,"After that, the backpropagation process that optimize all the parameters involved, including the generator's parameters are done. The gradient from the discriminator as the output will be passed to the generator."),(0,s.kt)("h3",{id:"variations-of-gan"},"Variations of GAN"),(0,s.kt)("p",null,"GAN also have several variations, the two example are :"),(0,s.kt)("h4",{id:"conditional-gan-cgan"},"Conditional GAN (cGAN)"),(0,s.kt)("p",null,"In traditional GAN, the generator takes random noise as input and produces new samples. In cGAN, both the generator and discriminator are conditioned on additional information, in the form of labels or class information. It uses the concept of conditional probability with the given condition instead of the concept of joint probability of the noise and real data."),(0,s.kt)("p",null,"This conditioning enables the generation of samples that are conditioned on specific attributes, making it useful for tasks like generating samples based on specific class labels or generating another image based on some input image (called image-to-image translation)."),(0,s.kt)("p",null,(0,s.kt)("img",{alt:"cGAN compared to GAN",src:t(2855).Z,width:"844",height:"360"}),(0,s.kt)("br",{parentName:"p"}),"\n","Source : ",(0,s.kt)("a",{parentName:"p",href:"https://learnopencv.com/conditional-gan-cgan-in-pytorch-and-tensorflow/"},"https://learnopencv.com/conditional-gan-cgan-in-pytorch-and-tensorflow/"),", ",(0,s.kt)("a",{parentName:"p",href:"https://developers.google.com/machine-learning/gan/applications"},"https://developers.google.com/machine-learning/gan/applications")),(0,s.kt)("h4",{id:"variational-autoencoder-gan-vae-gan"},"Variational Autoencoder GAN (VAE-GAN)"),(0,s.kt)("p",null,"VAE-GAN combines the ",(0,s.kt)("a",{parentName:"p",href:"/deep-learning/variational-autoencoder"},"variational autoencoder")," with the traditional GAN."),(0,s.kt)("h4",{id:"cyclegan"},"CycleGAN"))}h.isMDXComponent=!0},2855:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/cgan-a9e20f78cd55d24be6df0948fdaf9121.png"},12644:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/gan-mechanism-77e13606a12da22ef72d4535f02e33a7.png"},24401:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/generator-1537b2da6c092a8b0b408d9aebc459f4.png"},88542:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/minimax-loss-b619348ad4c45a2744a24fdbf69df6cf.png"},57477:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/random-noise-8450cd8b68c6e17dfe0a61a252989ca1.png"},58872:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/wasserstein-loss-ed4f77f8e2afc97603e0f3fa8acd6e68.png"}}]);