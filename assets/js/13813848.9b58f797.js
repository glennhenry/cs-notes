"use strict";(self.webpackChunkcs_notes=self.webpackChunkcs_notes||[]).push([[1131],{3905:(e,n,r)=>{r.d(n,{Zo:()=>d,kt:()=>y});var t=r(67294);function i(e,n,r){return n in e?Object.defineProperty(e,n,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[n]=r,e}function o(e,n){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);n&&(t=t.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),r.push.apply(r,t)}return r}function a(e){for(var n=1;n<arguments.length;n++){var r=null!=arguments[n]?arguments[n]:{};n%2?o(Object(r),!0).forEach((function(n){i(e,n,r[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):o(Object(r)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(r,n))}))}return e}function c(e,n){if(null==e)return{};var r,t,i=function(e,n){if(null==e)return{};var r,t,i={},o=Object.keys(e);for(t=0;t<o.length;t++)r=o[t],n.indexOf(r)>=0||(i[r]=e[r]);return i}(e,n);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(t=0;t<o.length;t++)r=o[t],n.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(i[r]=e[r])}return i}var l=t.createContext({}),p=function(e){var n=t.useContext(l),r=n;return e&&(r="function"==typeof e?e(n):a(a({},n),e)),r},d=function(e){var n=p(e.components);return t.createElement(l.Provider,{value:n},e.children)},s="mdxType",g={inlineCode:"code",wrapper:function(e){var n=e.children;return t.createElement(t.Fragment,{},n)}},u=t.forwardRef((function(e,n){var r=e.components,i=e.mdxType,o=e.originalType,l=e.parentName,d=c(e,["components","mdxType","originalType","parentName"]),s=p(r),u=i,y=s["".concat(l,".").concat(u)]||s[u]||g[u]||o;return r?t.createElement(y,a(a({ref:n},d),{},{components:r})):t.createElement(y,a({ref:n},d))}));function y(e,n){var r=arguments,i=n&&n.mdxType;if("string"==typeof e||i){var o=r.length,a=new Array(o);a[0]=u;var c={};for(var l in n)hasOwnProperty.call(n,l)&&(c[l]=n[l]);c.originalType=e,c[s]="string"==typeof e?e:i,a[1]=c;for(var p=2;p<o;p++)a[p]=r[p];return t.createElement.apply(null,a)}return t.createElement.apply(null,r)}u.displayName="MDXCreateElement"},62812:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>g,frontMatter:()=>o,metadata:()=>c,toc:()=>p});var t=r(87462),i=(r(67294),r(3905));const o={slug:"/deep-learning/reinforcement-learning/policy-gradient",id:"policy-gradient",title:"Policy-Gradient",description:"Policy-Gradient"},a=void 0,c={unversionedId:"deep-learning/reinforcement-learning/policy-gradient/policy-gradient",id:"deep-learning/reinforcement-learning/policy-gradient/policy-gradient",title:"Policy-Gradient",description:"Policy-Gradient",source:"@site/docs/deep-learning/16-reinforcement-learning/09-policy-gradient/policy-gradient.md",sourceDirName:"deep-learning/16-reinforcement-learning/09-policy-gradient",slug:"/deep-learning/reinforcement-learning/policy-gradient",permalink:"/cs-notes/deep-learning/reinforcement-learning/policy-gradient",draft:!1,editUrl:"https://github.com/glennhenry/cs-notes/tree/main/docs/deep-learning/16-reinforcement-learning/09-policy-gradient/policy-gradient.md",tags:[],version:"current",lastUpdatedBy:"glennhenry",lastUpdatedAt:1698234445,formattedLastUpdatedAt:"Oct 25, 2023",frontMatter:{slug:"/deep-learning/reinforcement-learning/policy-gradient",id:"policy-gradient",title:"Policy-Gradient",description:"Policy-Gradient"},sidebar:"sidebar",previous:{title:"Bandits",permalink:"/cs-notes/deep-learning/reinforcement-learning/bandits"},next:{title:"Actor-Critic",permalink:"/cs-notes/deep-learning/reinforcement-learning/actor-critic"}},l={},p=[{value:"DPG",id:"dpg",level:3}],d={toc:p},s="wrapper";function g(e){let{components:n,...r}=e;return(0,i.kt)(s,(0,t.Z)({},d,r,{components:n,mdxType:"MDXLayout"}),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"Main Source :")),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"Policy-Gradient")," is ..."),(0,i.kt)("h3",{id:"dpg"},"DPG"))}g.isMDXComponent=!0}}]);