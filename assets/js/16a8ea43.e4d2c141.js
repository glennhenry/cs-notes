"use strict";(self.webpackChunkcs_notes=self.webpackChunkcs_notes||[]).push([[7704],{3905:(e,t,n)=>{n.d(t,{Zo:()=>c,kt:()=>m});var i=n(67294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);t&&(i=i.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,i)}return n}function r(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,i,a=function(e,t){if(null==e)return{};var n,i,a={},o=Object.keys(e);for(i=0;i<o.length;i++)n=o[i],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(i=0;i<o.length;i++)n=o[i],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var s=i.createContext({}),p=function(e){var t=i.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):r(r({},t),e)),n},c=function(e){var t=p(e.components);return i.createElement(s.Provider,{value:t},e.children)},u="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return i.createElement(i.Fragment,{},t)}},h=i.forwardRef((function(e,t){var n=e.components,a=e.mdxType,o=e.originalType,s=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),u=p(n),h=a,m=u["".concat(s,".").concat(h)]||u[h]||d[h]||o;return n?i.createElement(m,r(r({ref:t},c),{},{components:n})):i.createElement(m,r({ref:t},c))}));function m(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var o=n.length,r=new Array(o);r[0]=h;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l[u]="string"==typeof e?e:a,r[1]=l;for(var p=2;p<o;p++)r[p]=n[p];return i.createElement.apply(null,r)}return i.createElement.apply(null,n)}h.displayName="MDXCreateElement"},21445:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>s,contentTitle:()=>r,default:()=>d,frontMatter:()=>o,metadata:()=>l,toc:()=>p});var i=n(87462),a=(n(67294),n(3905));const o={slug:"/deep-learning/computer-vision/cnn",id:"cnn",title:"CNN",description:"CNN"},r=void 0,l={unversionedId:"deep-learning/computer-vision/cnn/cnn",id:"deep-learning/computer-vision/cnn/cnn",title:"CNN",description:"CNN",source:"@site/docs/deep-learning/06-computer-vision/01-cnn/cnn.md",sourceDirName:"deep-learning/06-computer-vision/01-cnn",slug:"/deep-learning/computer-vision/cnn",permalink:"/cs-notes/deep-learning/computer-vision/cnn",draft:!1,editUrl:"https://github.com/glennhenry/cs-notes/tree/main/docs/deep-learning/06-computer-vision/01-cnn/cnn.md",tags:[],version:"current",lastUpdatedBy:"glennhenry",lastUpdatedAt:1695657784,formattedLastUpdatedAt:"Sep 25, 2023",frontMatter:{slug:"/deep-learning/computer-vision/cnn",id:"cnn",title:"CNN",description:"CNN"},sidebar:"sidebar",previous:{title:"Computer Vision",permalink:"/cs-notes/deep-learning/computer-vision"},next:{title:"GAN",permalink:"/cs-notes/deep-learning/computer-vision/gan"}},s={},p=[{value:"Convolution",id:"convolution",level:3},{value:"Stride",id:"stride",level:4},{value:"Padding",id:"padding",level:4},{value:"Pooling",id:"pooling",level:4},{value:"CNN",id:"cnn",level:3},{value:"Convolution",id:"convolution-1",level:4},{value:"Pooling",id:"pooling-1",level:4},{value:"Prediction",id:"prediction",level:4},{value:"Dropout",id:"dropout",level:4}],c={toc:p},u="wrapper";function d(e){let{components:t,...o}=e;return(0,a.kt)(u,(0,i.Z)({},c,o,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Main Source :")),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},(0,a.kt)("a",{parentName:"strong",href:"https://youtu.be/htiNBPxcXgo?si=qlgBDGouIRZRMArx"},"Deep learning lesson 8 - fast.ai"))),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},(0,a.kt)("a",{parentName:"strong",href:"https://youtu.be/YRhxdVk_sIs?si=Y3nwjS7h7hPpLCKa"},"Convolutional Neural Networks (CNNs) explained - deeplizard"))),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},(0,a.kt)("a",{parentName:"strong",href:"https://youtu.be/py5byOOHZM8?si=vOrMlnIPxELIyORA"},"CNN: Convolutional Neural Networks Explained - Computerphile")))),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Convolutional Neural Network(CNN)")," is a type of ",(0,a.kt)("a",{parentName:"p",href:"/deep-learning/neural-network"},"neural network")," that is specifically designed for processing grid-like data such as images."),(0,a.kt)("h3",{id:"convolution"},"Convolution"),(0,a.kt)("p",null,"Convolution is the process of combining two function to produce a third function. In the context of image processing, a mathematical function will be applied to an image and it will produce another image."),(0,a.kt)("p",null,"The function applied to image is called ",(0,a.kt)("strong",{parentName:"p"},"kernel")," or ",(0,a.kt)("strong",{parentName:"p"},(0,a.kt)("a",{parentName:"strong",href:"/computer-graphics/signal-processing#image-filters"},"filters")),". The function is a small square matrix with some numerical values. Convolution operation is when the kernel is applied to image by sliding it and performing a multiplication (dot product) between the number in matrix and the pixel value in the image. The resulting product wil be summed up and it will result in another image."),(0,a.kt)("p",null,(0,a.kt)("img",{alt:"GIF of convolution process",src:n(7242).Z,width:"535",height:"299"}),(0,a.kt)("br",{parentName:"p"}),"\n","Source : ",(0,a.kt)("a",{parentName:"p",href:"https://towardsdatascience.com/computer-vision-convolution-basics-2d0ae3b79346"},"https://towardsdatascience.com/computer-vision-convolution-basics-2d0ae3b79346")),(0,a.kt)("p",null,"Following the nature of dot product, the choice of values in matrix will determine the result of convolution process. For example, the sharpen filters has high value in the central pixel and negative values in the neighbouring pixels. This enhances the difference between central pixel and its neighbours, making it receive higher emphasis leading to a sharpened appearance."),(0,a.kt)("p",null,(0,a.kt)("img",{alt:"Kernel example",src:n(64735).Z,width:"557",height:"675"}),(0,a.kt)("br",{parentName:"p"}),"\n","Source : ",(0,a.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Kernel_(image_processing)"},"https://en.wikipedia.org/wiki/Kernel_(image_processing)")),(0,a.kt)("h4",{id:"stride"},"Stride"),(0,a.kt)("p",null,"While doing convolution, we can adjust how the process is done. ",(0,a.kt)("strong",{parentName:"p"},"Stride")," is the hyperparameter used to determine the movement of the kernel while doing the convolution operation, it can be thought as the step size."),(0,a.kt)("p",null,"Like the image below, stride is used to skip some pixel value, this will make the resulting image size different."),(0,a.kt)("p",null,(0,a.kt)("img",{alt:"Stride",src:n(90417).Z,width:"700",height:"224"}),(0,a.kt)("br",{parentName:"p"}),"\n","Source : ",(0,a.kt)("a",{parentName:"p",href:"https://www.codingninjas.com/studio/library/convolution-layer-padding-stride-and-pooling-in-cnn"},"https://www.codingninjas.com/studio/library/convolution-layer-padding-stride-and-pooling-in-cnn")),(0,a.kt)("h4",{id:"padding"},"Padding"),(0,a.kt)("p",null,"Another hyperparamter of convolution is padding. Padding is additional pixel added around the image. The pixels at border have less neighbour than other pixels in the center, this can make the resulting image biased towards the central pixels. By adding padding, pixels in the border can be more balance."),(0,a.kt)("p",null,"Another purpose is to reduce information loss, while applying kernel to the image, the border pixels can't be on the center of the kernel, this can result in information loss at the borders."),(0,a.kt)("p",null,(0,a.kt)("img",{alt:"Padding of zeros",src:n(60523).Z,width:"552",height:"324"}),(0,a.kt)("br",{parentName:"p"}),"\n","Source : ",(0,a.kt)("a",{parentName:"p",href:"https://www.numpyninja.com/post/how-padding-helps-in-cnn"},"https://www.numpyninja.com/post/how-padding-helps-in-cnn")," (with modification)"),(0,a.kt)("h4",{id:"pooling"},"Pooling"),(0,a.kt)("p",null,"Pooling is the process of downsampling or reducing the dimension of features. Color of image is considered as features, as it provide information about image. In the case of CNN, pooling is done to reduce the image size, this is done by taking the representation of image. Example of pooling technique is the max-pooling, which takes the largest values in a region."),(0,a.kt)("p",null,"Reducing the features is useful in CNN to help it focuses on some patterns and relationship between features."),(0,a.kt)("p",null,(0,a.kt)("img",{alt:"Max pooling",src:n(6347).Z,width:"589",height:"215"}),(0,a.kt)("br",{parentName:"p"}),"\n","Source : ",(0,a.kt)("a",{parentName:"p",href:"https://www.geeksforgeeks.org/cnn-introduction-to-pooling-layer/"},"https://www.geeksforgeeks.org/cnn-introduction-to-pooling-layer/")),(0,a.kt)("h3",{id:"cnn"},"CNN"),(0,a.kt)("p",null,"CNN is specialized type of neural network used for image analysis, CNN typically consists of 4 different layer. Same as traditional neural network, these layer are connected together and will pass its result to next layer."),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("strong",{parentName:"p"},"Input Layer")," : Input of CNN is an image in the form of number which is the representation of the image color. Input layer typically expect : ","[batch_size, channels, width, height]",", where width and height is the size of image, channels represent how many color channel in the image (e.g. RGB image means 3 channel), and batch_size is the number of image processed together in a single forward and backward pass.")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("strong",{parentName:"p"},"Convolutional Layer")," : Which is the layer that performs convolution operation explained above. So instead of multiplying input data by weights as we did in traditional neural network, CNN does convolution process to the input data which is the image in numerical representation then pass it onto the next layer that does convolution again. The convolution layer may also include an ",(0,a.kt)("a",{parentName:"p",href:"/deep-learning/deep-learning-foundation#activation-function"},"activation function"),".")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("strong",{parentName:"p"},"Pooling Layer")," : Pooling layer that does the pooling process to reduce the image dimension. The pooling layer reduce image size but it also take the representation of the overall image. Each neuron in pooling layer will capture different representation of image depending on the input.")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("strong",{parentName:"p"},"Fully Connected Layer")," : The fully connected layers are the same layers as the traditional neural network. After extracting the information from image from convolution and pooling layer, this layer is responsible for making prediction."))),(0,a.kt)("p",null,(0,a.kt)("img",{alt:"CNN Layers",src:n(40776).Z,width:"673",height:"260"}),(0,a.kt)("br",{parentName:"p"}),"\n","Source : ",(0,a.kt)("a",{parentName:"p",href:"https://developersbreach.com/convolution-neural-network-deep-learning/"},"https://developersbreach.com/convolution-neural-network-deep-learning/")),(0,a.kt)("h4",{id:"convolution-1"},"Convolution"),(0,a.kt)("p",null,"The input data will be an image in the form of its pixel colors. Convolution process will be done into the input data, however, the filter used here is a matrix that consist of random numbers. The convolution process is the same as above explanation, this will produce another image."),(0,a.kt)("p",null,"These filter allows us to detect low-level patterns. The first convolution process may won't be able to capture important patterns or features. However, these numbers will be adjusted later to improve the detection."),(0,a.kt)("p",null,(0,a.kt)("img",{alt:"Convolution of a number 7 image",src:n(48504).Z,width:"643",height:"214"}),(0,a.kt)("br",{parentName:"p"}),"\n","Source : ",(0,a.kt)("a",{parentName:"p",href:"https://youtu.be/YRhxdVk_sIs?si=ZLAexy3x4VYMjQ0E&t=347"},"https://youtu.be/YRhxdVk_sIs?si=ZLAexy3x4VYMjQ0E&t=347")),(0,a.kt)("p",null,"Some of the filters in the convolution maybe are supposed to detect edges, other may supposed to detect curve, and etc."),(0,a.kt)("p",null,(0,a.kt)("img",{alt:"Overall layer of abstraction",src:n(58994).Z,width:"518",height:"711"}),(0,a.kt)("br",{parentName:"p"}),"\n","Source : ",(0,a.kt)("a",{parentName:"p",href:"https://www.analyticsvidhya.com/blog/2022/03/basic-introduction-to-convolutional-neural-network-in-deep-learning/"},"https://www.analyticsvidhya.com/blog/2022/03/basic-introduction-to-convolutional-neural-network-in-deep-learning/")),(0,a.kt)("p",null,"The number of output image depends on the number of filter use. When we say 32 filter, this mean we have 32 distinct matrix with its own numbers. Each filter will be applied to the image, therefore producing 32 different image, the result is called ",(0,a.kt)("strong",{parentName:"p"},"feature maps")," as it is actually not a separate image, just a different form of image. (note: each conv layer can have different number of filter)"),(0,a.kt)("p",null,"When we connect the layer together, we may have than 1 input image or feature maps. In this case, the convolution process works by applying a single filter in the next layer to all the feature maps from the previous layer, and the results are summed to generate a single feature map. This process is repeated for each filter in the second layer."),(0,a.kt)("p",null,"The notation for convolution layer is (numberOfFilter x imageWidth x imageHeight). The input image image is typically separated by its color channel, so red, green, and blue color of the image is processed separately."),(0,a.kt)("p",null,(0,a.kt)("img",{alt:"Convolution with 6 filter",src:n(21052).Z,width:"637",height:"222"}),(0,a.kt)("br",{parentName:"p"}),"\n","Source : ",(0,a.kt)("a",{parentName:"p",href:"https://youtu.be/pj9-rr1wDhM?si=-7Fnrb2DpTa71Jo8&t=450"},"https://youtu.be/pj9-rr1wDhM?si=-7Fnrb2DpTa71Jo8&t=450")),(0,a.kt)("h4",{id:"pooling-1"},"Pooling"),(0,a.kt)("p",null,"Pooling is done to reduce the image dimension, which also reduces the features of the image. It can be thought as summarizing the whole image in a smaller dimension that consist of pixel that represent the overall image or called ",(0,a.kt)("strong",{parentName:"p"},"feature extraction"),"."),(0,a.kt)("p",null,"This layer doesn't have adjustable parameters, it is a fixed process."),(0,a.kt)("p",null,(0,a.kt)("img",{alt:"Pooling layer",src:n(87952).Z,width:"685",height:"385"}),(0,a.kt)("br",{parentName:"p"}),"\n","Source : ",(0,a.kt)("a",{parentName:"p",href:"https://youtu.be/pj9-rr1wDhM?si=-7Fnrb2DpTa71Jo8&t=450"},"https://youtu.be/pj9-rr1wDhM?si=-7Fnrb2DpTa71Jo8&t=450")),(0,a.kt)("h4",{id:"prediction"},"Prediction"),(0,a.kt)("p",null,"After receiving result from the last layer convolution or pooling layer, the fully connected layer will make prediction. The result from previous layer will first be flattened into one-dimensional vector. This will combine the result from all the filter that does different detection."),(0,a.kt)("p",null,"From now on, how will the network works is same as traditional neural network, it consist of weight, bias, and activation function. After reaching the last layers, it can now make prediction. In this step, ",(0,a.kt)("a",{parentName:"p",href:"/deep-learning/deep-learning-foundation#loss-function"},"loss function")," will be calculated, the specific function depends on the task."),(0,a.kt)("p",null,"After calculating the loss, it's time for the model to learn with backpropagation technique. Gradient of the loss function will be calculated with respect to each parameters, including fully connected layer weights and the coefficient in the filter matrix. Gradients with respect to the filters are calculated and used to update the filter weights."),(0,a.kt)("p",null,"The input in the fully connected layer is based on the previous layer, the previous layer is also based on the previous layer, backward pass will be done adjusting all adjustable parameter."),(0,a.kt)("h4",{id:"dropout"},"Dropout"),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Dropout")," is a data augmentation techinique to reduce overfitting in neural network by deactivating some neuron in the layer. Dropout can be thought as discarding some random color in an image. The idea of dropout is, we human, still able to recognize corrupted image. Computer should also know how to recognize these."),(0,a.kt)("p",null,(0,a.kt)("img",{alt:"Dropout deactivting neurons",src:n(76794).Z,width:"534",height:"277"}),(0,a.kt)("br",{parentName:"p"}),"\n","Source : ",(0,a.kt)("a",{parentName:"p",href:"https://www.researchgate.net/figure/9-An-illustration-of-the-dropout-mechanism-within-the-proposed-CNN-a-Shows-a_fig23_317277576"},"https://www.researchgate.net/figure/9-An-illustration-of-the-dropout-mechanism-within-the-proposed-CNN-a-Shows-a_fig23_317277576")))}d.isMDXComponent=!0},21052:(e,t,n)=>{n.d(t,{Z:()=>i});const i=n.p+"assets/images/6-convolution-filter-a67781b2cf970bde2a86db40aaae1d01.png"},40776:(e,t,n)=>{n.d(t,{Z:()=>i});const i=n.p+"assets/images/cnn-layer-f1ef1f8a21ce9dc9f41b8afc58e9e866.png"},48504:(e,t,n)=>{n.d(t,{Z:()=>i});const i=n.p+"assets/images/convolution-layer-72e8624e6b8efdfd5e3657a64e792362.png"},7242:(e,t,n)=>{n.d(t,{Z:()=>i});const i=n.p+"assets/images/convolution-66c6bb6fe67d91be117f81b75840dd65.gif"},76794:(e,t,n)=>{n.d(t,{Z:()=>i});const i=n.p+"assets/images/dropout-271b2db2b4464507ee27fcedc40a3657.png"},64735:(e,t,n)=>{n.d(t,{Z:()=>i});const i=n.p+"assets/images/kernel-example-77b7d160aee9f38ad3434fa23f1150ac.png"},58994:(e,t,n)=>{n.d(t,{Z:()=>i});const i=n.p+"assets/images/overall-layer-2258b5febd8c07dd29a8ecdaa34534c4.png"},60523:(e,t,n)=>{n.d(t,{Z:()=>i});const i=n.p+"assets/images/padding-b283a409e9c4dbca630bb490cdb62579.png"},87952:(e,t,n)=>{n.d(t,{Z:()=>i});const i=n.p+"assets/images/pooling-layer-c3758162cfd3d19da630e1185384c073.png"},6347:(e,t,n)=>{n.d(t,{Z:()=>i});const i=n.p+"assets/images/pooling-171c1b5a2c107b675df2c8f54df06b6b.png"},90417:(e,t,n)=>{n.d(t,{Z:()=>i});const i=n.p+"assets/images/stride-9d826ff97f607604af5cf0a5910bb792.png"}}]);