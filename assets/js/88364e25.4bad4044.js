"use strict";(self.webpackChunkcs_notes=self.webpackChunkcs_notes||[]).push([[3555],{52678:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>r,default:()=>g,frontMatter:()=>s,metadata:()=>o,toc:()=>l});var i=t(85893),a=t(11151);const s={slug:"/compilers/scanning",id:"scanning",title:"Scanning",description:"Scanning"},r=void 0,o={id:"compilers/scanning/scanning",title:"Scanning",description:"Scanning",source:"@site/docs/compilers/03-scanning/scanning.md",sourceDirName:"compilers/03-scanning",slug:"/compilers/scanning",permalink:"/cs-notes/compilers/scanning",draft:!1,unlisted:!1,editUrl:"https://github.com/glennhenry/cs-notes/tree/main/docs/compilers/03-scanning/scanning.md",tags:[],version:"current",lastUpdatedBy:"glennhenry",lastUpdatedAt:1714543168e3,frontMatter:{slug:"/compilers/scanning",id:"scanning",title:"Scanning",description:"Scanning"},sidebar:"sidebar",previous:{title:"Syntax",permalink:"/cs-notes/compilers/syntax"},next:{title:"Parsing",permalink:"/cs-notes/compilers/parsing"}},c={},l=[];function h(e){const n={a:"a",admonition:"admonition",br:"br",img:"img",li:"li",p:"p",strong:"strong",ul:"ul",...(0,a.a)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Main Source :"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.strong,{children:"Chapter 2, Programming Language Pragmatics - Michael L. Scott"})}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.a,{href:"/programming-language-theory/syntax",children:"This note on programming language theory"})," discuss how syntax is specified. After writing source code in certain syntax, the next process is ",(0,i.jsx)(n.a,{href:"/compilers/parsing",children:"parsing"}),". It is the process of analyzing if the structure of a sequence of symbols follows the rules of a formal grammar correctly."]}),"\n",(0,i.jsxs)(n.p,{children:["Before parsing, a step called ",(0,i.jsx)(n.strong,{children:"scanning"})," occurs. This involves dividing the sequence of characters (e.g., source code) into meaningful units called tokens. Each token is then identified according to its category (e.g., keyword, identifier, literals), and parsing occurs afterwards."]}),"\n",(0,i.jsx)(n.admonition,{type:"info",children:(0,i.jsxs)(n.p,{children:["Scanning is the first step in ",(0,i.jsx)(n.a,{href:"/programming-language-theory/plt-fundamentals#compilation-process",children:"compilation process"}),", while parsing is the second step."]})}),"\n",(0,i.jsx)(n.p,{children:"The purpose of scanning is to simplify the input by removing meaningless comments for the parser and eliminating whitespace (e.g., spaces, tabs, carriage returns, newlines) to reduce input complexity, while preserving only the important tokens."}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.img,{alt:"Scanning algorithm for Pascal",src:t(31224).Z+"",width:"453",height:"470"}),(0,i.jsx)(n.br,{}),"\n","Source : Book page 48"]}),"\n",(0,i.jsx)(n.p,{children:"Above is the outline of scanner algorithm in Pascal programming language. Although it is from a specific language, the similar approach can be used for others. In general, the algorithm should ignore any white spaces. If it encounters unique symbols, it checks the symbol table if it is meaningful for the language. If some keywords are not from the language, it could be user-defined identifier, the compiler will also keep track of this."}),"\n",(0,i.jsxs)(n.p,{children:["The deterministic behavior of scanner can be described with a ",(0,i.jsx)(n.a,{href:"/theory-of-computation-and-automata/finite-automata",children:"finite automaton"})," like ",(0,i.jsx)(n.a,{href:"/theory-of-computation-and-automata/finite-automata#dfa",children:"DFA"}),". Deterministic means the system will always know what to do when it encounters any input. The automaton starts with an initial state, then it transitions to other state depending on the symbol encountered. If it reaches a final state, it means it has recognized some token."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.img,{alt:"Finite automaton of Pascal scanner",src:t(26777).Z+"",width:"482",height:"528"}),(0,i.jsx)(n.br,{}),"\n","Source : Book page 49"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.a,{href:"#regular-expression",children:"Regular expression"})," is used to define the lexical rules or patterns that a scanner should recognize. This is why earlier we mentioned that regular expressions are helpful in defining tokens, as they are used to specify the patterns that scanner recognizes."]}),"\n",(0,i.jsxs)(n.p,{children:["Since a scanner reflects a finite automaton, creating a scanner specified with a regular expression involves converting the regular expression into an equivalent finite automaton. The regular expression is converted into an ",(0,i.jsx)(n.a,{href:"/theory-of-computation-and-automata/finite-automata#nfa",children:"NFA"})," first, then converted into a DFA. Optionally, we may ",(0,i.jsx)(n.a,{href:"/theory-of-computation-and-automata/finite-automata#minimization",children:"minimize the DFA"})," to reduce the number of states."]}),"\n",(0,i.jsx)(n.admonition,{type:"tip",children:(0,i.jsxs)(n.p,{children:["See ",(0,i.jsx)(n.a,{href:"/theory-of-computation-and-automata/regular-languages-part-2#regular-expression-to-finite-automata",children:"regular expression to finite automata"})," for an abstract example."]})}),"\n",(0,i.jsxs)(n.p,{children:["The practical way of designing a scanner is making our own regular expression based on the language syntax, then use a ",(0,i.jsx)(n.strong,{children:"scanner generator"}),". A scanner generator will generate the logic to tokenize the input source code based on the defined lexical rules. The actual code for scanner may involve the use of switch statement and nested loop to simulate an automaton behavior."]}),"\n",(0,i.jsxs)(n.p,{children:["Obviously, potential error will occur during scanning, this is called ",(0,i.jsx)(n.strong,{children:"lexical error"}),". It can arise from invalid characters, unrecognized character sequences, or violations of the language's lexical rules. The scanner may stop the scanning and report the error to user or ignoring the invalid token and continuing the scanning process."]})]})}function g(e={}){const{wrapper:n}={...(0,a.a)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(h,{...e})}):h(e)}},26777:(e,n,t)=>{t.d(n,{Z:()=>i});const i=t.p+"assets/images/finite-automaton-76a32f1aeabc4a4d5bb550fb2e449604.png"},31224:(e,n,t)=>{t.d(n,{Z:()=>i});const i=t.p+"assets/images/scanning-2039c23a992ac7aee697c2377331995b.png"},11151:(e,n,t)=>{t.d(n,{Z:()=>o,a:()=>r});var i=t(67294);const a={},s=i.createContext(a);function r(e){const n=i.useContext(s);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:r(e.components),i.createElement(s.Provider,{value:n},e.children)}}}]);