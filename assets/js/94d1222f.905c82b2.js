"use strict";(self.webpackChunkcs_notes=self.webpackChunkcs_notes||[]).push([[5100],{22566:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>r,default:()=>u,frontMatter:()=>a,metadata:()=>d,toc:()=>l});var s=t(85893),i=t(11151);const a={slug:"/cloud-computing-and-distributed-systems/mapreduce",id:"mapreduce",title:"MapReduce",description:"MapReduce"},r=void 0,d={id:"cloud-computing-and-distributed-systems/mapreduce/mapreduce",title:"MapReduce",description:"MapReduce",source:"@site/docs/cloud-computing-and-distributed-systems/11-mapreduce/mapreduce.md",sourceDirName:"cloud-computing-and-distributed-systems/11-mapreduce",slug:"/cloud-computing-and-distributed-systems/mapreduce",permalink:"/cs-notes/cloud-computing-and-distributed-systems/mapreduce",draft:!1,unlisted:!1,editUrl:"https://github.com/glennhenry/cs-notes/tree/main/docs/cloud-computing-and-distributed-systems/11-mapreduce/mapreduce.md",tags:[],version:"current",lastUpdatedBy:"glennhenry",lastUpdatedAt:1712495182,formattedLastUpdatedAt:"Apr 7, 2024",frontMatter:{slug:"/cloud-computing-and-distributed-systems/mapreduce",id:"mapreduce",title:"MapReduce",description:"MapReduce"},sidebar:"sidebar",previous:{title:"Microservice",permalink:"/cs-notes/cloud-computing-and-distributed-systems/microservice"},next:{title:"Lambda",permalink:"/cs-notes/cloud-computing-and-distributed-systems/lambda"}},c={},l=[{value:"Map &amp; Reduce",id:"map--reduce",level:3},{value:"MapReduce Operations",id:"mapreduce-operations",level:3},{value:"Benefits",id:"benefits",level:3}];function o(e){const n={a:"a",br:"br",code:"code",em:"em",h3:"h3",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.a)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Main Source :"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/MapReduce",children:"MapReduce - Wikipedia"})})}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"MapReduce"})," is a programming model or framework designed for processing and analyzing large-scale data sets in parallel across a distributed cluster of computers. It is also used in Apache Hadoop framework."]}),"\n",(0,s.jsx)(n.h3,{id:"map--reduce",children:"Map & Reduce"}),"\n",(0,s.jsxs)(n.p,{children:["MapReduce is inspired from ",(0,s.jsx)(n.em,{children:"map"})," and ",(0,s.jsx)(n.em,{children:"reduce"})," from functional programming"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Map"})," : A map operation applies a given function to each element of a collection and returns a new collection containing the transformed elements."]}),"\n",(0,s.jsx)(n.p,{children:"A simple usage of map in Kotlin :"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-kotlin",children:"fun main() {\n    val numbers = listOf(1, 2, 3, 4, 5)\n    val squaredNumbers = numbers.map { num -> num * num }\n    println(squaredNumbers.joinToString()) // Output: 1, 4, 9, 16, 25\n}\n"})}),"\n",(0,s.jsxs)(n.p,{children:["The given function is a lambda, which is defined inside the braces. It takes an input that we call ",(0,s.jsx)(n.code,{children:"num"}),", and it will square that number to produce a result. This is done for each element in the collection."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Reduce or Fold"})," : A reduce combines the elements of a collection into a single value by repeatedly applying a binary function to pairs of elements. As a result, it reduces the collection to a single value."]}),"\n",(0,s.jsx)(n.p,{children:"Another usage in Kotlin :"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-Kotlin",children:"fun main() {\n    val numbers = listOf(1, 2, 3, 4, 5)\n    val accumulation = numbers.reduce { accumulatedSoFar, nextNum -> accumulatedSoFar + nextNum }\n    println(accumulation) // Output: 15\n}\n"})}),"\n",(0,s.jsxs)(n.p,{children:["The reduce function takes two parameters, the first being value accumulated so far (or initially), and the second being the value we are currently processing. At first, ",(0,s.jsx)(n.code,{children:"accumulatedSoFar"})," will be 0 and ",(0,s.jsx)(n.code,{children:"nextNum"})," is 1, next ",(0,s.jsx)(n.code,{children:"accumulatedSoFar"})," will be 1 (because 0 + 1 = 1), and ",(0,s.jsx)(n.code,{children:"nextNum"})," is 2. This is done until we reach the last element."]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"mapreduce-operations",children:"MapReduce Operations"}),"\n",(0,s.jsx)(n.p,{children:"MapReduce system typically consist of three operations or steps :"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Map"})," : Each node in the distributed system owns a subset of data locally, which are possibly messy. Each data will be associated with a key-value pair, with the key being the unique identifier of the data, and the value is the actual data. A map function is applied to the data independently based on the keys and in parallel, producing an intermediate key-value pairs as output."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Shuffle"})," : The intermediate key-value pairs are partitioned based on their keys and distributed across the cluster. This will make the data with a particular key all contained within the same node."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Reduce"})," : The reduce function is applied to each unique key and its associated set of intermediate values. The reduce function aggregates, combines, or analyzes the intermediate values for each key and produces final output key-value pairs. The final output key-value pairs are collected and stored in the desired output location (or combined)."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.img,{alt:"MapReduce operations",src:t(97887).Z+"",width:"639",height:"397"}),(0,s.jsx)(n.br,{}),"\n","Source : ",(0,s.jsx)(n.a,{href:"https://datascientest.com/en/mapreduce-how-to-use-it-for-big-data",children:"https://datascientest.com/en/mapreduce-how-to-use-it-for-big-data"})]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"benefits",children:"Benefits"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Performance"})," : As emphasized before, MapReduce operation is done in parallel, dedicated to handle large data datasets and complex computations."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Scalability"})," : Allows for horizontal scale, increasing more machines to enhance the parallel processing."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Fault Tolerance"})," : Classic benefits of distributed system, when a node fails during processing, we can redistribute the work to other available nodes, ensuring fault tolerance and continuous execution."]}),"\n"]})]})}function u(e={}){const{wrapper:n}={...(0,i.a)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(o,{...e})}):o(e)}},97887:(e,n,t)=>{t.d(n,{Z:()=>s});const s=t.p+"assets/images/mapreduce-46ef1ffde7045774fb907ee140bfea11.png"},11151:(e,n,t)=>{t.d(n,{Z:()=>d,a:()=>r});var s=t(67294);const i={},a=s.createContext(i);function r(e){const n=s.useContext(a);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function d(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:r(e.components),s.createElement(a.Provider,{value:n},e.children)}}}]);