"use strict";(self.webpackChunkcs_notes=self.webpackChunkcs_notes||[]).push([[6523],{27060:(e,n,s)=>{s.d(n,{A:()=>i});const i=s.p+"assets/images/speech-recognition-506e94627e0a8401a83b630ec9979538.png"},28453:(e,n,s)=>{s.d(n,{R:()=>r,x:()=>c});var i=s(96540);const t={},o=i.createContext(t);function r(e){const n=i.useContext(o);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:r(e.components),i.createElement(o.Provider,{value:n},e.children)}},96642:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>a,contentTitle:()=>c,default:()=>g,frontMatter:()=>r,metadata:()=>i,toc:()=>l});const i=JSON.parse('{"id":"digital-media-processing/speech-processing/speech-processing","title":"Speech Processing","description":"Speech Processing","source":"@site/docs/digital-media-processing/11-speech-processing/speech-processing.md","sourceDirName":"digital-media-processing/11-speech-processing","slug":"/digital-media-processing/speech-processing","permalink":"/cs-notes/digital-media-processing/speech-processing","draft":false,"unlisted":false,"editUrl":"https://github.com/glennhenry/cs-notes/tree/main/docs/digital-media-processing/11-speech-processing/speech-processing.md","tags":[],"version":"current","lastUpdatedBy":"glennhenry","lastUpdatedAt":1723296077000,"frontMatter":{"slug":"/digital-media-processing/speech-processing","id":"speech-processing","title":"Speech Processing","description":"Speech Processing"},"sidebar":"sidebar","previous":{"title":"Audio Editing","permalink":"/cs-notes/digital-media-processing/audio-editing"},"next":{"title":"Video Representation","permalink":"/cs-notes/digital-media-processing/video-representation"}}');var t=s(74848),o=s(28453);const r={slug:"/digital-media-processing/speech-processing",id:"speech-processing",title:"Speech Processing",description:"Speech Processing"},c=void 0,a={},l=[];function d(e){const n={a:"a",admonition:"admonition",br:"br",img:"img",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Main Source:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.strong,{children:"Various source from Google and YouTube"})}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Speech processing"})," is the analysis, synthesis, and understanding of spoken language. It involves various techniques and algorithms including speech recognition, speech synthesis, speaker recognition, and speech enhancement. Speech processing involves a lot of ",(0,t.jsx)(n.a,{href:"/machine-learning",children:"machine learning"})," and ",(0,t.jsx)(n.a,{href:"/deep-learning",children:"deep learning"})," techniques."]}),"\n",(0,t.jsx)(n.p,{children:"Speech processing involves some steps, here is a high-level overview:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Speech Capturing"}),": The first thing is to capture the speech sound signal using recording devices like microphone. Analog sound signal will be converted into digital signal using an analog-to-digital converter (ADC)."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Pre-processing"}),": Digital signal is then pre-processed, this may include enhancing quality, such as ",(0,t.jsx)(n.a,{href:"/digital-signal-processing/filtering",children:"filtering"}),", ",(0,t.jsx)(n.a,{href:"/digital-signal-processing/denoising",children:"noise reduction"}),", and removing unwanted elements like background noise."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Feature Extraction"}),": Feature extraction means we identify and capture sound characteristics such as loudness, pitch, rhythm. This will be give us more information which will be useful later on."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Speech Recognition"}),": This is the main process of speech processing, it includes:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Acoustics Modeling: Predict the likelihood of a specific word or phrase being spoken given the current state of the audio signal based on probability. For example, in the English language, after a subject is spoken, a verb will have a higher chance than an adjective to be spoken next."}),"\n",(0,t.jsx)(n.li,{children:"Language Modeling: Language modeling uses statistical properties and patterns of natural language to predict the next word or phrase that is likely to be spoken. The machine learning language model is trained a lot of text data."}),"\n",(0,t.jsx)(n.li,{children:"Decoding: In the decoding stage, the acoustic, and language models are combined to find the most likely sequence of words that matches the speech input."}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.img,{alt:"Flowchart of speech processing and a sound signal is identified as hello",src:s(27060).A+"",width:"624",height:"320"}),(0,t.jsx)(n.br,{}),"\n","Source: ",(0,t.jsx)(n.a,{href:"https://www.kardome.com/blog-posts/difference-speech-and-voice-recognition",children:"https://www.kardome.com/blog-posts/difference-speech-and-voice-recognition"})]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.admonition,{type:"tip",children:(0,t.jsxs)(n.p,{children:["See also ",(0,t.jsx)(n.a,{href:"/deep-learning/deep-learning-tasks#natural-language-processing-nlp",children:"natural language processing (NLP)"}),"."]})})]})}function g(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}}}]);