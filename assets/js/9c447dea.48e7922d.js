"use strict";(self.webpackChunkcs_notes=self.webpackChunkcs_notes||[]).push([[5857],{3905:(a,e,t)=>{t.d(e,{Zo:()=>l,kt:()=>N});var s=t(67294);function n(a,e,t){return e in a?Object.defineProperty(a,e,{value:t,enumerable:!0,configurable:!0,writable:!0}):a[e]=t,a}function i(a,e){var t=Object.keys(a);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(a);e&&(s=s.filter((function(e){return Object.getOwnPropertyDescriptor(a,e).enumerable}))),t.push.apply(t,s)}return t}function m(a){for(var e=1;e<arguments.length;e++){var t=null!=arguments[e]?arguments[e]:{};e%2?i(Object(t),!0).forEach((function(e){n(a,e,t[e])})):Object.getOwnPropertyDescriptors?Object.defineProperties(a,Object.getOwnPropertyDescriptors(t)):i(Object(t)).forEach((function(e){Object.defineProperty(a,e,Object.getOwnPropertyDescriptor(t,e))}))}return a}function r(a,e){if(null==a)return{};var t,s,n=function(a,e){if(null==a)return{};var t,s,n={},i=Object.keys(a);for(s=0;s<i.length;s++)t=i[s],e.indexOf(t)>=0||(n[t]=a[t]);return n}(a,e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(a);for(s=0;s<i.length;s++)t=i[s],e.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(a,t)&&(n[t]=a[t])}return n}var p=s.createContext({}),o=function(a){var e=s.useContext(p),t=e;return a&&(t="function"==typeof a?a(e):m(m({},e),a)),t},l=function(a){var e=o(a.components);return s.createElement(p.Provider,{value:e},a.children)},c="mdxType",d={inlineCode:"code",wrapper:function(a){var e=a.children;return s.createElement(s.Fragment,{},e)}},h=s.forwardRef((function(a,e){var t=a.components,n=a.mdxType,i=a.originalType,p=a.parentName,l=r(a,["components","mdxType","originalType","parentName"]),c=o(t),h=n,N=c["".concat(p,".").concat(h)]||c[h]||d[h]||i;return t?s.createElement(N,m(m({ref:e},l),{},{components:t})):s.createElement(N,m({ref:e},l))}));function N(a,e){var t=arguments,n=e&&e.mdxType;if("string"==typeof a||n){var i=t.length,m=new Array(i);m[0]=h;var r={};for(var p in e)hasOwnProperty.call(e,p)&&(r[p]=e[p]);r.originalType=a,r[c]="string"==typeof a?a:n,m[1]=r;for(var o=2;o<i;o++)m[o]=t[o];return s.createElement.apply(null,m)}return s.createElement.apply(null,t)}h.displayName="MDXCreateElement"},44454:(a,e,t)=>{t.r(e),t.d(e,{assets:()=>p,contentTitle:()=>m,default:()=>d,frontMatter:()=>i,metadata:()=>r,toc:()=>o});var s=t(87462),n=(t(67294),t(3905));const i={slug:"/deep-learning/diffusion/diffusion-model",id:"diffusion-model",title:"Diffusion Model",description:"Diffusion Model"},m=void 0,r={unversionedId:"deep-learning/diffusion/diffusion-model/diffusion-model",id:"deep-learning/diffusion/diffusion-model/diffusion-model",title:"Diffusion Model",description:"Diffusion Model",source:"@site/docs/deep-learning/15-diffusion/01-diffusion-model/diffusion-model.md",sourceDirName:"deep-learning/15-diffusion/01-diffusion-model",slug:"/deep-learning/diffusion/diffusion-model",permalink:"/cs-notes/deep-learning/diffusion/diffusion-model",draft:!1,editUrl:"https://github.com/glennhenry/cs-notes/tree/main/docs/deep-learning/15-diffusion/01-diffusion-model/diffusion-model.md",tags:[],version:"current",lastUpdatedBy:"glennhenry",lastUpdatedAt:1697540755,formattedLastUpdatedAt:"Oct 17, 2023",frontMatter:{slug:"/deep-learning/diffusion/diffusion-model",id:"diffusion-model",title:"Diffusion Model",description:"Diffusion Model"},sidebar:"sidebar",previous:{title:"Vision Transformers",permalink:"/cs-notes/deep-learning/transformers/vision-transformers"},next:{title:"Stable Diffusion",permalink:"/cs-notes/deep-learning/diffusion/stable-diffusion"}},p={},o=[{value:"Denoising Diffusion Model",id:"denoising-diffusion-model",level:2},{value:"Denoising Diffusion Probabilistic Model (DDPM)",id:"denoising-diffusion-probabilistic-model-ddpm",level:3},{value:"Forward Process",id:"forward-process",level:4},{value:"Reverse Process",id:"reverse-process",level:4},{value:"Training Objective",id:"training-objective",level:4},{value:"Summary",id:"summary",level:4},{value:"Denoising Diffusion Implicit Models (DDIM)",id:"denoising-diffusion-implicit-models-ddim",level:3},{value:"Conditional &amp; Unconditional Generation",id:"conditional--unconditional-generation",level:3},{value:"Unconditional",id:"unconditional",level:4},{value:"Conditional",id:"conditional",level:4},{value:"Score-Based Diffusion Model (SBDM)",id:"score-based-diffusion-model-sbdm",level:2},{value:"Latent Diffusion Model (LDM)",id:"latent-diffusion-model-ldm",level:2}],l={toc:o},c="wrapper";function d(a){let{components:e,...i}=a;return(0,n.kt)(c,(0,s.Z)({},l,i,{components:e,mdxType:"MDXLayout"}),(0,n.kt)("p",null,(0,n.kt)("strong",{parentName:"p"},"Main Source :")),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},(0,n.kt)("a",{parentName:"strong",href:"https://en.wikipedia.org/wiki/Diffusion_model"},"Wikipedia Diffusion model"))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},(0,n.kt)("a",{parentName:"strong",href:"https://youtu.be/fbLgFrlTnGU?si=tR6le4piBvVpeR_9"},"What are Diffusion Models? - Ari Seff"))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},(0,n.kt)("a",{parentName:"strong",href:"https://www.assemblyai.com/blog/diffusion-models-for-machine-learning-introduction/"},"Introduction to Diffusion Models for Machine Learning - AssemblyAI"))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},(0,n.kt)("a",{parentName:"strong",href:"https://youtu.be/aUqbWBQTKaA?si=BONjB3Ul4iGOmy-1"},"[Lab Seminar] DDIM: Denoising Diffusion Implicit Model (ICLR, 2021) - DSAIL SKKU")))),(0,n.kt)("p",null,(0,n.kt)("strong",{parentName:"p"},"Diffusion Model")," is a class of generative model, meaning it generates new data by learning the underlying distribution of a given dataset and uses this knowledge to generate new data samples. Diffusion model is typically used for tasks including image generation, image denoising, generating high-resolution image, and etc."),(0,n.kt)("p",null,"Diffusion model is inspired by the concept of ",(0,n.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Diffusion"},"diffusion")," in physics, which is a stochastic phenomenon where particles spread out from an area of high concentration to an area of low concentration, eventually leading to a uniform concentration. The underlying principles and equations of diffusion in physics provide a mathematical foundation that is adapted and applied to model to generates data."),(0,n.kt)("p",null,"The idea of diffusion model is, we model the target image (the target image we want to generate) as a data distribution (called target distribution), and then the model will aim to transform a simple base distribution, typically a Gaussian distribution, into the target distribution through an iterative diffusion process."),(0,n.kt)("video",{width:"720",height:"360",controls:!0},(0,n.kt)("source",{src:"https://learnopencv.com/wp-content/uploads/2023/02/denoising-diffusion-probabilistic-models_flower_inference_2.mp4",type:"video/mp4"})),(0,n.kt)("p",null,"Source : ",(0,n.kt)("a",{parentName:"p",href:"https://learnopencv.com/denoising-diffusion-probabilistic-models/"},"https://learnopencv.com/denoising-diffusion-probabilistic-models/")),(0,n.kt)("h2",{id:"denoising-diffusion-model"},"Denoising Diffusion Model"),(0,n.kt)("p",null,"There are many variation of diffusion model, each with their own concept, ",(0,n.kt)("strong",{parentName:"p"},"Denoising Diffusion Model")," is the type of diffusion model that uses the diffusion concept."),(0,n.kt)("h3",{id:"denoising-diffusion-probabilistic-model-ddpm"},"Denoising Diffusion Probabilistic Model (DDPM)"),(0,n.kt)("p",null,"the type of denoising diffusion model that learns the underlying ",(0,n.kt)("strong",{parentName:"p"},"probability distribution")," of a dataset and generate new samples from that distribution."),(0,n.kt)("p",null,"The overall process of denoising diffusion model consist of two steps, the forward process that gradually add noise to the image, and the reverse process that tries to reverse the process or remove the noise to generate clean samples."),(0,n.kt)("h4",{id:"forward-process"},"Forward Process"),(0,n.kt)("p",null,"In DDPM, the noising process is modeled using a ",(0,n.kt)("a",{parentName:"p",href:"/machine-learning/reinforcement-learning/markov-models#markov-chain"},(0,n.kt)("strong",{parentName:"a"},"Markov chain")),". Markov chain is a mathematical model that assumes the future state of a system only depends on current step. In other word, the current state of a system depends only on the previous state. The key idea behind using a Markov chain in diffusion models is to describe the evolution of the system's state as an iterative stochastic process."),(0,n.kt)("p",null,"The forward process begins with adding noise to the image in gradual manner, the process will be divided into discrete time steps. The noise, we are adding is modeled using a ",(0,n.kt)("strong",{parentName:"p"},"Gaussian (normal) distribution"),". A Gaussian distribution is characterized by its mean (",(0,n.kt)("span",{parentName:"p",className:"math math-inline"},(0,n.kt)("span",{parentName:"span",className:"katex"},(0,n.kt)("span",{parentName:"span",className:"katex-mathml"},(0,n.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,n.kt)("semantics",{parentName:"math"},(0,n.kt)("mrow",{parentName:"semantics"},(0,n.kt)("mi",{parentName:"mrow"},"\u03bc")),(0,n.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"\\mu")))),(0,n.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,n.kt)("span",{parentName:"span",className:"base"},(0,n.kt)("span",{parentName:"span",className:"strut",style:{height:"0.625em",verticalAlign:"-0.1944em"}}),(0,n.kt)("span",{parentName:"span",className:"mord mathnormal"},"\u03bc"))))),") and variance (",(0,n.kt)("span",{parentName:"p",className:"math math-inline"},(0,n.kt)("span",{parentName:"span",className:"katex"},(0,n.kt)("span",{parentName:"span",className:"katex-mathml"},(0,n.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,n.kt)("semantics",{parentName:"math"},(0,n.kt)("mrow",{parentName:"semantics"},(0,n.kt)("msup",{parentName:"mrow"},(0,n.kt)("mi",{parentName:"msup"},"\u03c3"),(0,n.kt)("mn",{parentName:"msup"},"2"))),(0,n.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"\\sigma^2")))),(0,n.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,n.kt)("span",{parentName:"span",className:"base"},(0,n.kt)("span",{parentName:"span",className:"strut",style:{height:"0.8141em"}}),(0,n.kt)("span",{parentName:"span",className:"mord"},(0,n.kt)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.03588em"}},"\u03c3"),(0,n.kt)("span",{parentName:"span",className:"msupsub"},(0,n.kt)("span",{parentName:"span",className:"vlist-t"},(0,n.kt)("span",{parentName:"span",className:"vlist-r"},(0,n.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.8141em"}},(0,n.kt)("span",{parentName:"span",style:{top:"-3.063em",marginRight:"0.05em"}},(0,n.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,n.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,n.kt)("span",{parentName:"span",className:"mord mtight"},"2")))))))))))),"), which determine the central tendency and spread of the distribution, respectively."),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Gaussian distribution noises",src:t(44710).Z,width:"666",height:"245"}),(0,n.kt)("br",{parentName:"p"}),"\n","Source : ",(0,n.kt)("a",{parentName:"p",href:"https://analyticsindiamag.com/a-guide-to-different-types-of-noises-and-image-denoising-methods/"},"https://analyticsindiamag.com/a-guide-to-different-types-of-noises-and-image-denoising-methods/")),(0,n.kt)("p",null,"Utilizing the Markov chain with diffusion model, the distribution of noise at some time step ",(0,n.kt)("span",{parentName:"p",className:"math math-inline"},(0,n.kt)("span",{parentName:"span",className:"katex"},(0,n.kt)("span",{parentName:"span",className:"katex-mathml"},(0,n.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,n.kt)("semantics",{parentName:"math"},(0,n.kt)("mrow",{parentName:"semantics"},(0,n.kt)("mi",{parentName:"mrow"},"t")),(0,n.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"t")))),(0,n.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,n.kt)("span",{parentName:"span",className:"base"},(0,n.kt)("span",{parentName:"span",className:"strut",style:{height:"0.6151em"}}),(0,n.kt)("span",{parentName:"span",className:"mord mathnormal"},"t")))))," only depends on previous time step ",(0,n.kt)("span",{parentName:"p",className:"math math-inline"},(0,n.kt)("span",{parentName:"span",className:"katex"},(0,n.kt)("span",{parentName:"span",className:"katex-mathml"},(0,n.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,n.kt)("semantics",{parentName:"math"},(0,n.kt)("mrow",{parentName:"semantics"},(0,n.kt)("mi",{parentName:"mrow"},"t"),(0,n.kt)("mo",{parentName:"mrow"},"\u2212"),(0,n.kt)("mn",{parentName:"mrow"},"1")),(0,n.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"t-1")))),(0,n.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,n.kt)("span",{parentName:"span",className:"base"},(0,n.kt)("span",{parentName:"span",className:"strut",style:{height:"0.6984em",verticalAlign:"-0.0833em"}}),(0,n.kt)("span",{parentName:"span",className:"mord mathnormal"},"t"),(0,n.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2222em"}}),(0,n.kt)("span",{parentName:"span",className:"mbin"},"\u2212"),(0,n.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2222em"}})),(0,n.kt)("span",{parentName:"span",className:"base"},(0,n.kt)("span",{parentName:"span",className:"strut",style:{height:"0.6444em"}}),(0,n.kt)("span",{parentName:"span",className:"mord"},"1"))))),". Following the calculation in Markov chain, current step distribution will be calculated by the product of each previously conditional step."),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Forward process notation",src:t(40666).Z,width:"369",height:"249"}),(0,n.kt)("br",{parentName:"p"}),"\n","Source : ",(0,n.kt)("a",{parentName:"p",href:"https://youtu.be/fbLgFrlTnGU?si=tR6le4piBvVpeR_9&t=109"},"https://youtu.be/fbLgFrlTnGU?si=tR6le4piBvVpeR_9&t=109")),(0,n.kt)("admonition",{type:"note"},(0,n.kt)("p",{parentName:"admonition"},"The forward process is fixed, meaning it doesn't have adjustable parameters.")),(0,n.kt)("p",null,"In the context of diffusion model, the type of Gaussian distribution used is the ",(0,n.kt)("strong",{parentName:"p"},"diagonal Gaussian distribution"),". The variance, denoted as ",(0,n.kt)("span",{parentName:"p",className:"math math-inline"},(0,n.kt)("span",{parentName:"span",className:"katex"},(0,n.kt)("span",{parentName:"span",className:"katex-mathml"},(0,n.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,n.kt)("semantics",{parentName:"math"},(0,n.kt)("mrow",{parentName:"semantics"},(0,n.kt)("mi",{parentName:"mrow"},"\u03b2")),(0,n.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"\\beta")))),(0,n.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,n.kt)("span",{parentName:"span",className:"base"},(0,n.kt)("span",{parentName:"span",className:"strut",style:{height:"0.8889em",verticalAlign:"-0.1944em"}}),(0,n.kt)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.05278em"}},"\u03b2"))))),", varies at each time step and is constrained to be within the range of 0 and 1. The lower variance implies that the diffusion or transformation of the distribution occurs more gradually and with smaller perturbations, which may help us on the reverse process."),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Gaussian distribution",src:t(43753).Z,width:"490",height:"103"}),(0,n.kt)("br",{parentName:"p"}),"\n","Source : ",(0,n.kt)("a",{parentName:"p",href:"https://youtu.be/fbLgFrlTnGU?si=mN1d8DKDP9vYJjQ0&t=129"},"https://youtu.be/fbLgFrlTnGU?si=mN1d8DKDP9vYJjQ0&t=129")),(0,n.kt)("p",null,"As we iteratively perform the forward diffusion process, the noise gradually converges towards a Gaussian distribution. Mathematically speaking, the noise can be approximated as a ",(0,n.kt)("strong",{parentName:"p"},"multivariate Gaussian distribution with a mean vector of zero and an identity covariance matrix"),"."),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Getting closer to identity matrix",src:t(71216).Z,width:"471",height:"192"}),(0,n.kt)("br",{parentName:"p"}),"\n","Source : ",(0,n.kt)("a",{parentName:"p",href:"https://youtu.be/fbLgFrlTnGU?si=C8gzMh3VVKSUXqBg&t=163"},"https://youtu.be/fbLgFrlTnGU?si=C8gzMh3VVKSUXqBg&t=163")),(0,n.kt)("h4",{id:"reverse-process"},"Reverse Process"),(0,n.kt)("p",null,"The reverse process will also be modeled using Markov chain, the noise will be assumed as a ",(0,n.kt)("strong",{parentName:"p"},"unimodal diagonal Gaussian distribution")," (the formula above in the image below), which takes current state (",(0,n.kt)("span",{parentName:"p",className:"math math-inline"},(0,n.kt)("span",{parentName:"span",className:"katex"},(0,n.kt)("span",{parentName:"span",className:"katex-mathml"},(0,n.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,n.kt)("semantics",{parentName:"math"},(0,n.kt)("mrow",{parentName:"semantics"},(0,n.kt)("msub",{parentName:"mrow"},(0,n.kt)("mi",{parentName:"msub"},"x"),(0,n.kt)("mi",{parentName:"msub"},"t"))),(0,n.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"x_t")))),(0,n.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,n.kt)("span",{parentName:"span",className:"base"},(0,n.kt)("span",{parentName:"span",className:"strut",style:{height:"0.5806em",verticalAlign:"-0.15em"}}),(0,n.kt)("span",{parentName:"span",className:"mord"},(0,n.kt)("span",{parentName:"span",className:"mord mathnormal"},"x"),(0,n.kt)("span",{parentName:"span",className:"msupsub"},(0,n.kt)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,n.kt)("span",{parentName:"span",className:"vlist-r"},(0,n.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.2806em"}},(0,n.kt)("span",{parentName:"span",style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"}},(0,n.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,n.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,n.kt)("span",{parentName:"span",className:"mord mathnormal mtight"},"t")))),(0,n.kt)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,n.kt)("span",{parentName:"span",className:"vlist-r"},(0,n.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.15em"}},(0,n.kt)("span",{parentName:"span"})))))))))),") and current time step (",(0,n.kt)("span",{parentName:"p",className:"math math-inline"},(0,n.kt)("span",{parentName:"span",className:"katex"},(0,n.kt)("span",{parentName:"span",className:"katex-mathml"},(0,n.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,n.kt)("semantics",{parentName:"math"},(0,n.kt)("mrow",{parentName:"semantics"},(0,n.kt)("mi",{parentName:"mrow"},"t")),(0,n.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"t")))),(0,n.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,n.kt)("span",{parentName:"span",className:"base"},(0,n.kt)("span",{parentName:"span",className:"strut",style:{height:"0.6151em"}}),(0,n.kt)("span",{parentName:"span",className:"mord mathnormal"},"t"))))),") as input."),(0,n.kt)("p",null,"In the reverse process of a diffusion model, it involves inferring the previous step given the current step. The calculation is done by multiplying the product of conditional distributions at each time step in reverse order (",(0,n.kt)("span",{parentName:"p",className:"math math-inline"},(0,n.kt)("span",{parentName:"span",className:"katex"},(0,n.kt)("span",{parentName:"span",className:"katex-mathml"},(0,n.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,n.kt)("semantics",{parentName:"math"},(0,n.kt)("mrow",{parentName:"semantics"},(0,n.kt)("msub",{parentName:"mrow"},(0,n.kt)("mi",{parentName:"msub"},"x"),(0,n.kt)("mrow",{parentName:"msub"},(0,n.kt)("mi",{parentName:"mrow"},"t"),(0,n.kt)("mo",{parentName:"mrow"},"\u2212"),(0,n.kt)("mn",{parentName:"mrow"},"1"))),(0,n.kt)("mi",{parentName:"mrow",mathvariant:"normal"},"\u2223"),(0,n.kt)("msub",{parentName:"mrow"},(0,n.kt)("mi",{parentName:"msub"},"x"),(0,n.kt)("mi",{parentName:"msub"},"t"))),(0,n.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"x_{t - 1} | x_t")))),(0,n.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,n.kt)("span",{parentName:"span",className:"base"},(0,n.kt)("span",{parentName:"span",className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,n.kt)("span",{parentName:"span",className:"mord"},(0,n.kt)("span",{parentName:"span",className:"mord mathnormal"},"x"),(0,n.kt)("span",{parentName:"span",className:"msupsub"},(0,n.kt)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,n.kt)("span",{parentName:"span",className:"vlist-r"},(0,n.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.3011em"}},(0,n.kt)("span",{parentName:"span",style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"}},(0,n.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,n.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,n.kt)("span",{parentName:"span",className:"mord mtight"},(0,n.kt)("span",{parentName:"span",className:"mord mathnormal mtight"},"t"),(0,n.kt)("span",{parentName:"span",className:"mbin mtight"},"\u2212"),(0,n.kt)("span",{parentName:"span",className:"mord mtight"},"1"))))),(0,n.kt)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,n.kt)("span",{parentName:"span",className:"vlist-r"},(0,n.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.2083em"}},(0,n.kt)("span",{parentName:"span"})))))),(0,n.kt)("span",{parentName:"span",className:"mord"},"\u2223"),(0,n.kt)("span",{parentName:"span",className:"mord"},(0,n.kt)("span",{parentName:"span",className:"mord mathnormal"},"x"),(0,n.kt)("span",{parentName:"span",className:"msupsub"},(0,n.kt)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,n.kt)("span",{parentName:"span",className:"vlist-r"},(0,n.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.2806em"}},(0,n.kt)("span",{parentName:"span",style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"}},(0,n.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,n.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,n.kt)("span",{parentName:"span",className:"mord mathnormal mtight"},"t")))),(0,n.kt)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,n.kt)("span",{parentName:"span",className:"vlist-r"},(0,n.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.15em"}},(0,n.kt)("span",{parentName:"span"})))))))))),") with the Gaussian noise distribution, denoted as ",(0,n.kt)("span",{parentName:"p",className:"math math-inline"},(0,n.kt)("span",{parentName:"span",className:"katex"},(0,n.kt)("span",{parentName:"span",className:"katex-mathml"},(0,n.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,n.kt)("semantics",{parentName:"math"},(0,n.kt)("mrow",{parentName:"semantics"},(0,n.kt)("mi",{parentName:"mrow"},"p"),(0,n.kt)("mo",{parentName:"mrow",stretchy:"false"},"("),(0,n.kt)("msub",{parentName:"mrow"},(0,n.kt)("mi",{parentName:"msub"},"x"),(0,n.kt)("mi",{parentName:"msub"},"T")),(0,n.kt)("mo",{parentName:"mrow",stretchy:"false"},")")),(0,n.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"p(x_T)")))),(0,n.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,n.kt)("span",{parentName:"span",className:"base"},(0,n.kt)("span",{parentName:"span",className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,n.kt)("span",{parentName:"span",className:"mord mathnormal"},"p"),(0,n.kt)("span",{parentName:"span",className:"mopen"},"("),(0,n.kt)("span",{parentName:"span",className:"mord"},(0,n.kt)("span",{parentName:"span",className:"mord mathnormal"},"x"),(0,n.kt)("span",{parentName:"span",className:"msupsub"},(0,n.kt)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,n.kt)("span",{parentName:"span",className:"vlist-r"},(0,n.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.3283em"}},(0,n.kt)("span",{parentName:"span",style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"}},(0,n.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,n.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,n.kt)("span",{parentName:"span",className:"mord mathnormal mtight",style:{marginRight:"0.13889em"}},"T")))),(0,n.kt)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,n.kt)("span",{parentName:"span",className:"vlist-r"},(0,n.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.15em"}},(0,n.kt)("span",{parentName:"span"})))))),(0,n.kt)("span",{parentName:"span",className:"mclose"},")"))))),", which was generated during the forward process (We assume the forward diffusion approaches Gaussian distribution)."),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Reverse process notation",src:t(18178).Z,width:"462",height:"340"}),(0,n.kt)("br",{parentName:"p"}),"\n","Source : ",(0,n.kt)("a",{parentName:"p",href:"https://youtu.be/fbLgFrlTnGU?si=v6ixlxk-gmWiHtDW&t=279"},"https://youtu.be/fbLgFrlTnGU?si=v6ixlxk-gmWiHtDW&t=279")),(0,n.kt)("p",null,"The inference process is where the process is made learnable or adjustable. In the implementation of reverse process, there are two parameters, the mean (",(0,n.kt)("span",{parentName:"p",className:"math math-inline"},(0,n.kt)("span",{parentName:"span",className:"katex"},(0,n.kt)("span",{parentName:"span",className:"katex-mathml"},(0,n.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,n.kt)("semantics",{parentName:"math"},(0,n.kt)("mrow",{parentName:"semantics"},(0,n.kt)("mi",{parentName:"mrow"},"\u03bc")),(0,n.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"\\mu")))),(0,n.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,n.kt)("span",{parentName:"span",className:"base"},(0,n.kt)("span",{parentName:"span",className:"strut",style:{height:"0.625em",verticalAlign:"-0.1944em"}}),(0,n.kt)("span",{parentName:"span",className:"mord mathnormal"},"\u03bc"))))),") and the variance (",(0,n.kt)("span",{parentName:"p",className:"math math-inline"},(0,n.kt)("span",{parentName:"span",className:"katex"},(0,n.kt)("span",{parentName:"span",className:"katex-mathml"},(0,n.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,n.kt)("semantics",{parentName:"math"},(0,n.kt)("mrow",{parentName:"semantics"},(0,n.kt)("mi",{parentName:"mrow",mathvariant:"normal"},"\u03a3")),(0,n.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"\\Sigma")))),(0,n.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,n.kt)("span",{parentName:"span",className:"base"},(0,n.kt)("span",{parentName:"span",className:"strut",style:{height:"0.6833em"}}),(0,n.kt)("span",{parentName:"span",className:"mord"},"\u03a3"))))),") of the Gaussian distribution. The variance is made fixed and only the mean is made learnable, for training stabilization purposes. In essence, the model will dynamically learn and adapt the optimal parameters to effectively reverse the diffusion process."),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Reverse process implementation",src:t(34532).Z,width:"524",height:"110"}),(0,n.kt)("br",{parentName:"p"}),"\n","Source : ",(0,n.kt)("a",{parentName:"p",href:"https://youtu.be/fbLgFrlTnGU?si=o0xlAFVkGm6B4nHr&t=651"},"https://youtu.be/fbLgFrlTnGU?si=o0xlAFVkGm6B4nHr&t=651")),(0,n.kt)("h4",{id:"training-objective"},"Training Objective"),(0,n.kt)("p",null,"The forward and reverse process can be understood as process that transform data or distribution (the input image) in two different directions. The forward process involves adding noise that will make the data distribution approach Gaussian distribution. The reverse process involves transforming the data back to its original distribution. This is done by approximating the unnoised data, by doing this, we effectively generate new data points during this process."),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"The objective of diffusion model",src:t(46722).Z,width:"283",height:"291"}),(0,n.kt)("br",{parentName:"p"}),"\n","Source : ",(0,n.kt)("a",{parentName:"p",href:"https://youtu.be/fbLgFrlTnGU?si=lOk5eb9Au4EJumjW&t=376"},"https://youtu.be/fbLgFrlTnGU?si=lOk5eb9Au4EJumjW&t=376")," (with modification)"),(0,n.kt)("p",null,"The process and objective of diffusion model is similar to ",(0,n.kt)("a",{parentName:"p",href:"/deep-learning/variational-autoencoder"},(0,n.kt)("strong",{parentName:"a"},"variational autoencoder (VAE)")),". In VAE, the encoder takes the input data and maps it to a lower-dimensional representation called the ",(0,n.kt)("strong",{parentName:"p"},"latent space"),". This latent space serves as a compressed representation that captures the essential information and underlying structure present in the input data. The decoder takes the latent space and sample from it, to generate new data samples. The objective is to approximate the true data distribution from the sampled distribution."),(0,n.kt)("p",null,'The similar objective can be applied to diffusion model, "Given transformed data, how to untransform it?". The primary aim of a diffusion model is to enhance the inference process, particularly by focusing on the reverse process that involves computing the preceding state of the Markov chain.'),(0,n.kt)("p",null,"The training objective can be summarized with the following formula (","[similar to loss in VAE]",") :"),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Training objective formula",src:t(25423).Z,width:"795",height:"57"}),(0,n.kt)("br",{parentName:"p"}),"\n","Source : ",(0,n.kt)("a",{parentName:"p",href:"https://youtu.be/fbLgFrlTnGU?si=D6pH6EyDnxSz0j1P&t=458"},"https://youtu.be/fbLgFrlTnGU?si=D6pH6EyDnxSz0j1P&t=458")," (with modification)"),(0,n.kt)("p",null,"The ",(0,n.kt)("span",{parentName:"p",className:"math math-inline"},(0,n.kt)("span",{parentName:"span",className:"katex"},(0,n.kt)("span",{parentName:"span",className:"katex-mathml"},(0,n.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,n.kt)("semantics",{parentName:"math"},(0,n.kt)("mrow",{parentName:"semantics"},(0,n.kt)("mi",{parentName:"mrow"},"log"),(0,n.kt)("mo",{parentName:"mrow"},"\u2061"),(0,n.kt)("msub",{parentName:"mrow"},(0,n.kt)("mi",{parentName:"msub"},"p"),(0,n.kt)("mi",{parentName:"msub"},"\u03b8")),(0,n.kt)("mo",{parentName:"mrow",stretchy:"false"},"("),(0,n.kt)("mi",{parentName:"mrow"},"x"),(0,n.kt)("mo",{parentName:"mrow",stretchy:"false"},")")),(0,n.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"\\log p_{\\theta}(x)")))),(0,n.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,n.kt)("span",{parentName:"span",className:"base"},(0,n.kt)("span",{parentName:"span",className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,n.kt)("span",{parentName:"span",className:"mop"},"lo",(0,n.kt)("span",{parentName:"span",style:{marginRight:"0.01389em"}},"g")),(0,n.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.1667em"}}),(0,n.kt)("span",{parentName:"span",className:"mord"},(0,n.kt)("span",{parentName:"span",className:"mord mathnormal"},"p"),(0,n.kt)("span",{parentName:"span",className:"msupsub"},(0,n.kt)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,n.kt)("span",{parentName:"span",className:"vlist-r"},(0,n.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.3361em"}},(0,n.kt)("span",{parentName:"span",style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"}},(0,n.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,n.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,n.kt)("span",{parentName:"span",className:"mord mtight"},(0,n.kt)("span",{parentName:"span",className:"mord mathnormal mtight",style:{marginRight:"0.02778em"}},"\u03b8"))))),(0,n.kt)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,n.kt)("span",{parentName:"span",className:"vlist-r"},(0,n.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.15em"}},(0,n.kt)("span",{parentName:"span"})))))),(0,n.kt)("span",{parentName:"span",className:"mopen"},"("),(0,n.kt)("span",{parentName:"span",className:"mord mathnormal"},"x"),(0,n.kt)("span",{parentName:"span",className:"mclose"},")")))))," represent the likelihood of the original data, it must be greater or equal to the first term subtracted by second term. We represent the original data as a likelihood because our goal is to reconstruct it. By maximizing the likelihood, we aim to ensure that the reconstructed data closely resembles the original data."),(0,n.kt)("p",null,"The first term is the ",(0,n.kt)("strong",{parentName:"p"},"reconstruction term"),", which is the comparison of generated data and the original data. The second term is the ",(0,n.kt)("strong",{parentName:"p"},"KL divergence")," measures the difference of probability distribution between the target distribution (input data) and the learned distribution (generated distribuion)."),(0,n.kt)("h4",{id:"summary"},"Summary"),(0,n.kt)("p",null,"In summary, diffusion model starts with the forward process where we add Gaussian distribution noise to the image. After a bunch of step, we obtained a distribution approximately close to Gaussian distribution. In the reverse process, the model aims to remove the noise by inferring the previous distribution based on the current distribution, which is where the model learns. This process is often described as sampling because it entails generating samples from an approximated distribution obtained at the current step."),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Diffusion process summary",src:t(43371).Z,width:"968",height:"279"}),(0,n.kt)("br",{parentName:"p"}),"\n","Source : ",(0,n.kt)("a",{parentName:"p",href:"https://scholar.harvard.edu/binxuw/classes/machine-learning-scratch/materials/foundation-diffusion-generative-models"},"https://scholar.harvard.edu/binxuw/classes/machine-learning-scratch/materials/foundation-diffusion-generative-models")),(0,n.kt)("p",null,"After training the model, to generate new data using a trained diffusion model, we start with a random noise sample and then perform the reverse diffusion steps."),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"The process of generating image from a random noise, after model training",src:t(81122).Z,width:"608",height:"608"}),(0,n.kt)("br",{parentName:"p"}),"\n","Source : ",(0,n.kt)("a",{parentName:"p",href:"https://tree.rocks/make-diffusion-model-from-scratch-easy-way-to-implement-quick-diffusion-model-e60d18fd0f2e"},"https://tree.rocks/make-diffusion-model-from-scratch-easy-way-to-implement-quick-diffusion-model-e60d18fd0f2e")),(0,n.kt)("h3",{id:"denoising-diffusion-implicit-models-ddim"},"Denoising Diffusion Implicit Models (DDIM)"),(0,n.kt)("p",null,"The type of denoising diffusion model previously we talked about uses the probabilistic Markov chain as the framework, which can be slow during the sampling process in the reverse diffusion (there is some technique to skip the diffusion in forward process). Furthermore, DDPM require alot of forward diffusion step, which also increase the step in reverse process."),(0,n.kt)("p",null,"DDIM is a non-Markovian diffusion model, it removed the use of Markov chain. In Markov chain, during the reverse process, we assume that previous step only depends on current step (e.g. ",(0,n.kt)("span",{parentName:"p",className:"math math-inline"},(0,n.kt)("span",{parentName:"span",className:"katex"},(0,n.kt)("span",{parentName:"span",className:"katex-mathml"},(0,n.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,n.kt)("semantics",{parentName:"math"},(0,n.kt)("mrow",{parentName:"semantics"},(0,n.kt)("msub",{parentName:"mrow"},(0,n.kt)("mi",{parentName:"msub"},"x"),(0,n.kt)("mn",{parentName:"msub"},"1"))),(0,n.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"x_1")))),(0,n.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,n.kt)("span",{parentName:"span",className:"base"},(0,n.kt)("span",{parentName:"span",className:"strut",style:{height:"0.5806em",verticalAlign:"-0.15em"}}),(0,n.kt)("span",{parentName:"span",className:"mord"},(0,n.kt)("span",{parentName:"span",className:"mord mathnormal"},"x"),(0,n.kt)("span",{parentName:"span",className:"msupsub"},(0,n.kt)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,n.kt)("span",{parentName:"span",className:"vlist-r"},(0,n.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.3011em"}},(0,n.kt)("span",{parentName:"span",style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"}},(0,n.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,n.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,n.kt)("span",{parentName:"span",className:"mord mtight"},"1")))),(0,n.kt)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,n.kt)("span",{parentName:"span",className:"vlist-r"},(0,n.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.15em"}},(0,n.kt)("span",{parentName:"span"}))))))))))," depends on ",(0,n.kt)("span",{parentName:"p",className:"math math-inline"},(0,n.kt)("span",{parentName:"span",className:"katex"},(0,n.kt)("span",{parentName:"span",className:"katex-mathml"},(0,n.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,n.kt)("semantics",{parentName:"math"},(0,n.kt)("mrow",{parentName:"semantics"},(0,n.kt)("msub",{parentName:"mrow"},(0,n.kt)("mi",{parentName:"msub"},"x"),(0,n.kt)("mn",{parentName:"msub"},"2"))),(0,n.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"x_2")))),(0,n.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,n.kt)("span",{parentName:"span",className:"base"},(0,n.kt)("span",{parentName:"span",className:"strut",style:{height:"0.5806em",verticalAlign:"-0.15em"}}),(0,n.kt)("span",{parentName:"span",className:"mord"},(0,n.kt)("span",{parentName:"span",className:"mord mathnormal"},"x"),(0,n.kt)("span",{parentName:"span",className:"msupsub"},(0,n.kt)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,n.kt)("span",{parentName:"span",className:"vlist-r"},(0,n.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.3011em"}},(0,n.kt)("span",{parentName:"span",style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"}},(0,n.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,n.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,n.kt)("span",{parentName:"span",className:"mord mtight"},"2")))),(0,n.kt)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,n.kt)("span",{parentName:"span",className:"vlist-r"},(0,n.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.15em"}},(0,n.kt)("span",{parentName:"span"}))))))))))," = ",(0,n.kt)("span",{parentName:"p",className:"math math-inline"},(0,n.kt)("span",{parentName:"span",className:"katex"},(0,n.kt)("span",{parentName:"span",className:"katex-mathml"},(0,n.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,n.kt)("semantics",{parentName:"math"},(0,n.kt)("mrow",{parentName:"semantics"},(0,n.kt)("mi",{parentName:"mrow"},"q"),(0,n.kt)("mo",{parentName:"mrow",stretchy:"false"},"("),(0,n.kt)("msub",{parentName:"mrow"},(0,n.kt)("mi",{parentName:"msub"},"x"),(0,n.kt)("mn",{parentName:"msub"},"2")),(0,n.kt)("mi",{parentName:"mrow",mathvariant:"normal"},"\u2223"),(0,n.kt)("msub",{parentName:"mrow"},(0,n.kt)("mi",{parentName:"msub"},"x"),(0,n.kt)("mn",{parentName:"msub"},"1")),(0,n.kt)("mo",{parentName:"mrow",stretchy:"false"},")")),(0,n.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"q(x_2|x_1)")))),(0,n.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,n.kt)("span",{parentName:"span",className:"base"},(0,n.kt)("span",{parentName:"span",className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,n.kt)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.03588em"}},"q"),(0,n.kt)("span",{parentName:"span",className:"mopen"},"("),(0,n.kt)("span",{parentName:"span",className:"mord"},(0,n.kt)("span",{parentName:"span",className:"mord mathnormal"},"x"),(0,n.kt)("span",{parentName:"span",className:"msupsub"},(0,n.kt)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,n.kt)("span",{parentName:"span",className:"vlist-r"},(0,n.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.3011em"}},(0,n.kt)("span",{parentName:"span",style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"}},(0,n.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,n.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,n.kt)("span",{parentName:"span",className:"mord mtight"},"2")))),(0,n.kt)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,n.kt)("span",{parentName:"span",className:"vlist-r"},(0,n.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.15em"}},(0,n.kt)("span",{parentName:"span"})))))),(0,n.kt)("span",{parentName:"span",className:"mord"},"\u2223"),(0,n.kt)("span",{parentName:"span",className:"mord"},(0,n.kt)("span",{parentName:"span",className:"mord mathnormal"},"x"),(0,n.kt)("span",{parentName:"span",className:"msupsub"},(0,n.kt)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,n.kt)("span",{parentName:"span",className:"vlist-r"},(0,n.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.3011em"}},(0,n.kt)("span",{parentName:"span",style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"}},(0,n.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,n.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,n.kt)("span",{parentName:"span",className:"mord mtight"},"1")))),(0,n.kt)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,n.kt)("span",{parentName:"span",className:"vlist-r"},(0,n.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.15em"}},(0,n.kt)("span",{parentName:"span"})))))),(0,n.kt)("span",{parentName:"span",className:"mclose"},")"))))),")."),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"DDIM without Markov chain",src:t(8650).Z,width:"924",height:"161"}),(0,n.kt)("br",{parentName:"p"}),"\n","Source : ",(0,n.kt)("a",{parentName:"p",href:"https://betterprogramming.pub/diffusion-models-ddpms-ddims-and-classifier-free-guidance-e07b297b2869"},"https://betterprogramming.pub/diffusion-models-ddpms-ddims-and-classifier-free-guidance-e07b297b2869")," (with modification)"),(0,n.kt)("p",null,"DDIM does not rely on a strict sequential dependence on previous steps. The elimination of the Markov chain allows for the consideration of multiple states beyond just the previous one in the reverse diffusion process. This transformation turns the process into an optimization problem, as the inclusion of more states introduces complex dependencies and variations in the data."),(0,n.kt)("p",null,"The goal is to find an optimal ",(0,n.kt)("strong",{parentName:"p"},"latent code"),", latent code is nothing but a set of parameters that captures the information required to generate a denoised or clean sample from a corrupted input. We adjust the parameters by minimizing the reconstruction loss between the generated sample and the corrupted input."),(0,n.kt)("admonition",{type:"tip"},(0,n.kt)("p",{parentName:"admonition"},"DDPM can be seen as a special case of DDIM, where we only consider the previous state for current state.",(0,n.kt)("br",{parentName:"p"}),"\n",'The term "implicit" in DDIM means that we do not explicitly try to denoise the image, instead we just find the best parameters that minimize the lost.')),(0,n.kt)("h3",{id:"conditional--unconditional-generation"},"Conditional & Unconditional Generation"),(0,n.kt)("p",null,"Diffusion model can also be integrated with a conditional prompt. The conditional prompt serves as a guide or constraint during the generation process, allowing for more controlled and targeted generation of data. The conditional prompt can be in the form of text, images, or any other type of input."),(0,n.kt)("h4",{id:"unconditional"},"Unconditional"),(0,n.kt)("p",null,"In the unconditional generation, we do not include any additional constraint. The model will start with a random noise sample and applies the reverse process to progressively reduce the noise and generate new data samples. The resulting data will be similar to the training data."),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Unconditional generation",src:t(32707).Z,width:"628",height:"335"}),(0,n.kt)("br",{parentName:"p"}),"\n","Source : ",(0,n.kt)("a",{parentName:"p",href:"https://betterprogramming.pub/beginners-guide-to-unconditional-image-generation-using-diffusers-c703e675bda8"},"https://betterprogramming.pub/beginners-guide-to-unconditional-image-generation-using-diffusers-c703e675bda8")),(0,n.kt)("h4",{id:"conditional"},"Conditional"),(0,n.kt)("p",null,"In the conditional generation, the model is trained to learn the distribution of the training data given certain input conditions. During the generation process, the model takes the input conditions into account and adjusts the reverse process accordingly to generate samples that satisfy the given conditions."),(0,n.kt)("p",null,"The target data in reverse process which is ",(0,n.kt)("span",{parentName:"p",className:"math math-inline"},(0,n.kt)("span",{parentName:"span",className:"katex"},(0,n.kt)("span",{parentName:"span",className:"katex-mathml"},(0,n.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,n.kt)("semantics",{parentName:"math"},(0,n.kt)("mrow",{parentName:"semantics"},(0,n.kt)("msub",{parentName:"mrow"},(0,n.kt)("mi",{parentName:"msub"},"p"),(0,n.kt)("mi",{parentName:"msub"},"\u03b8")),(0,n.kt)("mo",{parentName:"mrow",stretchy:"false"},"("),(0,n.kt)("msub",{parentName:"mrow"},(0,n.kt)("mi",{parentName:"msub"},"x"),(0,n.kt)("mn",{parentName:"msub"},"0")),(0,n.kt)("mo",{parentName:"mrow",stretchy:"false"},")")),(0,n.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"p_{\\theta}(x_{0})")))),(0,n.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,n.kt)("span",{parentName:"span",className:"base"},(0,n.kt)("span",{parentName:"span",className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,n.kt)("span",{parentName:"span",className:"mord"},(0,n.kt)("span",{parentName:"span",className:"mord mathnormal"},"p"),(0,n.kt)("span",{parentName:"span",className:"msupsub"},(0,n.kt)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,n.kt)("span",{parentName:"span",className:"vlist-r"},(0,n.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.3361em"}},(0,n.kt)("span",{parentName:"span",style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"}},(0,n.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,n.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,n.kt)("span",{parentName:"span",className:"mord mtight"},(0,n.kt)("span",{parentName:"span",className:"mord mathnormal mtight",style:{marginRight:"0.02778em"}},"\u03b8"))))),(0,n.kt)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,n.kt)("span",{parentName:"span",className:"vlist-r"},(0,n.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.15em"}},(0,n.kt)("span",{parentName:"span"})))))),(0,n.kt)("span",{parentName:"span",className:"mopen"},"("),(0,n.kt)("span",{parentName:"span",className:"mord"},(0,n.kt)("span",{parentName:"span",className:"mord mathnormal"},"x"),(0,n.kt)("span",{parentName:"span",className:"msupsub"},(0,n.kt)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,n.kt)("span",{parentName:"span",className:"vlist-r"},(0,n.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.3011em"}},(0,n.kt)("span",{parentName:"span",style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"}},(0,n.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,n.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,n.kt)("span",{parentName:"span",className:"mord mtight"},(0,n.kt)("span",{parentName:"span",className:"mord mtight"},"0"))))),(0,n.kt)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,n.kt)("span",{parentName:"span",className:"vlist-r"},(0,n.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.15em"}},(0,n.kt)("span",{parentName:"span"})))))),(0,n.kt)("span",{parentName:"span",className:"mclose"},")")))))," becomes ",(0,n.kt)("span",{parentName:"p",className:"math math-inline"},(0,n.kt)("span",{parentName:"span",className:"katex"},(0,n.kt)("span",{parentName:"span",className:"katex-mathml"},(0,n.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,n.kt)("semantics",{parentName:"math"},(0,n.kt)("mrow",{parentName:"semantics"},(0,n.kt)("msub",{parentName:"mrow"},(0,n.kt)("mi",{parentName:"msub"},"p"),(0,n.kt)("mi",{parentName:"msub"},"\u03b8")),(0,n.kt)("mo",{parentName:"mrow",stretchy:"false"},"("),(0,n.kt)("msub",{parentName:"mrow"},(0,n.kt)("mi",{parentName:"msub"},"x"),(0,n.kt)("mn",{parentName:"msub"},"0")),(0,n.kt)("mi",{parentName:"mrow",mathvariant:"normal"},"\u2223"),(0,n.kt)("mi",{parentName:"mrow"},"y"),(0,n.kt)("mo",{parentName:"mrow",stretchy:"false"},")")),(0,n.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"p_{\\theta}(x_{0}|y)")))),(0,n.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,n.kt)("span",{parentName:"span",className:"base"},(0,n.kt)("span",{parentName:"span",className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,n.kt)("span",{parentName:"span",className:"mord"},(0,n.kt)("span",{parentName:"span",className:"mord mathnormal"},"p"),(0,n.kt)("span",{parentName:"span",className:"msupsub"},(0,n.kt)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,n.kt)("span",{parentName:"span",className:"vlist-r"},(0,n.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.3361em"}},(0,n.kt)("span",{parentName:"span",style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"}},(0,n.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,n.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,n.kt)("span",{parentName:"span",className:"mord mtight"},(0,n.kt)("span",{parentName:"span",className:"mord mathnormal mtight",style:{marginRight:"0.02778em"}},"\u03b8"))))),(0,n.kt)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,n.kt)("span",{parentName:"span",className:"vlist-r"},(0,n.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.15em"}},(0,n.kt)("span",{parentName:"span"})))))),(0,n.kt)("span",{parentName:"span",className:"mopen"},"("),(0,n.kt)("span",{parentName:"span",className:"mord"},(0,n.kt)("span",{parentName:"span",className:"mord mathnormal"},"x"),(0,n.kt)("span",{parentName:"span",className:"msupsub"},(0,n.kt)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,n.kt)("span",{parentName:"span",className:"vlist-r"},(0,n.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.3011em"}},(0,n.kt)("span",{parentName:"span",style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"}},(0,n.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,n.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,n.kt)("span",{parentName:"span",className:"mord mtight"},(0,n.kt)("span",{parentName:"span",className:"mord mtight"},"0"))))),(0,n.kt)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,n.kt)("span",{parentName:"span",className:"vlist-r"},(0,n.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.15em"}},(0,n.kt)("span",{parentName:"span"})))))),(0,n.kt)("span",{parentName:"span",className:"mord"},"\u2223"),(0,n.kt)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.03588em"}},"y"),(0,n.kt)("span",{parentName:"span",className:"mclose"},")"))))),". The reverse step also takes the additional condition. The conditional generation can actually simplify the generation process by constraining the range of possible outputs."),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Reverse step network",src:t(43777).Z,width:"251",height:"96"}),(0,n.kt)("br",{parentName:"p"}),"\n","Source : ",(0,n.kt)("a",{parentName:"p",href:"https://youtu.be/fbLgFrlTnGU?si=luVZ1O9GCWV8_2PH&t=714"},"https://youtu.be/fbLgFrlTnGU?si=luVZ1O9GCWV8_2PH&t=714")),(0,n.kt)("h2",{id:"score-based-diffusion-model-sbdm"},"Score-Based Diffusion Model (SBDM)"),(0,n.kt)("p",null,(0,n.kt)("strong",{parentName:"p"},"Score-Based Diffusion Model (SBDM)")," is also known as ",(0,n.kt)("strong",{parentName:"p"},"Noise Conditional Score Network (NCSN)")," or ",(0,n.kt)("strong",{parentName:"p"},"Score-Matching with Langevin Dynamics (SMLD)"),". SBDM introduces the concept of ",(0,n.kt)("strong",{parentName:"p"},"score"),", mathematically, it is the gradient of the log-likelihood of the data distribution."),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Score function",src:t(94365).Z,width:"284",height:"45"}),(0,n.kt)("br",{parentName:"p"}),"\n","Source : ",(0,n.kt)("a",{parentName:"p",href:"https://youtu.be/fbLgFrlTnGU?si=lEL8BBYdL0f1cetc&t=907"},"https://youtu.be/fbLgFrlTnGU?si=lEL8BBYdL0f1cetc&t=907")),(0,n.kt)("p",null,"A gradient with respect to some variables tells us the direction and magnitude of the steepest ascent or descent of a function at a particular point. Specifically in the context of SBDM, the gradient measures the direction in which the noise should be adjusted to move towards denoising or generating the desired output. It act as a guide for diffusion process by providing information on how to update the noise, but it does not provide a direct measure of similarity or dissimilarity."),(0,n.kt)("p",null,"The integration of score-based guidance with diffusion model fall between each diffusion step, score or gradient of the log-likelihood of the data distribution will be estimated with respect to the noise process. After that, the noise is updated in the direction of the estimated score."),(0,n.kt)("h2",{id:"latent-diffusion-model-ldm"},"Latent Diffusion Model (LDM)"),(0,n.kt)("p",null,"input data goes to encoder, it will be transformed into latent space or lower-dimensional representation. the output of encoder is a multivariate gaussian distribution, parameterized by its mean and variance, which is also produced by encoder. The distribtuion will be fed into diffusion model. diffusion model produces the new sampled image. to actually generate image, we use decoder that does the rerverse process.\ntypically use ",(0,n.kt)("a",{parentName:"p",href:"/deep-learning/variational-autoencoder"},"variational autoencoder (VAE)")),(0,n.kt)("hr",null),(0,n.kt)("p",null,"The entire diffusion topics is based on the fast.ai part 2 course, with addition from other sources."),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},(0,n.kt)("a",{parentName:"strong",href:"https://course.fast.ai/Lessons/part2.html"},"fast.ai Part 2 course")))),(0,n.kt)("p",null,"this note should include the general principle of how diffusion model works, the next notes should explain it in more detailed along with the explanation about the method and technique used."),(0,n.kt)("p",null,"what to explain in diffusion :"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"Diffusion method (done)"),(0,n.kt)("li",{parentName:"ul"},"Denoising Diffusion Probabilistic Models (DDPM) (done)"),(0,n.kt)("li",{parentName:"ul"},"Denoising Diffusion Implicit Models (DDIM) (done)"),(0,n.kt)("li",{parentName:"ul"},"conditional and unconditional diffusion (done)"),(0,n.kt)("li",{parentName:"ul"},"sampler (in stabble diffusion)"),(0,n.kt)("li",{parentName:"ul"},"CLIP (in dall e & midjourney)"),(0,n.kt)("li",{parentName:"ul"},"a"),(0,n.kt)("li",{parentName:"ul"},"b"),(0,n.kt)("li",{parentName:"ul"},"c\nthe last 3: stable diffusion, dall-e, and midjourney will explain what diffusion model technique they specifically uses, it can be thought as the application of diffusion model.\nwill also explain how stable diffusion and others apply the conditional generation technique such as cross attention with transformers"),(0,n.kt)("li",{parentName:"ul"},"stable diffusion"),(0,n.kt)("li",{parentName:"ul"},"dall-e"),(0,n.kt)("li",{parentName:"ul"},"midjourney")))}d.isMDXComponent=!0},71216:(a,e,t)=>{t.d(e,{Z:()=>s});const s=t.p+"assets/images/approach-identity-matrix-2336ab708059a75b31a755e0dad9c4f5.png"},8650:(a,e,t)=>{t.d(e,{Z:()=>s});const s=t.p+"assets/images/ddim-270de147713f25c4160c0427e93dbd96.png"},43371:(a,e,t)=>{t.d(e,{Z:()=>s});const s=t.p+"assets/images/diffusion-summary-ce581a3d73b6962da4914a730053f3b6.png"},40666:(a,e,t)=>{t.d(e,{Z:()=>s});const s=t.p+"assets/images/forward-process-notation-f53c42c883304c68a3667a76fc7b8573.png"},44710:(a,e,t)=>{t.d(e,{Z:()=>s});const s=t.p+"assets/images/gaussian-distribution-noise-a0d40f8ab3d16bcd3d56e322cff74168.png"},43753:(a,e,t)=>{t.d(e,{Z:()=>s});const s=t.p+"assets/images/gaussian-distribution-9569cf4b790dadd74f4101bcfe2bae0b.png"},81122:(a,e,t)=>{t.d(e,{Z:()=>s});const s=t.p+"assets/images/generation-process-268c9bb8f2a23fbea3ce8844804fbaf9.gif"},46722:(a,e,t)=>{t.d(e,{Z:()=>s});const s=t.p+"assets/images/objective-57e94625624526004f3b851095df306f.png"},34532:(a,e,t)=>{t.d(e,{Z:()=>s});const s=t.p+"assets/images/reverse-process-implementation-c4884f9c757dba8b0d036e36237361c9.png"},18178:(a,e,t)=>{t.d(e,{Z:()=>s});const s=t.p+"assets/images/reverse-process-notation-fa196f341c9afbfd2b8202827e0b3ec0.png"},43777:(a,e,t)=>{t.d(e,{Z:()=>s});const s=t.p+"assets/images/reverse-step-network-c1bb16987ba49e214988fa131a44268a.png"},94365:(a,e,t)=>{t.d(e,{Z:()=>s});const s=t.p+"assets/images/score-function-f623c8ae9a665225f7ac00e05f949146.png"},25423:(a,e,t)=>{t.d(e,{Z:()=>s});const s=t.p+"assets/images/training-formula-17beda6f8e60e6a73cc78b5ecc67d695.png"},32707:(a,e,t)=>{t.d(e,{Z:()=>s});const s=t.p+"assets/images/unconditional-generation-58bbcbb30fb288cd4bde16f7a76b2511.png"}}]);