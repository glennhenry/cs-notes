"use strict";(self.webpackChunkcs_notes=self.webpackChunkcs_notes||[]).push([[9750],{15594:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>h,contentTitle:()=>r,default:()=>l,frontMatter:()=>a,metadata:()=>o,toc:()=>c});var s=n(85893),i=n(11151);const a={slug:"/operating-system/multithreading",id:"multithreading",title:"Multithreading",description:"Multithreading"},r=void 0,o={id:"operating-system/multithreading/multithreading",title:"Multithreading",description:"Multithreading",source:"@site/docs/operating-system/04-multithreading/multithreading.md",sourceDirName:"operating-system/04-multithreading",slug:"/operating-system/multithreading",permalink:"/cs-notes/operating-system/multithreading",draft:!1,unlisted:!1,editUrl:"https://github.com/glennhenry/cs-notes/tree/main/docs/operating-system/04-multithreading/multithreading.md",tags:[],version:"current",lastUpdatedBy:"glennhenry",lastUpdatedAt:1704279017,formattedLastUpdatedAt:"Jan 3, 2024",frontMatter:{slug:"/operating-system/multithreading",id:"multithreading",title:"Multithreading",description:"Multithreading"},sidebar:"sidebar",previous:{title:"Process Management",permalink:"/cs-notes/operating-system/process-management"},next:{title:"Process Synchronization",permalink:"/cs-notes/operating-system/process-synchronization"}},h={},c=[{value:"Thread",id:"thread",level:3},{value:"Multithreading Model",id:"multithreading-model",level:3},{value:"User &amp; Kernel Thread",id:"user--kernel-thread",level:4},{value:"Relationship Model",id:"relationship-model",level:4},{value:"Thread Management",id:"thread-management",level:3},{value:"Thread Creation &amp; Termination",id:"thread-creation--termination",level:4},{value:"Thread Execution &amp; Scheduling",id:"thread-execution--scheduling",level:4},{value:"Thread Communication",id:"thread-communication",level:4},{value:"Thread Synchronization",id:"thread-synchronization",level:4},{value:"Synchronization Primitives",id:"synchronization-primitives",level:5},{value:"Locks / Mutex",id:"locks--mutex",level:6},{value:"Condition Variables",id:"condition-variables",level:6},{value:"Semaphores",id:"semaphores",level:6},{value:"Barriers",id:"barriers",level:6},{value:"Spinlocks",id:"spinlocks",level:6},{value:"Atomic Operation",id:"atomic-operation",level:5},{value:"Thread Pool",id:"thread-pool",level:4},{value:"Multithreading Problems",id:"multithreading-problems",level:3},{value:"Communication",id:"communication",level:3},{value:"Shared Memory",id:"shared-memory",level:4},{value:"Message Passing",id:"message-passing",level:4}];function d(e){const t={a:"a",admonition:"admonition",br:"br",code:"code",h3:"h3",h4:"h4",h5:"h5",h6:"h6",img:"img",li:"li",p:"p",strong:"strong",ul:"ul",...(0,i.a)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(t.p,{children:(0,s.jsx)(t.strong,{children:"Main Source :"})}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:(0,s.jsx)(t.strong,{children:"[Chapter 4 Threads - Abraham Silberschatz-Operating System Concepts (9th,2012_12)]"})}),"\n",(0,s.jsx)(t.li,{children:(0,s.jsx)(t.strong,{children:"[Chapter 5 Process Synchronization - Abraham Silberschatz-Operating System Concepts (9th,2012_12)]"})}),"\n",(0,s.jsx)(t.li,{children:(0,s.jsx)(t.strong,{children:(0,s.jsx)(t.a,{href:"https://en.wikipedia.org/wiki/Multithreading_(computer_architecture)",children:"Multithreading (computer architecture) - Wikipedia"})})}),"\n",(0,s.jsx)(t.li,{children:(0,s.jsx)(t.strong,{children:(0,s.jsx)(t.a,{href:"https://en.wikipedia.org/wiki/Thread_(computing)",children:"Thread (computing) - Wikipedia"})})}),"\n"]}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"Multithreading"})," is a concept that enable us to use multiple thread to execute tasks."]}),"\n",(0,s.jsx)(t.h3,{id:"thread",children:"Thread"}),"\n",(0,s.jsxs)(t.p,{children:['Thread is a unit of execution in CPU, it can execute a set of instruction, basically it is a "worker" in a CPU. Thread exist within a ',(0,s.jsx)(t.a,{href:"/operating-system/process-management#process--thread",children:"process"})," and has its own data including thread ID, program counter, a register set, and a stack."]}),"\n",(0,s.jsx)(t.p,{children:"In multithreading, instead of just one thread or one worker in a process, multiple thread is utilized. The benefit is we are not limited to complete a single task at a time, for example, a mobile app can fetch data from remote server while also loading data from local storage. If possible, we can also divide a computationally intensive task into smaller, parallelizable subtasks, and use multiple threads to speeds up the overall execution time."}),"\n",(0,s.jsxs)(t.p,{children:["A thread can also be ",(0,s.jsx)(t.strong,{children:"blocked"}),", which means the thread is unable to make progress or continue its execution because it is waiting for a certain event such as I/O results or condition to occur. Blocked thread can be inefficient, as it is unable to perform any useful work."]}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.img,{alt:"Multithreading",src:n(34611).Z+"",width:"842",height:"329"}),(0,s.jsx)(t.br,{}),"\n","Source : ",(0,s.jsx)(t.a,{href:"https://towardsdatascience.com/multithreading-and-multiprocessing-in-10-minutes-20d9b3c6a867",children:"https://towardsdatascience.com/multithreading-and-multiprocessing-in-10-minutes-20d9b3c6a867"})]}),"\n",(0,s.jsx)(t.p,{children:"The image above shows the illustration of multithreading. Each thread holds different data, but they share the same memory space and resources of the parent process. In contrast, multiprocessing is when we utilize a processor that has several cores. Each core would have their own data and thread that will execute simultaneously."}),"\n",(0,s.jsxs)(t.p,{children:["Utilizing multiple threads is typically more efficient than making multiple process that execute the same tasks. Threads have a smaller memory footprint, require less time for ",(0,s.jsx)(t.a,{href:"/operating-system/process-management#context-switch",children:"context switching"}),", and have lower scheduling overhead. Also, separate process means ",(0,s.jsx)(t.a,{href:"/operating-system/inter-process-communication",children:"IPC"})," is required to communicate between processes, whereas thread shares the same memory within a process, thus communication will be easier."]}),"\n",(0,s.jsx)(t.h3,{id:"multithreading-model",children:"Multithreading Model"}),"\n",(0,s.jsx)(t.h4,{id:"user--kernel-thread",children:"User & Kernel Thread"}),"\n",(0,s.jsxs)(t.p,{children:["There are two types of thread, ",(0,s.jsx)(t.strong,{children:"user thread"})," and ",(0,s.jsx)(t.strong,{children:"kernel thread"}),"."]}),"\n",(0,s.jsxs)(t.p,{children:["User threads, also known as ",(0,s.jsx)(t.strong,{children:"green threads"}),", are implemented and managed by a thread library or runtime system at the user level, without direct involvement of the operating system kernel. The creation, scheduling, and synchronization of user threads are handled entirely in the user space (memory space where user applications run)."]}),"\n",(0,s.jsxs)(t.p,{children:["On the other hand, kernel threads, which is also known as ",(0,s.jsx)(t.strong,{children:"native threads"}),", are managed directly by the operating system kernel. Each kernel thread is represented as a separate entity within the operating system and has its own program counter, stack, and thread control block."]}),"\n",(0,s.jsx)(t.p,{children:"User threads are generally lightweight, however, they are not fully aware of the underlying thread management mechanisms. If a user thread blocks or performs an operation that blocks, it can potentially block the entire process, including all other user threads."}),"\n",(0,s.jsx)(t.p,{children:"Kernel threads are heavyweight, they require system calls and interaction with the operating system kernel for creation and management. The benefit of kernel thread is that they are fully managed by the OS, this allows for better utilization of system resources and efficient scheduling across multiple processors (achieving true parallelism)."}),"\n",(0,s.jsx)(t.h4,{id:"relationship-model",children:"Relationship Model"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"Many-to-One"})," : This model involves mapping multiple user-level threads to a single kernel-level thread. The thread management and scheduling are performed by a thread library or runtime system at the user level, and the operating system sees only a single thread. This model has efficient management, but may not take full advantage of multiprocessor systems as the execution of multiple threads is handled by a single kernel-level thread."]}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"One-to-One"})," : In this model, each user-level thread is mapped to a separate kernel-level thread by the operating system. This model provides more concurrency and true parallelism to the kernel-level. However, the overhead of creating and managing kernel-level threads can be higher compared to other models."]}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"Many-to-Many"})," : This model combines the aspect of many-to-one and one-to-one. Many-to-many model consist of many kernel threads and smaller or equal number of user thread. The operating system can create multiple kernel-level threads, while the thread library manages and schedules the user-level threads across the available kernel-level threads."]}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.img,{alt:"Relationship model",src:n(90637).Z+"",width:"551",height:"286"}),(0,s.jsx)(t.br,{}),"\n","Source : ",(0,s.jsx)(t.a,{href:"https://www.researchgate.net/figure/Three-types-of-thread-models-Popular-operating-systems-5-22-24-adopt-the_fig1_346379550",children:"https://www.researchgate.net/figure/Three-types-of-thread-models-Popular-operating-systems-5-22-24-adopt-the_fig1_346379550"})]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(t.h3,{id:"thread-management",children:"Thread Management"}),"\n",(0,s.jsx)(t.p,{children:"Multithreading implementation depends on the programming language used. Threading process involves thread creation, execution and scheduling, synchronization, and termination."}),"\n",(0,s.jsx)(t.h4,{id:"thread-creation--termination",children:"Thread Creation & Termination"}),"\n",(0,s.jsxs)(t.p,{children:["The thread library provided by programming languages have specific function or method to create and manage threads. For example, in Java, we can create a thread by extending the ",(0,s.jsx)(t.code,{children:"Thread"})," class or implementing the ",(0,s.jsx)(t.code,{children:"Runnable"})," interface and then invoking the ",(0,s.jsx)(t.code,{children:"start()"})," method. In C++, you can use the ",(0,s.jsx)(t.code,{children:"std::thread"})," class or the threading utilities provided by libraries like POSIX threads (",(0,s.jsx)(t.code,{children:"pthread_create()"})," function)."]}),"\n",(0,s.jsx)(t.p,{children:"When creating thread, we can specify thread attributes such as stack size, thread priority, CPU affinity. After a thread is created, it is assigned a unique identifier called the thread ID."}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.img,{alt:"Thread creation in Java",src:n(35354).Z+"",width:"663",height:"383"}),(0,s.jsx)(t.br,{}),"\n","Source : ",(0,s.jsx)(t.a,{href:"http://java-latte.blogspot.com/2015/07/create-thread-using-method-reference-in-java-8.html",children:"http://java-latte.blogspot.com/2015/07/create-thread-using-method-reference-in-java-8.html"})]}),"\n",(0,s.jsxs)(t.p,{children:["Thread can be stopped explicitly using function like ",(0,s.jsx)(t.code,{children:"stop()"})," in Java. Sometimes, the thread may not stop immediately due to specific logic or condition that is required to execute before it can safely terminate. Thread can also terminate naturally when it finishes its execution, where it automatically exits, and its resources are released by the system (or saved to ",(0,s.jsx)(t.a,{href:"#thread-pool",children:"thread pool"}),")."]}),"\n",(0,s.jsxs)(t.p,{children:["It is important to note that thread termination should be handled carefully. For example, a thread may have used some data structure, but when it is not freed before the termination, this can cause ",(0,s.jsx)(t.a,{href:"/computer-security/other-attack-and-exploit#memory-leak",children:"memory leak"}),"."]}),"\n",(0,s.jsx)(t.h4,{id:"thread-execution--scheduling",children:"Thread Execution & Scheduling"}),"\n",(0,s.jsxs)(t.p,{children:["In Java, we can start the execution of a thread, by calling the ",(0,s.jsx)(t.code,{children:"start()"})," method on the ",(0,s.jsx)(t.code,{children:"Thread"})," object. The ",(0,s.jsx)(t.code,{children:"start()"})," method internally calls the thread's ",(0,s.jsx)(t.code,{children:"run()"})," method, which contains the code that will be executed by the thread. The JVM manages the execution of threads and ensures that the ",(0,s.jsx)(t.code,{children:"run()"})," method is executed concurrently with other threads."]}),"\n",(0,s.jsxs)(t.p,{children:["Thread scheduling in Java is handled by the JVM and the operating system. The JVM uses a ",(0,s.jsx)(t.a,{href:"/operating-system/process-management#multitasking",children:"preemptive scheduling algorithm"}),", where the operating system decides when to switch between threads. Similar to process scheduling, this involves ",(0,s.jsx)(t.a,{href:"/operating-system/process-management#context-switch",children:"context switch"})," to save the thread state, determining based on some ",(0,s.jsx)(t.a,{href:"/operating-system/process-management#scheduling-algorithms",children:"scheduling algorithm"}),"."]}),"\n",(0,s.jsxs)(t.p,{children:["Java provides methods like ",(0,s.jsx)(t.code,{children:"yield()"})," and ",(0,s.jsx)(t.code,{children:"sleep()"})," to influence thread scheduling. The ",(0,s.jsx)(t.code,{children:"yield()"})," method allows a thread to voluntarily give up its remaining time slice, allowing other threads to run. The ",(0,s.jsx)(t.code,{children:"sleep()"})," method pauses the execution of a thread for a specified period of time."]}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.img,{alt:"Thread state in Java",src:n(81155).Z+"",width:"552",height:"449"}),(0,s.jsx)(t.br,{}),"\n","Source : ",(0,s.jsx)(t.a,{href:"https://medium.com/spring-boot/multithreading-in-java-with-examples-25b0bc80831b",children:"https://medium.com/spring-boot/multithreading-in-java-with-examples-25b0bc80831b"})]}),"\n",(0,s.jsx)(t.h4,{id:"thread-communication",children:"Thread Communication"}),"\n",(0,s.jsxs)(t.p,{children:["Multiple threads exist within the same process, threads can communicate by sharing memory. They can read from and write to shared data structures or variables. Another way is communicating through ",(0,s.jsx)(t.strong,{children:(0,s.jsx)(t.a,{href:"#communication",children:"message passing"})}),", where they send messages or signals to each other. One thread can send a message to another thread, which then receives and processes the message."]}),"\n",(0,s.jsx)(t.h4,{id:"thread-synchronization",children:"Thread Synchronization"}),"\n",(0,s.jsxs)(t.p,{children:["Synchronizing threads is crucial to ensure proper coordination and consistency when multiple threads access shared resources while communicating, to prevent ",(0,s.jsx)(t.a,{href:"#multithreading-problems",children:"concurrency issues"}),"."]}),"\n",(0,s.jsxs)(t.p,{children:["When a code or data structure can be safely accessed and modified by multiple threads concurrently without causing unexpected or incorrect behavior, this is called ",(0,s.jsx)(t.strong,{children:(0,s.jsx)(t.a,{href:"/computer-and-programming-fundamentals/concurrency-and-parallelism#thread-safe",children:"thread safe"})}),"."]}),"\n",(0,s.jsx)(t.h5,{id:"synchronization-primitives",children:"Synchronization Primitives"}),"\n",(0,s.jsx)(t.p,{children:"These are fundamental tools used in multithreaded programming to synchronize."}),"\n",(0,s.jsx)(t.h6,{id:"locks--mutex",children:"Locks / Mutex"}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"Mutex (mutual exclusion)"})," is a synchronization primitive that ensure only one thread to access a shared resource. It works by having a lock, a thread that wants to access the resource must acquire the lock first. If the lock is already held by another thread, the requesting thread will be blocked until the lock is released. When the thread that access the resource has finished, then the lock will be released."]}),"\n",(0,s.jsx)(t.p,{children:"The mutex technique can be implemented in the software-level by memory synchronization instructions provided by the hardware architecture."}),"\n",(0,s.jsx)(t.h6,{id:"condition-variables",children:"Condition Variables"}),"\n",(0,s.jsx)(t.p,{children:"Condition variables are synchronization primitives that allow threads to wait for a specific condition to become true before proceeding with their execution. They are typically used in conjunction with locks/mutexes to enable efficient thread coordination and synchronization."}),"\n",(0,s.jsx)(t.h6,{id:"semaphores",children:"Semaphores"}),"\n",(0,s.jsx)(t.p,{children:"Semaphore allows specified number of thread to access a shared resource. A semaphore maintains a count, and when a thread wants to access resource, it attempts to acquire the semaphore. If the count is greater than zero, the thread is allowed to proceed, and the count is decremented. If the count is zero, indicating that the resource is currently in use, the thread will be blocked until another thread releases the semaphore, which increments the count."}),"\n",(0,s.jsx)(t.h6,{id:"barriers",children:"Barriers"}),"\n",(0,s.jsx)(t.p,{children:"Barriers synchronize a group of threads at a specific point in code. Threads reach the barrier and wait until all participating threads have arrived. Once all threads have reached the barrier, they are released simultaneously, allowing them to continue their execution."}),"\n",(0,s.jsx)(t.h6,{id:"spinlocks",children:"Spinlocks"}),"\n",(0,s.jsx)(t.p,{children:'Spinlock is when a thread "spins", which means that it continuously executes a loop, frequently checking a condition or waiting for a certain state to be reached.'}),"\n",(0,s.jsx)(t.p,{children:"The basic idea of a spinlock is that a thread attempting to acquire the lock repeatedly checks if the lock is available in a tight loop, spinning until it becomes available. The thread keeps spinning until it successfully acquires the lock, at which point it can proceed with the critical section of code or the shared resource it wants to access."}),"\n",(0,s.jsx)(t.p,{children:"This differs from traditional locks where the thread would be put to sleep if the lock is unavailable. Spinlocks are useful in situations where the expected wait time for acquiring a lock is very short, and the overhead of putting a thread to sleep and waking it up is considered too costly."}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.img,{alt:"Various synchronization primitives",src:n(29277).Z+"",width:"1111",height:"437"}),(0,s.jsx)(t.br,{}),"\n","Source : ",(0,s.jsx)(t.a,{href:"https://www.javatpoint.com/mutex-vs-semaphore",children:"mutex"}),", ",(0,s.jsx)(t.a,{href:"https://stackoverflow.com/questions/34519/what-is-a-semaphore",children:"semaphores"}),", ",(0,s.jsx)(t.a,{href:"https://www.ictdemy.com/java/threads/multithreading-in-java-barrier-countdownlatch",children:"barriers"}),", ",(0,s.jsx)(t.a,{href:"https://www.quora.com/What-are-the-advantages-and-disadvantages-of-using-a-spinlock-in-the-kernel-of-an-operating-system-keep-in-mind-there-may-be-multiple-processors",children:"spinlocks"})]}),"\n",(0,s.jsx)(t.h5,{id:"atomic-operation",children:"Atomic Operation"}),"\n",(0,s.jsx)(t.p,{children:"Atomic operations are operations that are guaranteed to be executed atomically, without interruption. They provide a way to perform thread-safe operations on shared variables without the need for locks or synchronization primitives. Atomic operations are typically used for simple operations like incrementing or decrementing a variable. Atomic operations can be supported by the OS or hardware, with specific instructions."}),"\n",(0,s.jsx)(t.h4,{id:"thread-pool",children:"Thread Pool"}),"\n",(0,s.jsx)(t.p,{children:"Thread pool is a technique to improve performance and resource management in multithreaded applications."}),"\n",(0,s.jsxs)(t.p,{children:["When there are pre-allocated threads which are waiting and ready to be used to execute tasks, they are stored in ",(0,s.jsx)(t.strong,{children:"thread pools"}),". Thread pool isn't just a place where you store thread after their creation, it is a place where you maintain a set of reusable threads. These threads are created in advance and added to the pool. When a task arrives, a thread from the pool is assigned to execute it. Once the task is completed, the thread is returned to the pool for reuse. Thread pool allows for efficient resource management, it helps to reduce the resource exhaustion when creating new thread."]}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.img,{alt:"Thread pool",src:n(82709).Z+"",width:"479",height:"214"}),(0,s.jsx)(t.br,{}),"\n","Source : ",(0,s.jsx)(t.a,{href:"https://dip-mazumder.medium.com/how-to-determine-java-thread-pool-size-a-comprehensive-guide-4f73a4758273",children:"https://dip-mazumder.medium.com/how-to-determine-java-thread-pool-size-a-comprehensive-guide-4f73a4758273"})]}),"\n",(0,s.jsx)(t.h3,{id:"multithreading-problems",children:"Multithreading Problems"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"Race conditions"})," : Race conditions occur when multiple threads access shared data concurrently and try to modify it simultaneously. This can lead to unpredictable and incorrect results, because each thread may observe the data differently, some may access it after modification, and so may not."]}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{alt:"Race condition",src:n(42174).Z+"",width:"819",height:"378"})}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"Starvation"})," : Starvation occurs when a thread is blocked from gaining access to required resources. This can lead to a thread not making progress and adversely affect overall system performance."]}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"Deadlocks"})," : Deadlocks occurs when two or more threads are blocked indefinitely waiting for each other."]}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.img,{alt:"Deadlock",src:n(9560).Z+"",width:"380",height:"257"}),(0,s.jsx)(t.br,{}),"\n","Source : ",(0,s.jsx)(t.a,{href:"https://en.wikipedia.org/wiki/Deadlock",children:"https://en.wikipedia.org/wiki/Deadlock"})]}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"Livelock"})," : Livelock is similar to a deadlock, but in a livelock, the processes or threads are not blocked or waiting for a resource explicitly. Instead, they are continuously reacting to each other's actions in a way that prevents any of them from making forward progress."]}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.img,{alt:"Livelock",src:n(44602).Z+"",width:"636",height:"422"}),(0,s.jsx)(t.br,{}),"\n","Source : ",(0,s.jsx)(t.a,{href:"http://15418.courses.cs.cmu.edu/spring2014/lecture/snoopimpl1/slide_021",children:"http://15418.courses.cs.cmu.edu/spring2014/lecture/snoopimpl1/slide_021"})]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(t.h3,{id:"communication",children:"Communication"}),"\n",(0,s.jsxs)(t.p,{children:["Communication is essential to coordinate between thread and processes. There are mainly two technique, ",(0,s.jsx)(t.strong,{children:"shared memory"})," and ",(0,s.jsx)(t.strong,{children:"message passing"}),"."]}),"\n",(0,s.jsx)(t.h4,{id:"shared-memory",children:"Shared Memory"}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"Shared Memory"})," is typically used for thread, but can also be used for process communication. The implementation is simple, a portion of memory is allocated and made accessible to multiple processes for read and write. However, this communication mechanism may require ",(0,s.jsx)(t.a,{href:"#thread-synchronization",children:"additional synchronization technique"})," to prevent ",(0,s.jsx)(t.a,{href:"#multithreading-problems",children:"concurrency issues"}),"."]}),"\n",(0,s.jsx)(t.h4,{id:"message-passing",children:"Message Passing"}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"Message Passing"}),' is an act of communication between processes or thread without using shared memory, it is inherently associated with "message".']}),"\n",(0,s.jsx)(t.p,{children:"Message passing can be synchronous or asynchronous. In the synchronous model, the sender process blocks until the message is received by the recipient process. In the asynchronous model, the sender process continues execution immediately after sending the message, without waiting for a response from the recipient. The recipient process can receive the message at a later time."}),"\n",(0,s.jsx)(t.p,{children:"Some example of message passing :"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"Pipes"})," : Pipes are a form of ",(0,s.jsx)(t.a,{href:"/operating-system/inter-process-communication",children:"inter-process communication (IPC)"})," that allows the output of one process to be used as the input of another process. In a pipe, data flows in a unidirectional manner from the writer process to the reader process. Pipes can be either named or unnamed, with unnamed pipes typically used for communication between related processes (e.g., parent-child processes)."]}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"Sockets"})," : Sockets are a communication endpoint that enables bidirectional communication between processes over a network. They can be used for IPC within the same machine (domain sockets) or across different machines (network sockets)."]}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:(0,s.jsx)(t.a,{href:"/backend-development/message-broker#message-broker",children:"Message Queues"})})," : Message queues is where processes exchange messages through a shared ",(0,s.jsx)(t.a,{href:"/data-structures-and-algorithms/queue",children:"queue"})," in the operating system. Each message has a specific format and is placed into the queue by the sending process. The receiving process can then retrieve messages from the queue in a first-in-first-out (FIFO) order."]}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"Channels"})," : Channels is a higher-level concept for message passing. Channels typically provide a set of operations, such as sending and receiving messages, and may incorporate synchronization mechanisms like blocking or non-blocking operations. Channels can be implemented using various underlying mechanisms, including shared memory, pipes, or sockets."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.img,{alt:"Message passing",src:n(32973).Z+"",width:"379",height:"205"}),(0,s.jsx)(t.br,{}),"\n","Source : ",(0,s.jsx)(t.a,{href:"https://beingintelligent.com/difference-between-shared-memory-and-message-passing-process-communication.html",children:"https://beingintelligent.com/difference-between-shared-memory-and-message-passing-process-communication.html"})]}),"\n",(0,s.jsx)(t.admonition,{type:"tip",children:(0,s.jsxs)(t.p,{children:["In relation to concurrency, see also ",(0,s.jsx)(t.a,{href:"/computer-and-programming-fundamentals/concurrency-and-parallelism",children:"concurrency and parallelism"}),"."]})})]})}function l(e={}){const{wrapper:t}={...(0,i.a)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},9560:(e,t,n)=>{n.d(t,{Z:()=>s});const s=n.p+"assets/images/deadlock-cae19d8db430f8355244b5ae6e57977f.gif"},44602:(e,t,n)=>{n.d(t,{Z:()=>s});const s=n.p+"assets/images/livelock-3ef0ca56e62834558f82634e28a83877.png"},32973:(e,t,n)=>{n.d(t,{Z:()=>s});const s=n.p+"assets/images/message-passing-2aa51aaf5dd6d447bf1a3f5185fc2d9e.png"},34611:(e,t,n)=>{n.d(t,{Z:()=>s});const s=n.p+"assets/images/multithread-9188c0330bdee33732c95c88e88325d7.png"},42174:(e,t,n)=>{n.d(t,{Z:()=>s});const s=n.p+"assets/images/race-condition-2409cdf955c3ea05e59fee5de1c766ae.png"},90637:(e,t,n)=>{n.d(t,{Z:()=>s});const s=n.p+"assets/images/relationship-model-c899acc248ce46e84641242df298f23a.png"},29277:(e,t,n)=>{n.d(t,{Z:()=>s});const s=n.p+"assets/images/synchronization-primitives-b7c9a816689cced423c6740ea47590c5.png"},35354:(e,t,n)=>{n.d(t,{Z:()=>s});const s=n.p+"assets/images/thread-creation-992c1a16f51cb5b9cffa5338804acd5d.png"},82709:(e,t,n)=>{n.d(t,{Z:()=>s});const s=n.p+"assets/images/thread-pool-adb1157d7d2b6e29c6bab18fdb8eb502.png"},81155:(e,t,n)=>{n.d(t,{Z:()=>s});const s=n.p+"assets/images/thread-state-in-java-f97c0ed50e4fbf6a9fe666737179fd9b.png"},11151:(e,t,n)=>{n.d(t,{Z:()=>o,a:()=>r});var s=n(67294);const i={},a=s.createContext(i);function r(e){const t=s.useContext(a);return s.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:r(e.components),s.createElement(a.Provider,{value:t},e.children)}}}]);