"use strict";(self.webpackChunkcs_notes=self.webpackChunkcs_notes||[]).push([[6126],{27522:(e,s,n)=>{n.r(s),n.d(s,{assets:()=>l,contentTitle:()=>r,default:()=>c,frontMatter:()=>a,metadata:()=>o,toc:()=>h});var t=n(85893),i=n(11151);const a={slug:"/database-system/query-processing",id:"query-processing",title:"Query Processing",description:"Query Processing"},r=void 0,o={id:"database-system/query-processing/query-processing",title:"Query Processing",description:"Query Processing",source:"@site/docs/database-system/13-query-processing/query-processing.md",sourceDirName:"database-system/13-query-processing",slug:"/database-system/query-processing",permalink:"/cs-notes/database-system/query-processing",draft:!1,unlisted:!1,editUrl:"https://github.com/glennhenry/cs-notes/tree/main/docs/database-system/13-query-processing/query-processing.md",tags:[],version:"current",lastUpdatedBy:"glennhenry",lastUpdatedAt:1707130823,formattedLastUpdatedAt:"Feb 5, 2024",frontMatter:{slug:"/database-system/query-processing",id:"query-processing",title:"Query Processing",description:"Query Processing"},sidebar:"sidebar",previous:{title:"Index Implementation",permalink:"/cs-notes/database-system/index-implementation"},next:{title:"Concurrency Control",permalink:"/cs-notes/database-system/concurrency-control"}},l={},h=[{value:"Physical-Query-Plan Operators",id:"physical-query-plan-operators",level:3},{value:"Query Processing",id:"query-processing",level:3},{value:"One-Pass Algorithms",id:"one-pass-algorithms",level:4},{value:"Nested-Loop Join",id:"nested-loop-join",level:4},{value:"Two-Pass Algorithm",id:"two-pass-algorithm",level:4},{value:"Sorting-Based",id:"sorting-based",level:5},{value:"Hashing-Based",id:"hashing-based",level:5},{value:"Index-Based Algorithms",id:"index-based-algorithms",level:4},{value:"Buffer Management",id:"buffer-management",level:4},{value:"Architecture",id:"architecture",level:5},{value:"Strategies",id:"strategies",level:5},{value:"Query Compiler",id:"query-compiler",level:3}];function d(e){const s={a:"a",admonition:"admonition",annotation:"annotation",br:"br",h3:"h3",h4:"h4",h5:"h5",img:"img",li:"li",math:"math",mi:"mi",mn:"mn",mo:"mo",mrow:"mrow",p:"p",semantics:"semantics",span:"span",strong:"strong",ul:"ul",...(0,i.a)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(s.p,{children:(0,t.jsx)(s.strong,{children:"Main Source :"})}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsx)(s.li,{children:(0,t.jsx)(s.strong,{children:"Chapter 15, 16 - Database Systems - The Complete Book (2nd Edition)"})}),"\n"]}),"\n",(0,t.jsx)(s.p,{children:"701-757 query execution\n759-841 query compiler"}),"\n",(0,t.jsx)(s.p,{children:"The process of query goes from parsing, creating the unoptimized initial query plan (also called logical query plan) in algebraic representation, and transforming it into optimized physical query plan."}),"\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.img,{alt:"Process of query",src:n(8194).Z+"",width:"335",height:"417"}),(0,t.jsx)(s.br,{}),"\n","Source : Book page 703"]}),"\n",(0,t.jsx)(s.h3,{id:"physical-query-plan-operators",children:"Physical-Query-Plan Operators"}),"\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"Physical-Query-Plan Operators"})," are the component of query planning that does a specific step of a plan, which often correspond to an operation in relational algebra."]}),"\n",(0,t.jsx)(s.p,{children:"The physical query plan is generated after the query has been compiled into a logical query plan, which is similar to expressions of relational algebra. The generation of physical query plan involve these operators."}),"\n",(0,t.jsxs)(s.p,{children:["An example of physical-query-plan operator is ",(0,t.jsx)(s.strong,{children:"scanning table"}),". Scanning table operators read table and its record, they are useful for us to know the table's data. There are three approach of scanning table :"]}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.strong,{children:"Table-scan"})," : Read record in the block one by one."]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.strong,{children:"Index-scan"})," : Uses index to read the blocks and records."]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.strong,{children:"Sort-scan"})," : If the table can fit in main-memory, we may sort it and read the records."]}),"\n"]}),"\n",(0,t.jsx)(s.h3,{id:"query-processing",children:"Query Processing"}),"\n",(0,t.jsx)(s.h4,{id:"one-pass-algorithms",children:"One-Pass Algorithms"}),"\n",(0,t.jsxs)(s.p,{children:["In the case of database, ",(0,t.jsx)(s.strong,{children:"one-pass algorithms"})," are category of algorithms that reads data from the disk, process it, and write the results back in the disk, all in one pass."]}),"\n",(0,t.jsx)(s.p,{children:"There are three types of one-pass algorithms :"}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsxs)(s.li,{children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"Tuple-at-a-time, unary operations"})," : Read and process one block at a time, require small amount memory. This type of algorithms includes common operation like projection and selection. These kinds of operations are implemented by loading records from the disk into the input buffer and the operation is performed on them. The result of the operation goes to the output buffer."]}),"\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.img,{alt:"Tuple-at-a-time",src:n(51080).Z+"",width:"525",height:"224"}),(0,t.jsx)(s.br,{}),"\n","Source : Book page 711"]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"Full-relation, unary operations"})," : Require most or all record, the amount of record processed at once is limited to the memory buffers available, this includes grouping and eliminating duplicate operation."]}),"\n",(0,t.jsx)(s.p,{children:"The process of eliminating duplicate is similar to the previous operation. Before sending the result to the output buffer, we will first check if the record has been seen before. The previously seen record is stored at another buffer, we may use hash table to speed up the search."}),"\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.img,{alt:"Eliminating duplicate",src:n(42006).Z+"",width:"515",height:"307"}),(0,t.jsx)(s.br,{}),"\n","Source : Book page 713"]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"Full-relation, binary operations"})," : Require most or all record and performed on two table or records, such as union and intersection. For example, set intersection can be done by storing the record of one set (table) into some buffer, and read the other set and see if the record is present in the buffer. If so, we can copy to the output buffer."]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(s.admonition,{type:"info",children:(0,t.jsx)(s.p,{children:"Unary operations are operation performed on single input, while binary is performed on two inputs."})}),"\n",(0,t.jsx)(s.h4,{id:"nested-loop-join",children:"Nested-Loop Join"}),"\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"Nested-Loop Join"})," is a family of algorithms that joins two tables. There are some variants of nested-loop join :"]}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsxs)(s.li,{children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"Tuple-Based"})," : A straightforward algorithm that loops over two sets (tables) and produce another tuple that satisfy certain join condition."]}),"\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.img,{alt:"Tuple-based join",src:n(78843).Z+"",width:"410",height:"91"}),(0,t.jsx)(s.br,{}),"\n","Source : Book page 719"]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"Block-Based"})," : The block-based algorithm is an improvement over tuple-based algorithm. It involves considering a block of tuples instead of individual tuple. Furthermore, to reduce the disk I/O operation, we will store as many tuple from the outer set in main memory."]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(s.h4,{id:"two-pass-algorithm",children:"Two-Pass Algorithm"}),"\n",(0,t.jsxs)(s.p,{children:["One-pass algorithms read data from disk, process it, and write the result back to the disk. In contrast, ",(0,t.jsx)(s.strong,{children:"two-pass algorithms"})," read from the disk again after writing the result."]}),"\n",(0,t.jsx)(s.p,{children:"Two-pass algorithm can be based on sorting and hash. Sorting-based algorithms use sorting technique to organize data in the first and second pass. Hashing-based algorithms use hash functions to partition the data into buckets in the first pass and second pass."}),"\n",(0,t.jsx)(s.h5,{id:"sorting-based",children:"Sorting-Based"}),"\n",(0,t.jsx)(s.p,{children:"Example of sorting-based algorithms :"}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsxs)(s.li,{children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"Two-Phase, Multiway Merge-Sort (TPMMS or 2PMMS)"})," : Algorithm to sort very large relations in two passes, consisting two phases. This algorithm is a variant of ",(0,t.jsx)(s.a,{href:"/data-structures-and-algorithms/divide-and-conquer#merge-sort",children:"merge sort"})," that is designed to handle large data that cannot fit in the main memory."]}),"\n",(0,t.jsx)(s.p,{children:"In phase 1, the algorithm sort the tuples from one relation in the main memory. The table is not entirely sorted, instead it repeatedly sorts the sublist of the relation. The sorted sublist is then written to the secondary storage."}),"\n",(0,t.jsxs)(s.p,{children:["In phase 2, the sorted sublists generated in phase 1 are merged together. However, there is a limitation on the number of sorted sublists that can be merged in this phase. The maximum number of sorted sublists allowed is ",(0,t.jsxs)(s.span,{className:"katex",children:[(0,t.jsx)(s.span,{className:"katex-mathml",children:(0,t.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,t.jsxs)(s.semantics,{children:[(0,t.jsxs)(s.mrow,{children:[(0,t.jsx)(s.mi,{children:"M"}),(0,t.jsx)(s.mo,{children:"\u2212"}),(0,t.jsx)(s.mn,{children:"1"})]}),(0,t.jsx)(s.annotation,{encoding:"application/x-tex",children:"M - 1"})]})})}),(0,t.jsxs)(s.span,{className:"katex-html","aria-hidden":"true",children:[(0,t.jsxs)(s.span,{className:"base",children:[(0,t.jsx)(s.span,{className:"strut",style:{height:"0.7667em",verticalAlign:"-0.0833em"}}),(0,t.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.10903em"},children:"M"}),(0,t.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2222em"}}),(0,t.jsx)(s.span,{className:"mbin",children:"\u2212"}),(0,t.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2222em"}})]}),(0,t.jsxs)(s.span,{className:"base",children:[(0,t.jsx)(s.span,{className:"strut",style:{height:"0.6444em"}}),(0,t.jsx)(s.span,{className:"mord",children:"1"})]})]})]}),", where ",(0,t.jsxs)(s.span,{className:"katex",children:[(0,t.jsx)(s.span,{className:"katex-mathml",children:(0,t.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,t.jsxs)(s.semantics,{children:[(0,t.jsx)(s.mrow,{children:(0,t.jsx)(s.mi,{children:"M"})}),(0,t.jsx)(s.annotation,{encoding:"application/x-tex",children:"M"})]})})}),(0,t.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,t.jsxs)(s.span,{className:"base",children:[(0,t.jsx)(s.span,{className:"strut",style:{height:"0.6833em"}}),(0,t.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.10903em"},children:"M"})]})})]})," is the number of available main-memory buffers."]}),"\n",(0,t.jsx)(s.p,{children:"In the merging process, the smallest key among the remaining element in the sublist will be moved into the output block. This is done until the output block is full, if it is, then write it to the disk and create a new output block."}),"\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.img,{alt:"2PMMS algorithm",src:n(3091).Z+"",width:"477",height:"373"}),(0,t.jsx)(s.br,{}),"\n","Source : Book page 724"]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"Eliminate Duplication"})," : Based on sorting, we can remove duplicate tuples in a table easily. The first pass involve sorting the tuple into sublists, similar to the first phase of 2PMMS. In the second pass, we repeatedly select the tuples in the sorted sublists and copy the unconsidered tuple to the output block."]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"Join"})," : Given relations (tables) R(X, Y) and S(Y, Z) to join, where X and Y are attributes belong to R, same for Y and Z, which are attributes that belong to S. The process is as follows :"]}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsx)(s.li,{children:"Sort R and S using the 2PMMS algorithm, with Y as the sort key."}),"\n",(0,t.jsxs)(s.li,{children:["Merge the sorted S and R using two buffers, the merge process is the next step :","\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsx)(s.li,{children:"Find the smallest value based on the join attributes Y that appears at the front of both R and S."}),"\n",(0,t.jsx)(s.li,{children:"If that Y value doesn't appear at the front of the other relation, remove the tuple(s) with that Y value."}),"\n",(0,t.jsx)(s.li,{children:"If the Y value appears at the front of both R and S, identify all the tuples in R and S that have that Y value. If necessary, read more blocks from R and/or S until there are no more Y value in either relation."}),"\n",(0,t.jsx)(s.li,{children:"Output all the tuples that can be created by joining the identified tuples from R and S based on their common Y value."}),"\n",(0,t.jsx)(s.li,{children:"If either relation has no more unprocessed tuples in the memory, load more tuples from that relation into the buffer."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(s.h5,{id:"hashing-based",children:"Hashing-Based"}),"\n",(0,t.jsx)(s.p,{children:"In comparison to sorting-based algorithms :"}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.strong,{children:"Duplicate Elimination"})," : The idea is, same record will hash to same hash code, and will fall into the same bucket. Each record is hashed, so it is partitioned into different bucket. Within a bucket, only one copy of the duplicate records is kept, and the rest are removed. This method works as long as the table is small, so that no non-duplicate record in the same bucket."]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.strong,{children:"Join (Hash Join Algorithm)"})," : Similar to other operation, we will hash the record and partition them into buckets. Within a bucket, if the join attribute values match, the tuples are considered a match and can be combined."]}),"\n"]}),"\n",(0,t.jsx)(s.h4,{id:"index-based-algorithms",children:"Index-Based Algorithms"}),"\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"Index-based algorithms"})," is a set of algorithms that leverage ",(0,t.jsx)(s.a,{href:"/database-system/index",children:"database indexes"}),", such as selection and join."]}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.strong,{children:"Selection"})," :"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.strong,{children:"Unsorted Index Join"})," :"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.strong,{children:"Sorted Index Join"})," :"]}),"\n"]}),"\n",(0,t.jsx)(s.h4,{id:"buffer-management",children:"Buffer Management"}),"\n",(0,t.jsx)(s.p,{children:"Buffer management is concerned with the management and allocation of buffers in main memory, which is an area to hold data recently read from or written to disk."}),"\n",(0,t.jsx)(s.h5,{id:"architecture",children:"Architecture"}),"\n",(0,t.jsx)(s.h5,{id:"strategies",children:"Strategies"}),"\n",(0,t.jsx)(s.p,{children:"LRU, FIFO, clock/second chance"}),"\n",(0,t.jsx)(s.h3,{id:"query-compiler",children:"Query Compiler"}),"\n",(0,t.jsx)(s.p,{children:"parsing preprocessing\nquery plans\nestimation, heuristics"})]})}function c(e={}){const{wrapper:s}={...(0,i.a)(),...e.components};return s?(0,t.jsx)(s,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},3091:(e,s,n)=>{n.d(s,{Z:()=>t});const t=n.p+"assets/images/2pmms-64973ae2d8a161d36880d4ff2730d77f.png"},42006:(e,s,n)=>{n.d(s,{Z:()=>t});const t=n.p+"assets/images/eliminate-duplicate-1a1203dc27dafb26663acebd69061d8b.png"},8194:(e,s,n)=>{n.d(s,{Z:()=>t});const t=n.p+"assets/images/query-process-1684aa6480ff8ed121a5293ca64bf1ae.png"},51080:(e,s,n)=>{n.d(s,{Z:()=>t});const t=n.p+"assets/images/tuple-at-a-time-328da3f3cea11393a67dd79791b52792.png"},78843:(e,s,n)=>{n.d(s,{Z:()=>t});const t=n.p+"assets/images/tuple-based-18fd279f2e92ea83d4bed108b7be5f8c.png"},11151:(e,s,n)=>{n.d(s,{Z:()=>o,a:()=>r});var t=n(67294);const i={},a=t.createContext(i);function r(e){const s=t.useContext(a);return t.useMemo((function(){return"function"==typeof e?e(s):{...s,...e}}),[s,e])}function o(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:r(e.components),t.createElement(a.Provider,{value:s},e.children)}}}]);