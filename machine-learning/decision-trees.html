<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-machine-learning/decision-trees/decision-trees" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.1.0">
<title data-rh="true">Decision Trees | CS Notes</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://glennhenry.github.io/cs-notes/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://glennhenry.github.io/cs-notes/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://glennhenry.github.io/cs-notes/machine-learning/decision-trees"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Decision Trees | CS Notes"><meta data-rh="true" name="description" content="Decision Trees"><meta data-rh="true" property="og:description" content="Decision Trees"><link data-rh="true" rel="icon" href="/cs-notes/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://glennhenry.github.io/cs-notes/machine-learning/decision-trees"><link data-rh="true" rel="alternate" href="https://glennhenry.github.io/cs-notes/machine-learning/decision-trees" hreflang="en"><link data-rh="true" rel="alternate" href="https://glennhenry.github.io/cs-notes/machine-learning/decision-trees" hreflang="x-default"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/cs-notes/assets/css/styles.318f8846.css">
<script src="/cs-notes/assets/js/runtime~main.82de7b47.js" defer="defer"></script>
<script src="/cs-notes/assets/js/main.5e115dad.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"dark")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top navbarHideable_m1mJ navbar--dark"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/cs-notes/"><div class="navbar__logo"><img src="/cs-notes/img/logo.svg" alt="Docusaurus Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/cs-notes/img/logo.svg" alt="Docusaurus Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Notes</b></a><a href="https://github.com/glennhenry/cs-notes" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Github<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/facebook/docusaurus" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Made with Docusaurus<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS darkNavbarColorModeToggle_X3D1" type="button" disabled="" title="Switch between dark and light mode (currently dark mode)" aria-label="Switch between dark and light mode (currently dark mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><div class="navbar__search"><span aria-label="expand searchbar" role="button" class="search-icon" tabindex="0"></span><input id="search_input_react" type="search" placeholder="Loading..." aria-label="Search" class="navbar__search-input search-bar" disabled=""></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd sidebarWithHideableNavbar_wUlq"><a tabindex="-1" class="sidebarLogo_isFc" href="/cs-notes/"><img src="/cs-notes/img/logo.svg" alt="Docusaurus Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/cs-notes/img/logo.svg" alt="Docusaurus Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"><b>Notes</b></a><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/cs-notes/">Intro</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/cs-notes/digital-signal-processing">Digital Signal Processing</a><button aria-label="Expand sidebar category &#x27;Digital Signal Processing&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/cs-notes/computer-and-programming-fundamentals">Computer &amp; Programming Fundamentals</a><button aria-label="Expand sidebar category &#x27;Computer &amp; Programming Fundamentals&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/cs-notes/digital-media-processing">Digital Media Processing</a><button aria-label="Expand sidebar category &#x27;Digital Media Processing&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/cs-notes/computer-networking">Computer Networking</a><button aria-label="Expand sidebar category &#x27;Computer Networking&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/cs-notes/data-structures-and-algorithms">Data Structures &amp; Algorithms</a><button aria-label="Expand sidebar category &#x27;Data Structures &amp; Algorithms&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/cs-notes/computer-organization-and-architecture">Computer Organization &amp; Architecture</a><button aria-label="Expand sidebar category &#x27;Computer Organization &amp; Architecture&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/cs-notes/operating-system">Operating System</a><button aria-label="Expand sidebar category &#x27;Operating System&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/cs-notes/theory-of-computation-and-automata">Theory of Computation &amp; Automata</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/cs-notes/compilers">Compilers</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/cs-notes/programming-language-theory">Programming Language Theory</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/cs-notes/database-system">Database System</a><button aria-label="Expand sidebar category &#x27;Database System&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/cs-notes/computer-graphics">Computer Graphics</a><button aria-label="Expand sidebar category &#x27;Computer Graphics&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/cs-notes/frontend-web-development">Frontend Web Development</a><button aria-label="Expand sidebar category &#x27;Frontend Web Development&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/cs-notes/backend-development">Backend Development</a><button aria-label="Expand sidebar category &#x27;Backend Development&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/cs-notes/computer-security">Computer Security</a><button aria-label="Expand sidebar category &#x27;Computer Security&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" href="/cs-notes/machine-learning">Machine Learning</a><button aria-label="Collapse sidebar category &#x27;Machine Learning&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/cs-notes/machine-learning/linear-regression">Linear Regression</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/cs-notes/machine-learning/logistic-regression">Logistic Regression</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/cs-notes/machine-learning/naive-bayes">Naive Bayes</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/cs-notes/machine-learning/k-nearest-neighbors">K-Nearest Neighbors</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/cs-notes/machine-learning/decision-trees">Decision Trees</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/cs-notes/machine-learning/random-forest">Random Forest</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/cs-notes/machine-learning/gradient-boosting-machine">Gradient Boosting Machine</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/cs-notes/machine-learning/support-vector-machine">Support Vector Machine</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/cs-notes/machine-learning/principal-component-analysis">Principal Component Analysis</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/cs-notes/machine-learning/k-means-clustering">k-Means Clustering</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/cs-notes/machine-learning/collaborative-filtering">Collaborative Filtering</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/cs-notes/deep-learning">Deep Learning</a><button aria-label="Expand sidebar category &#x27;Deep Learning&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/cs-notes/software-engineering">Software Engineering</a><button aria-label="Expand sidebar category &#x27;Software Engineering&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/cs-notes/cloud-computing">Cloud Computing</a><button aria-label="Expand sidebar category &#x27;Cloud Computing&#x27;" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/cs-notes/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/cs-notes/machine-learning"><span itemprop="name">Machine Learning</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Decision Trees</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Decision Trees</h1></header><p><strong>Main Source :</strong></p>
<ul>
<li><strong><a href="https://youtu.be/ZVR2Way4nwQ?si=tx3IEid6R97igFpY" target="_blank" rel="noopener noreferrer">Decision Tree Classification Clearly Explained! - Normalized Nerd</a></strong></li>
<li><strong><a href="https://youtu.be/UhY5vPfQIrA?si=cis0NaIiQysElvcp" target="_blank" rel="noopener noreferrer">Decision Tree Regression Clearly Explained! - Normalized Nerd</a></strong></li>
</ul>
<p><strong>Decision Trees</strong> is a machine learning algorithm also used to solve both classification and regression tasks. A decision tree is a flowchart-like structure where each internal node represents a feature or attribute, each branch represents a decision rule, and each leaf node represents the outcome or class label. The tree is built by recursively partitioning the data based on the values of different features, aiming to create homogeneous subsets of data at each internal node.</p>
<p>A decision tree is like a flowchart or a series of yes-or-no questions that helps make decisions or predictions. It consists of nodes that begins with the root node. At each step, the decision tree asks a question based on a feature (charateristics) and uses the answer to decide which path to follow.</p>
<p>The goal is to ask the most informative questions that help separate the fruits into different categories as accurately as possible. By following the path of questions, the decision tree eventually reaches a leaf node (the last node that has no children), which provides the final classification or prediction.</p>
<p><img loading="lazy" alt="Decision tree example" src="/cs-notes/assets/images/decision-tree-example-d16b618df35a821bf12ab8e89b53e72f.png" width="680" height="375" class="img_ev3q"><br>
<!-- -->Source : <a href="https://regenerativetoday.com/simple-explanation-on-how-decision-tree-algorithm-makes-decisions/" target="_blank" rel="noopener noreferrer">https://regenerativetoday.com/simple-explanation-on-how-decision-tree-algorithm-makes-decisions/</a></p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="classification">Classification<a href="#classification" class="hash-link" aria-label="Direct link to Classification" title="Direct link to Classification">​</a></h3>
<p>Decision tree is used to classify data with no linear relationship between the features. To begin, we need to have a data with some features and their label (in case of classification, which group they belong to).</p>
<p>For example, the following image has 2 features which is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">x_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> in x-axis and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">x_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> in y-axis, the label or the group are red and green points.</p>
<p><img loading="lazy" alt="Data plotted" src="/cs-notes/assets/images/data-plotted-4aee736613123fe5dfc7d740a0fa6135.png" width="405" height="365" class="img_ev3q"><br>
<!-- -->Source : <a href="https://youtu.be/ZVR2Way4nwQ?si=KnrjjRrUxcUb423p&amp;t=126" target="_blank" rel="noopener noreferrer">https://youtu.be/ZVR2Way4nwQ?si=KnrjjRrUxcUb423p&amp;t=126</a></p>
<p>We will then make a decision tree which will decide if a point should belong to red or green points. The goal of making the decision tree is to classify a new data with unknown label by asking several question until it can be distinguished by any group based on features of data observed before.</p>
<p><img loading="lazy" alt="Decision tree asking question until it can be distinguished" src="/cs-notes/assets/images/decision-tree-classification-example-1-fb27837f7ebbd5f6ee586d5932300a72.png" width="628" height="352" class="img_ev3q"><br>
<!-- -->Source : <a href="https://youtu.be/ZVR2Way4nwQ?si=IL5ETPFD168sA8I5&amp;t=201" target="_blank" rel="noopener noreferrer">https://youtu.be/ZVR2Way4nwQ?si=IL5ETPFD168sA8I5&amp;t=201</a></p>
<p>In this case, the question we are asking is whether the features are greater than or lower than some values (marked by straight line in the plot). By creating this decision tree, we can decided an unknown labeled data.</p>
<p><img loading="lazy" alt="Decision tree for classifying new data" src="/cs-notes/assets/images/decision-tree-classification-example-2-c45a3bbd04c3584009e91fb2c2a49aca.png" width="748" height="323" class="img_ev3q"><br>
<!-- -->Source : <a href="https://youtu.be/ZVR2Way4nwQ?si=cDHANAN3Xw9o0nfr&amp;t=247" target="_blank" rel="noopener noreferrer">https://youtu.be/ZVR2Way4nwQ?si=cDHANAN3Xw9o0nfr&amp;t=247</a></p>
<p>As the problem get more complex, this may be not enough, there are also many possible decision tree we can make to classify the data that result the same with before.</p>
<h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="entropy">Entropy<a href="#entropy" class="hash-link" aria-label="Direct link to Entropy" title="Direct link to Entropy">​</a></h4>
<p>For example, we can choose to either split the data based on feature <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub><mo>≤</mo><mn>4</mn></mrow><annotation encoding="application/x-tex">x_1 \le 4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.786em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">4</span></span></span></span> or <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>0</mn></msub><mo>≤</mo><mo>−</mo><mn>12</mn></mrow><annotation encoding="application/x-tex">x_0 \le -12</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.786em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">−</span><span class="mord">12</span></span></span></span>, using the first one, we obtained a fully distinguished red point.</p>
<p><img loading="lazy" alt="Different information gain for different decision tree question" src="/cs-notes/assets/images/information-gain-934b182fc615404cde687ac8feb3ac3e.png" width="623" height="320" class="img_ev3q"><br>
<!-- -->Source : <a href="https://youtu.be/ZVR2Way4nwQ?si=HRwBlguUln_WyG-J&amp;t=387" target="_blank" rel="noopener noreferrer">https://youtu.be/ZVR2Way4nwQ?si=HRwBlguUln_WyG-J&amp;t=387</a></p>
<p>We need to determine the best feature to split the data at each node of the tree. They help in selecting the most informative features that provide the most significant reduction to fully distinguish the data (remember we need to classify data).</p>
<p>We can measure the impurity of the data in something called <strong>Entropy</strong>. It quantifies the randomness or unpredictability of the target labels in a given set of examples. The entropy is calculated using the formula :</p>
<p><img loading="lazy" alt="Entropy formula" src="/cs-notes/assets/images/entropy-formula-3b62c71bd8f27cff824a7ca9d349b95c.png" width="335" height="89" class="img_ev3q"><br>
<!-- -->Source : <a href="https://youtu.be/ZVR2Way4nwQ?si=mtRqZ92xXOGmF63W&amp;t=414" target="_blank" rel="noopener noreferrer">https://youtu.be/ZVR2Way4nwQ?si=mtRqZ92xXOGmF63W&amp;t=414</a></p>
<p>The entropy formula is the sum of the probability of all label within the group of data. The first group (root node), has equal red and green point, the probability will be a 0.5. Subtituting 0.5 for the green probability to the entropy formula and summing it with the red probability, we will obtain 1. The result of entropy measure of how unpredictable our data is. The higher entropy means the more unpredictable.</p>
<p><img loading="lazy" alt="Calculating entropy for each decision question" src="/cs-notes/assets/images/entropy-calculation-5aec09e4f582b90508a0ca0c94a9b237.png" width="372" height="260" class="img_ev3q"><br>
<!-- -->Source : <a href="https://youtu.be/ZVR2Way4nwQ?si=JLeix7YIUmRlxqPE&amp;t=474" target="_blank" rel="noopener noreferrer">https://youtu.be/ZVR2Way4nwQ?si=JLeix7YIUmRlxqPE&amp;t=474</a></p>
<h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="information-gain">Information Gain<a href="#information-gain" class="hash-link" aria-label="Direct link to Information Gain" title="Direct link to Information Gain">​</a></h4>
<p>And now we can measure how useful is the splitting the dataset based on specific feature by using <strong>information gain</strong>. A higher information gain indicates that the feature is more useful in separating the examples into different classes. Here is the formula :</p>
<p><img loading="lazy" alt="Calculating information gain" src="/cs-notes/assets/images/information-gain-formula-9250d1c13d53236176cfbf2f5cfc56e3.png" width="366" height="156" class="img_ev3q"><br>
<!-- -->Source : <a href="https://youtu.be/ZVR2Way4nwQ?si=SLLEhq-fNUcLhXuX&amp;t=508" target="_blank" rel="noopener noreferrer">https://youtu.be/ZVR2Way4nwQ?si=SLLEhq-fNUcLhXuX&amp;t=508</a></p>
<p>Using the formula, we achieve a higher information gain for the second decision (the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>o</mi></msub><mo>≤</mo><mo>−</mo><mn>12</mn></mrow><annotation encoding="application/x-tex">x_o \le -12</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.786em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">o</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">−</span><span class="mord">12</span></span></span></span>), we will then choose to use this question to split at the root node. We will keep doing this until we reached the maximum depth of branch or until we can finally fully distinguish all the data if possible.</p>
<p><img loading="lazy" alt="The result of decision tree" src="/cs-notes/assets/images/decision-tree-result-c55688b9e2cbf0691d84e65cc8a6c057.png" width="450" height="484" class="img_ev3q"><br>
<!-- -->Source : <a href="https://youtu.be/ZVR2Way4nwQ?si=0Z2d9Lfye5MEXgQu&amp;t=602" target="_blank" rel="noopener noreferrer">https://youtu.be/ZVR2Way4nwQ?si=0Z2d9Lfye5MEXgQu&amp;t=602</a></p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="regression">Regression<a href="#regression" class="hash-link" aria-label="Direct link to Regression" title="Direct link to Regression">​</a></h3>
<p>Decision trees can also be used for regression tasks, the goal is to predict a continuous numerical value rather than a categorical label. When applying decision trees to regression, the basic structure and principles are similar to decision trees for classification, but with some differences in the way splits and predictions are made.</p>
<p>Instead of using measures like entropy or information gain, decision trees for regression uses variance as the measure of the impurity of the data. The higher variance means the higher impurity, the variance is calculated using the following formula :</p>
<p><img loading="lazy" alt="Variance formula" src="/cs-notes/assets/images/variance-measure-0a965fae0b7c2cffee6b77a4e9a1af10.png" width="500" height="310" class="img_ev3q"><br>
<!-- -->Source : <a href="https://youtu.be/UhY5vPfQIrA?si=FXGyFY6aCQPYlYZy&amp;t=424" target="_blank" rel="noopener noreferrer">https://youtu.be/UhY5vPfQIrA?si=FXGyFY6aCQPYlYZy&amp;t=424</a></p>
<p>After calculating the variance, we can then calculate the variance reduction, it is similar to what information gain is in classification. The higher variance reduction means the better split we have. We will keep doing this again until certain conditions are satisfied.</p>
<p>The splitting process in a regression decision tree involves selecting a feature and a split point that minimizes the chosen error metric. The quality of the split will be measured in mean squared error (MSE) or mean absolute error (MAE).</p>
<p><img loading="lazy" alt="Variance reduction calculation" src="/cs-notes/assets/images/variance-calculation-0ea8d729ea127424ee01c8ccb0921cce.png" width="442" height="399" class="img_ev3q"><br>
<!-- -->Source : <a href="https://youtu.be/UhY5vPfQIrA?si=S5jc_TZ0jmgT3ceS&amp;t=496" target="_blank" rel="noopener noreferrer">https://youtu.be/UhY5vPfQIrA?si=S5jc_TZ0jmgT3ceS&amp;t=496</a></p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/glennhenry/cs-notes/tree/main/docs/machine-learning/05-decision-trees/decision-trees.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2024-01-26T09:55:29.000Z">Jan 26, 2024</time></b> by <b>glennhenry</b></span></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/cs-notes/machine-learning/k-nearest-neighbors"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">K-Nearest Neighbors</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/cs-notes/machine-learning/random-forest"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Random Forest</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#classification" class="table-of-contents__link toc-highlight">Classification</a><ul><li><a href="#entropy" class="table-of-contents__link toc-highlight">Entropy</a></li><li><a href="#information-gain" class="table-of-contents__link toc-highlight">Information Gain</a></li></ul></li><li><a href="#regression" class="table-of-contents__link toc-highlight">Regression</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 My Project, Inc. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>