<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-deep-learning/gan/gan" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.1.1">
<title data-rh="true">GAN | CS Notes</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://glennhenry.github.io/cs-notes/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://glennhenry.github.io/cs-notes/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://glennhenry.github.io/cs-notes/deep-learning/gan"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="GAN | CS Notes"><meta data-rh="true" name="description" content="GAN"><meta data-rh="true" property="og:description" content="GAN"><link data-rh="true" rel="icon" href="/cs-notes/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://glennhenry.github.io/cs-notes/deep-learning/gan"><link data-rh="true" rel="alternate" href="https://glennhenry.github.io/cs-notes/deep-learning/gan" hreflang="en"><link data-rh="true" rel="alternate" href="https://glennhenry.github.io/cs-notes/deep-learning/gan" hreflang="x-default"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/cs-notes/assets/css/styles.319c3a75.css">
<script src="/cs-notes/assets/js/runtime~main.3bed0415.js" defer="defer"></script>
<script src="/cs-notes/assets/js/main.5ee6b9cc.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"dark")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top navbarHideable_m1mJ navbar--dark"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/cs-notes/"><div class="navbar__logo"><img src="/cs-notes/img/logo.svg" alt="Docusaurus Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/cs-notes/img/logo.svg" alt="Docusaurus Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Notes</b></a><a href="https://github.com/glennhenry/cs-notes" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Github<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/facebook/docusaurus" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Made with Docusaurus<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><a class="navbar__item navbar__link" href="/cs-notes/index">Index</a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS darkNavbarColorModeToggle_X3D1" type="button" disabled="" title="Switch between dark and light mode (currently dark mode)" aria-label="Switch between dark and light mode (currently dark mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><div class="navbar__search"><span aria-label="expand searchbar" role="button" class="search-icon" tabindex="0"></span><input id="search_input_react" type="search" placeholder="Loading..." aria-label="Search" class="navbar__search-input search-bar" disabled=""></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd sidebarWithHideableNavbar_wUlq"><a tabindex="-1" class="sidebarLogo_isFc" href="/cs-notes/"><img src="/cs-notes/img/logo.svg" alt="Docusaurus Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/cs-notes/img/logo.svg" alt="Docusaurus Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"><b>Notes</b></a><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/cs-notes/">Intro</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/cs-notes/index">Index</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/cs-notes/digital-signal-processing">Digital Signal Processing</a><button aria-label="Expand sidebar category &#x27;Digital Signal Processing&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/cs-notes/computer-and-programming-fundamentals">Computer &amp; Programming Fundamentals</a><button aria-label="Expand sidebar category &#x27;Computer &amp; Programming Fundamentals&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/cs-notes/digital-media-processing">Digital Media Processing</a><button aria-label="Expand sidebar category &#x27;Digital Media Processing&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/cs-notes/computer-networking">Computer Networking</a><button aria-label="Expand sidebar category &#x27;Computer Networking&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/cs-notes/data-structures-and-algorithms">Data Structures &amp; Algorithms</a><button aria-label="Expand sidebar category &#x27;Data Structures &amp; Algorithms&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/cs-notes/computer-organization-and-architecture">Computer Organization &amp; Architecture</a><button aria-label="Expand sidebar category &#x27;Computer Organization &amp; Architecture&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/cs-notes/operating-system">Operating System</a><button aria-label="Expand sidebar category &#x27;Operating System&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/cs-notes/theory-of-computation-and-automata">Theory of Computation &amp; Automata</a><button aria-label="Expand sidebar category &#x27;Theory of Computation &amp; Automata&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/cs-notes/programming-language-theory">Programming Language Theory</a><button aria-label="Expand sidebar category &#x27;Programming Language Theory&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/cs-notes/compilers">Compilers</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/cs-notes/database-system">Database System</a><button aria-label="Expand sidebar category &#x27;Database System&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/cs-notes/computer-graphics">Computer Graphics</a><button aria-label="Expand sidebar category &#x27;Computer Graphics&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/cs-notes/frontend-web-development">Frontend Web Development</a><button aria-label="Expand sidebar category &#x27;Frontend Web Development&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/cs-notes/backend-development">Backend Development</a><button aria-label="Expand sidebar category &#x27;Backend Development&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/cs-notes/computer-security">Computer Security</a><button aria-label="Expand sidebar category &#x27;Computer Security&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/cs-notes/machine-learning">Machine Learning</a><button aria-label="Expand sidebar category &#x27;Machine Learning&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" href="/cs-notes/deep-learning">Deep Learning</a><button aria-label="Collapse sidebar category &#x27;Deep Learning&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/cs-notes/deep-learning/deep-learning-foundation">Deep Learning Foundation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/cs-notes/deep-learning/deep-learning-tasks">Deep Learning Tasks</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/cs-notes/deep-learning/neural-network">Neural Network</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/cs-notes/deep-learning/cnn">CNN</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/cs-notes/deep-learning/resnet">ResNet</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/cs-notes/deep-learning/u-net">U-Net</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/cs-notes/deep-learning/siamese-network">Siamese Network</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/cs-notes/deep-learning/rnn">RNN</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/cs-notes/deep-learning/lstm">LSTM</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/cs-notes/deep-learning/gru">GRU</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/cs-notes/deep-learning/autoencoder">Autoencoder</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/cs-notes/deep-learning/variational-autoencoder">Variational Autoencoder</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/cs-notes/deep-learning/gan">GAN</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/cs-notes/deep-learning/transformers/attention-mechanism">Transformers</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/cs-notes/deep-learning/diffusion-model">Diffusion Model</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/cs-notes/deep-learning/reinforcement-learning/reinforcement-learning-fundamental">Reinforcement Learning</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/cs-notes/software-engineering">Software Engineering</a><button aria-label="Expand sidebar category &#x27;Software Engineering&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/cs-notes/cloud-computing-and-distributed-systems">Cloud Computing &amp; Distributed Systems</a><button aria-label="Expand sidebar category &#x27;Cloud Computing &amp; Distributed Systems&#x27;" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/cs-notes/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/cs-notes/deep-learning"><span itemprop="name">Deep Learning</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">GAN</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>GAN</h1></header><p><strong>Main Source :</strong></p>
<ul>
<li><strong><a href="https://developers.google.com/machine-learning/gan" target="_blank" rel="noopener noreferrer">Google ML GAN Course</a></strong></li>
<li><strong><a href="https://youtu.be/QJOEmwvnmTM?si=NiUmbLBTvcLh7wVb" target="_blank" rel="noopener noreferrer">WGANs: A stable alternative to traditional GANs || Wasserstein GAN - Developers Hutt</a></strong></li>
<li><strong><a href="https://youtu.be/yyqfZfnSzcw?si=WFBY7i7f-yAKT_i9" target="_blank" rel="noopener noreferrer">VAE-GAN Explained! - Connor Shorten</a></strong></li>
<li><strong><a href="https://youtu.be/-8hfnlxEPn4?si=nUnHWj5NL1H9Q2DN" target="_blank" rel="noopener noreferrer">CycleGAN Explained in 5 Minutes! - Matchue</a></strong></li>
</ul>
<p><strong>Generative Adversarial Network (GAN)</strong> is a machine learning framework specifically used to generate data. GANs are a generative model, similar as <a href="/cs-notes/deep-learning/variational-autoencoder">variational autoencoder (VAE)</a>, meaning they generate new samples that are similar to the training data. We feed some data to the model, the model will capture the pattern and common structure of the data to generate new instance of data.</p>
<p>GAN can be used to generate new images, audio, video, or generating next word in a sentence.</p>
<p>GAN consist of two components: the <strong>generator</strong> and the <strong>discriminator</strong>. The generator is responsible for generating new data samples, while the discriminator acts as a binary classifier, distinguishing between different types of data. GANs is an unsupervised learning because they do not rely on labeled data with correct outputs or labels.</p>
<p>The idea behind GANs is that the generator produces new data, and the discriminator which is able to differentiate between different types of data, in this case the discriminator differentiate between real or fake data, act as a critic that provides feedback to the generator to improve its data generation capabilities.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="adversarial-training">Adversarial Training<a href="#adversarial-training" class="hash-link" aria-label="Direct link to Adversarial Training" title="Direct link to Adversarial Training">​</a></h3>
<p>Both generator and discriminator are trained in adversarial way, the generator&#x27;s objective is to produce new samples that can fool the discriminator, while the discriminator&#x27;s objective is to accurately distinguish between real and fake samples.</p>
<p>The discriminator takes input from the data generated by the generator and the data from training samples. The data are combined together, every data from generator is labeled as fake and every data from the training samples is labeled as real.</p>
<p>The loss will be calculated from the classification result, the loss represent how good is the data generated by the generator and how correct is the classification of the discriminator.</p>
<p>GAN is considered as a <strong>minimax game</strong> or a <strong>zero-sum game</strong>, which is a mathematical game concept that represents a competitive interaction between two players. The goal of one player is to minimize their maximum possible loss (minimizer), while the goal of the other player is to maximize their minimum possible gain (maximizer).</p>
<p>In this case, the generator aims to minimize the discriminator&#x27;s ability to differentiate between real and fake samples, while the discriminator aims to maximize its ability to correctly classify real and fake samples.</p>
<p><img decoding="async" loading="lazy" alt="GAN mechanism between generator and discriminator" src="/cs-notes/assets/images/gan-mechanism-77e13606a12da22ef72d4535f02e33a7.png" width="771" height="339" class="img_ev3q"><br>
<!-- -->Source : <a href="https://sthalles.github.io/intro-to-gans/" target="_blank" rel="noopener noreferrer">https://sthalles.github.io/intro-to-gans/</a></p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="generator">Generator<a href="#generator" class="hash-link" aria-label="Direct link to Generator" title="Direct link to Generator">​</a></h3>
<p>The generator first takes a random input usually sampled from a normal or uniform distribution. The random input is often referred as <strong>latent vector</strong> or <strong>noise vector</strong>, which is a term for features that captures the charateristics of data. However, since it&#x27;s just a random input they don&#x27;t have necesarry meaning, they simply serve as a random seed for the starting point.</p>
<p><img decoding="async" loading="lazy" alt="Random noises as input" src="/cs-notes/assets/images/random-noise-8450cd8b68c6e17dfe0a61a252989ca1.png" width="233" height="175" class="img_ev3q"><br>
<!-- -->Source : <a href="https://www.researchgate.net/figure/The-semi-supervised-GAN-architecture-Random-noise-is-used-by-the-Generator-to-generate_fig4_335359919" target="_blank" rel="noopener noreferrer">https://www.researchgate.net/figure/The-semi-supervised-GAN-architecture-Random-noise-is-used-by-the-Generator-to-generate_fig4_335359919</a> (with modification)</p>
<p>The random input will then be transformed into a higher-dimensional representation. They are passed into some neural network architecture such as <a href="/cs-notes/deep-learning/cnn">convolutional neural network</a> for image related tasks that also include <a href="/cs-notes/deep-learning/deep-learning-foundation">activation function</a> to enable the network to capture complex patterns.</p>
<p>The final layer of generator produces the generated data, which could be images, text, or any other type of data depending on the application. The generated sample are then fed into discriminator to be classified.</p>
<p><img decoding="async" loading="lazy" alt="Generator" src="/cs-notes/assets/images/generator-1537b2da6c092a8b0b408d9aebc459f4.png" width="615" height="252" class="img_ev3q"><br>
<!-- -->Source : <a href="https://towardsdatascience.com/dcgans-deep-convolutional-generative-adversarial-networks-c7f392c2c8f8" target="_blank" rel="noopener noreferrer">https://towardsdatascience.com/dcgans-deep-convolutional-generative-adversarial-networks-c7f392c2c8f8</a></p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="discriminator">Discriminator<a href="#discriminator" class="hash-link" aria-label="Direct link to Discriminator" title="Direct link to Discriminator">​</a></h3>
<p>The discriminator can be any network architecture capable of classifying, if it&#x27;s an image related task, <a href="/cs-notes/deep-learning/cnn">convolutional neural network</a> can be used. The input data will be combined from the training samples and the generated samples. They will be labeled as fake or real and the discriminator will assign probability or how likely is the data to be real or fake.</p>
<h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="training-process">Training Process<a href="#training-process" class="hash-link" aria-label="Direct link to Training Process" title="Direct link to Training Process">​</a></h4>
<p>In GAN, the training process of both generator and discriminator are closely related. When the discriminator fails, meaning it fail to accurately distinguish between real and generated samples, this will also provide weak or incorrect feedback to the generator, which hold back the learning process. The generator may receive misleading signals that its generated samples are realistic, even if they are not, making it might not learn to improve and generate a better samples.</p>
<p>This is often called as <strong>convergence failure</strong>.</p>
<p>Both generator and discriminator are trained in alternating turns. This is to stabilize the learning process and to establish a feedback loop by improving iteratively from each other feedback.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="loss-function">Loss Function<a href="#loss-function" class="hash-link" aria-label="Direct link to Loss Function" title="Direct link to Loss Function">​</a></h3>
<p>The loss function used for GAN will be two, one for generator and another for discriminator. We used two loss function to be able to measure both of their performance. As explained before, the generator tries to minimize its loss by generating more realistic data, while the discriminator tries to minimize its loss by becoming better at classifying the data.</p>
<h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="minimax">Minimax<a href="#minimax" class="hash-link" aria-label="Direct link to Minimax" title="Direct link to Minimax">​</a></h4>
<p>The minimax loss is the loss function used in the original paper that introduced GAN. The formula is :</p>
<p><img decoding="async" loading="lazy" alt="Minimax loss function formula" src="/cs-notes/assets/images/minimax-loss-b619348ad4c45a2744a24fdbf69df6cf.png" width="839" height="405" class="img_ev3q"><br>
<!-- -->Source : <a href="https://developers.google.com/machine-learning/gan/loss" target="_blank" rel="noopener noreferrer">https://developers.google.com/machine-learning/gan/loss</a></p>
<p>The D and G is commonly used to refer the discriminator and generator, respectively. It is related to the <a href="/cs-notes/deep-learning/deep-learning-foundation#cross-entropy">cross entropy loss function formula</a>. The expected value measure of what we can expect to observe on average when dealing with uncertainty, in this case the uncertainty of the real data <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>E</mi><mi>x</mi></msub></mrow><annotation encoding="application/x-tex">E_x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> and the fake instance <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>E</mi><mi>z</mi></msub></mrow><annotation encoding="application/x-tex">E_z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.04398em">z</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>.</p>
<p>The first term <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>E</mi><mi>x</mi></msub><mo stretchy="false">[</mo><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>D</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">E_x[\log(D(x))]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">[</span><span class="mop">lo<span style="margin-right:0.01389em">g</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">))]</span></span></span></span> represents the expected log-likelihood (the logarithm of a probability) of the <strong>discriminator correctly classifying real data as real</strong>. The generator aims to minimize this term to generate data that can &quot;fool&quot; the discriminator.</p>
<p>The second term <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>E</mi><mi>z</mi></msub><mo stretchy="false">[</mo><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>D</mi><mo stretchy="false">(</mo><mi>G</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">E_z[\log(1 - D(G(z)))]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.04398em">z</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">[</span><span class="mop">lo<span style="margin-right:0.01389em">g</span></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mopen">(</span><span class="mord mathnormal">G</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.04398em">z</span><span class="mclose">)))]</span></span></span></span> represents the expected log-likelihood of the <strong>discriminator correctly classifying generated data as generated</strong>. The discriminator aims to maximize this term by correctly distinguishing between real and generated data.</p>
<p>The minimization or maximization of specific term is done by taking the partial derivative with respect to the specific parameters. The loss will be optimized and backpropagation process will be done to adjust all the parameters involved. The generator is connected to the discriminator to receive its gradient for optimization step.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="wasserstein-wgan">Wasserstein (WGAN)<a href="#wasserstein-wgan" class="hash-link" aria-label="Direct link to Wasserstein (WGAN)" title="Direct link to Wasserstein (WGAN)">​</a></h3>
<p>The Wasserstein loss is the alternative loss function for minimax, it modified the concept of standard GAN, becoming <strong>Wasserstein Generative Adversarial Networks (WGANs)</strong>. This was introduced to address GAN problem including the lack of meaningful loss metric.</p>
<p>The minimax loss does not provide a direct and meaningful measure of the quality of generated samples, it only provides a real or fake indicator. The objective function does not correlate well with the visual quality or desired characteristics of the generated samples, making it difficult to assess the progress of training.</p>
<p>In WGAN, the discriminator is no longer trained to classify samples as real or fake. Also, it is no longer called a discriminator, instead it is called a <strong>critic</strong>.</p>
<p>The real data from training sample and the fake data from generator is represented in a probability distribution. The discriminator or the critic still have its own network, however, the output of the network is a measure of how far is the input it received from the real data probability distribution. It is calculated using the <strong>earth mover distance</strong> or the <strong>wasserstein distance</strong>.</p>
<p>After that, the result of critic will be used in the wasserstein loss function, which is the below formula :</p>
<p><img decoding="async" loading="lazy" alt="Wasserstein loss" src="/cs-notes/assets/images/wasserstein-loss-ed4f77f8e2afc97603e0f3fa8acd6e68.png" width="858" height="433" class="img_ev3q"><br>
<!-- -->Source : <a href="https://developers.google.com/machine-learning/gan/loss" target="_blank" rel="noopener noreferrer">https://developers.google.com/machine-learning/gan/loss</a></p>
<p>The critic is trained to maximize the critic loss which is the difference between the output on real and fake instance. This mean we are training the critic to be able to accurately estimate the distance between input distribution and the real distribution. And the generator is trained to maximize the critic output for fake instance (or minimizing the negative output of critic), where the higher means the more close it is to real data.</p>
<p>In summary, the benefit of having the critic produce real-valued outputs instead of binary real or fake labels is that it allows the critic to provide a measure of the degree of realism in the generated samples.</p>
<p>After that, the backpropagation process that optimize all the parameters involved, including the generator&#x27;s parameters are done. The gradient from the discriminator as the output will be passed to the generator.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="variations-of-gan">Variations of GAN<a href="#variations-of-gan" class="hash-link" aria-label="Direct link to Variations of GAN" title="Direct link to Variations of GAN">​</a></h3>
<p>GAN also have several variations, the two example are :</p>
<h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="conditional-gan-cgan">Conditional GAN (cGAN)<a href="#conditional-gan-cgan" class="hash-link" aria-label="Direct link to Conditional GAN (cGAN)" title="Direct link to Conditional GAN (cGAN)">​</a></h4>
<p>In traditional GAN, the generator takes random noise as input and produces new samples. In cGAN, both the generator and discriminator are conditioned on additional information, in the form of labels or class information. It uses the concept of conditional probability with the given condition instead of the concept of joint probability of the noise and real data.</p>
<p>This conditioning enables the generation of samples that are conditioned on specific attributes, making it useful for tasks like generating samples based on specific class labels or generating another image based on some input image (called image-to-image translation).</p>
<p><img decoding="async" loading="lazy" alt="cGAN compared to GAN" src="/cs-notes/assets/images/cgan-a9e20f78cd55d24be6df0948fdaf9121.png" width="844" height="360" class="img_ev3q"><br>
<!-- -->Source : <a href="https://learnopencv.com/conditional-gan-cgan-in-pytorch-and-tensorflow/" target="_blank" rel="noopener noreferrer">https://learnopencv.com/conditional-gan-cgan-in-pytorch-and-tensorflow/</a>, <a href="https://developers.google.com/machine-learning/gan/applications" target="_blank" rel="noopener noreferrer">https://developers.google.com/machine-learning/gan/applications</a></p>
<h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="variational-autoencoder-gan-vae-gan">Variational Autoencoder GAN (VAE-GAN)<a href="#variational-autoencoder-gan-vae-gan" class="hash-link" aria-label="Direct link to Variational Autoencoder GAN (VAE-GAN)" title="Direct link to Variational Autoencoder GAN (VAE-GAN)">​</a></h4>
<p>VAE-GAN combines the <a href="/cs-notes/deep-learning/variational-autoencoder">variational autoencoder</a> with the traditional GAN. The generator in GAN is replaced by the decoder of VAE. The step are :</p>
<ol>
<li>Input data goes through encoder, the data will be transformed into latent space representation in the form of probability distribution.</li>
<li>The distribution will be sampled and goes into the decoder, transforming it back to higher-dimensional representation.</li>
<li>The generated data from decoder will be passed together with training sample to the discriminator</li>
<li>Discriminator classify real or fake data.</li>
</ol>
<p>There are 3 loss function used which is combined from loss in VAE and GAN :</p>
<ol>
<li><strong>Regularization / KL Divergence Loss</strong> : The loss for encoder which is responsible to map input data into latent space representation, the loss is supposed to encourage the encoder to make the latent space representation close to the prior distribution, which is set to normal distribution.</li>
<li><strong>Reconstruction Loss</strong> : The loss of VAE decoder, the difference between reconstructed image with the original image.</li>
<li><strong>Adversarial / GAN Loss</strong> : The loss resulted from discriminator that classify whether data is real or fake. The generator or the decoder of VAE need to generate data that can fool the discriminator while the discriminator need to classify real images as real and generated images as fake.</li>
</ol>
<p><img decoding="async" loading="lazy" alt="VAE-GAN architecture" src="/cs-notes/assets/images/vae-gan-bf881f3b087dd6c0e8dd8bbc2a94b4e8.png" width="841" height="380" class="img_ev3q"><br>
<!-- -->Referenced from : <a href="https://wandb.ai/shambhavicodes/vae-gan/reports/An-Introduction-to-VAE-GANs--VmlldzoxMTcxMjM5" target="_blank" rel="noopener noreferrer">https://wandb.ai/shambhavicodes/vae-gan/reports/An-Introduction-to-VAE-GANs--VmlldzoxMTcxMjM5</a>, <a href="https://medium.com/dataseries/variational-autoencoder-with-pytorch-2d359cbf027b" target="_blank" rel="noopener noreferrer">https://medium.com/dataseries/variational-autoencoder-with-pytorch-2d359cbf027b</a></p>
<h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="cyclegan">CycleGAN<a href="#cyclegan" class="hash-link" aria-label="Direct link to CycleGAN" title="Direct link to CycleGAN">​</a></h4>
<p><strong>Cycle-Consistent GAN</strong> is a type of GAN designed for image-to-image translation tasks. It is an unsupervised learning model that can learn to convert/transform one image to another image smoothly without paired training data. It is achieved using two paired of generator and discriminator.</p>
<p>The generator consists of two, the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>G</mi><mi>A</mi></msub></mrow><annotation encoding="application/x-tex">G_A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">A</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> that is responsible for transforming image from domain A to domain B, another one <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>G</mi><mi>B</mi></msub></mrow><annotation encoding="application/x-tex">G_B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05017em">B</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> is responsible for transforming image from domain B to domain A.</p>
<p>The discriminator <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>D</mi><mi>A</mi></msub></mrow><annotation encoding="application/x-tex">D_A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">A</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> classify between real and fake image from domain A which is from <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>G</mi><mi>A</mi></msub></mrow><annotation encoding="application/x-tex">G_A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">A</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>, while <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>D</mi><mi>B</mi></msub></mrow><annotation encoding="application/x-tex">D_B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05017em">B</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> does the same from <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>G</mi><mi>B</mi></msub></mrow><annotation encoding="application/x-tex">G_B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05017em">B</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>.</p>
<div class="theme-admonition theme-admonition-note admonition_xJq3 alert alert--secondary"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_BuS1"><p>The domain here means a specific style of an image that is visually distinguishable, a common example is a horse image (domain A) transitioning to zebra image (domain B).</p></div></div>
<p>The CycleGAN process operates in a cycle :</p>
<ol>
<li>Generator A takes an image from Domain A as input and translates it to Domain B. The goal is to generate a realistic image in Domain B as it is really coming from domain B.</li>
<li>Generator B takes that translated image and translates it back to Domain A. The goal is to reconstruct an image that is similar to the original input image from Domain A.</li>
<li>The discriminator compare the generated images with the same real images which we used as input for generator A in step 1.</li>
</ol>
<p>The process is same for the other discriminator.</p>
<p><img decoding="async" loading="lazy" alt="CycleGAN architecture" src="/cs-notes/assets/images/cyclegan-c78eaaf82f39994d760a41d351871fee.png" width="719" height="515" class="img_ev3q"><br>
<!-- -->Source : <a href="https://www.oreilly.com/library/view/hands-on-artificial-intelligence/9781788836067/c2e7d914-4e45-4528-8627-c590d19107ef.xhtml" target="_blank" rel="noopener noreferrer">https://www.oreilly.com/library/view/hands-on-artificial-intelligence/9781788836067/c2e7d914-4e45-4528-8627-c590d19107ef.xhtml</a></p>
<p>There are two loss function used, the same adversarial/GAN loss which is obtained from the discriminator classification (classify whether image is real or fake). Another loss is the <strong>cycle consistency loss</strong>, which is loss introduced to ensure the translation from A to B and then from B to A or vice versa reconstructs the original image.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/glennhenry/cs-notes/tree/main/docs/deep-learning/13-gan/gan.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2023-10-13T10:50:28.000Z">Oct 13, 2023</time></b> by <b>glennhenry</b></span></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/cs-notes/deep-learning/variational-autoencoder"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Variational Autoencoder</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/cs-notes/deep-learning/transformers/attention-mechanism"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Attention Mechanism</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#adversarial-training" class="table-of-contents__link toc-highlight">Adversarial Training</a></li><li><a href="#generator" class="table-of-contents__link toc-highlight">Generator</a></li><li><a href="#discriminator" class="table-of-contents__link toc-highlight">Discriminator</a><ul><li><a href="#training-process" class="table-of-contents__link toc-highlight">Training Process</a></li></ul></li><li><a href="#loss-function" class="table-of-contents__link toc-highlight">Loss Function</a><ul><li><a href="#minimax" class="table-of-contents__link toc-highlight">Minimax</a></li></ul></li><li><a href="#wasserstein-wgan" class="table-of-contents__link toc-highlight">Wasserstein (WGAN)</a></li><li><a href="#variations-of-gan" class="table-of-contents__link toc-highlight">Variations of GAN</a><ul><li><a href="#conditional-gan-cgan" class="table-of-contents__link toc-highlight">Conditional GAN (cGAN)</a></li><li><a href="#variational-autoencoder-gan-vae-gan" class="table-of-contents__link toc-highlight">Variational Autoencoder GAN (VAE-GAN)</a></li><li><a href="#cyclegan" class="table-of-contents__link toc-highlight">CycleGAN</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024, myself. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>